
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Faire &#8212; LocalRQA  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/autodoc_pydantic.css" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'usecases/faire';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="local_rqa namespace" href="../api_reference/local_rqa.html" />
    <link rel="prev" title="Databricks" href="databricks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">LocalRQA  documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../getting_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quickstart.html">Quickstart</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/data.html">Data</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/data/data_description.html">RQA Data Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/data/data_preparation.html">Prepare RQA Data</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/training.html">Training</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/training/retriever.html">Training a Retriever</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/retriever/ctl.html">Contrastive Learning (CTL)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/retriever/dca.html">Distill from Cross-Attention scores (DCA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/retriever/rpg.html">Distill from an LM’s probability distribution (RPG)</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../modules/training/generator.html">Training a Generator</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/generator/sft.html">SFT with Gold Data (SFT)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/generator/swr.html">SFT with a Frozen Retriever (SwR)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../modules/training/generator/fid.html">Fusion-in-Decoder Training (FiD)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/evaluation.html">Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/evaluation/eval_retriever.html">Retriever Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/evaluation/eval_e2e.html">End-to-End Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules/serving.html">Serving</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../modules/serving/human_eval.html">Static Human Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/serving/interactive.html">Interactive Chat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../modules/serving/acc_frameworks.html">Inference Acceleration Frameworks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Playground</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../playground/custom_rqa.html">Customize your RQA system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../playground/custom_trainer.html">Customize Model Trainers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Use Cases</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="databricks.html">Databricks</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Faire</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api_reference/local_rqa.html">local_rqa namespace</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.evaluation.html">local_rqa.evaluation package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.guardrails.html">local_rqa.guardrails package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.pipelines.html">local_rqa.pipelines package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.qa_llms.html">local_rqa.qa_llms package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.retrievers.html">local_rqa.retrievers package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.schema.html">local_rqa.schema package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.serve.html">local_rqa.serve package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api_reference/local_rqa.text_loaders.html">local_rqa.text_loaders package</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api_reference/local_rqa.trainers.html">local_rqa.trainers namespace</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/local_rqa.trainers.qa_llm.html">local_rqa.trainers.qa_llm namespace</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_reference/local_rqa.trainers.retriever.html">local_rqa.trainers.retriever namespace</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/usecases/faire.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Faire</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-data">Prepare Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunking-and-formatting">Chunking and Formatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-qa">Generating QA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-retriever">Train a Retriever</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-generator">Train a Generator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-evaluation">Automatic Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploy-the-rqa-system">Deploy the RQA system</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="faire">
<span id="use-case-faire"></span><h1>Faire<a class="headerlink" href="#faire" title="Link to this heading">#</a></h1>
<p>Faire is an online wholesale marketplace connecting independent retailers and brands around the world:</p>
<blockquote>
<div><p>Now more than ever, consumers are choosing to support local shops over big-box chains. There are millions of thriving small businesses in North America, Europe, and Australia alone, who collectively represent a trillion dollar market. With our global community and the power of technology, Faire is helping fuel the growth of entrepreneurs everywhere.</p>
</div></blockquote>
<p>To find out more about Faire, you can visit <a class="reference external" href="https://www.faire.com/">faire.com</a>.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../_images/faire_logo.jpg"><img alt="Faire" src="../_images/faire_logo.jpg" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-text">Image credit: <a class="reference external" href="https://www.faire.com/">https://www.faire.com/</a></span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>In this tutorial</strong>, we provide an end-to-end example of using LocalRQA to:</p>
<ol class="arabic simple">
<li><p>Prepare RQA data using documents obtained from Faire’s websites</p></li>
<li><p>Train a retriever model</p></li>
<li><p>Train a generator model</p></li>
<li><p>Use automatic metrics to measure the RQA system’s performance</p></li>
<li><p>Deploy the RQA system for human evaluation/interactive free chat</p></li>
</ol>
<section id="prepare-data">
<h2>Prepare Data<a class="headerlink" href="#prepare-data" title="Link to this heading">#</a></h2>
<p>We contacted Faire’s Sales team and crawled documents from <a class="reference external" href="https://www.faire.com/support">faire.com/support</a> according to their suggestions, and then processed the data to only keep raw texts. You can find these data under <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/raw&gt;</span></code> directory. These data include the guides and FAQ documents that Faire used to support their retailers.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="c1">// docs.jsonl</span>
<span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Faire account security best practices&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://www.faire.com/support/articles/4408644893851&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Faire helps you discover products, manage your orders, and pay invoices...&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;title&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Resetting my password&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;https://www.faire.com/support/articles/360019854651&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;If you would like to reset your password, please follow the steps below:...&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="err">...</span>
<span class="p">]</span>
</pre></div>
</div>
<section id="chunking-and-formatting">
<h3>Chunking and Formatting<a class="headerlink" href="#chunking-and-formatting" title="Link to this heading">#</a></h3>
<p>The first step is to chunk these documents and format them into <code class="docutils literal notranslate"><span class="pre">local_rqa.schema.document.Document</span></code> objects. This will essentially convert these raw data into a single <strong>document database</strong> that can be used for all subsequent training and evaluation steps. For JSONL files, this can be done using the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/data/process_docs.py<span class="w"> </span><span class="se">\</span>
--document_path<span class="w"> </span>&lt;example/faire/raw/docs.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--chunk_size<span class="w"> </span><span class="m">400</span><span class="w"> </span><span class="se">\</span>
--chunk_overlap_size<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--save_dir<span class="w"> </span>&lt;example/faire&gt;<span class="w"> </span><span class="se">\</span>
--save_name<span class="w"> </span>&lt;documents&gt;
</pre></div>
</div>
<p>This will read in the JSON file, chunk all texts into documents of maximum token length 400, and save the resulting document database into <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/documents.pkl&gt;</span></code>.</p>
<p><em>Alternatively</em>, you could also customize its behavior using <code class="docutils literal notranslate"><span class="pre">langchain</span></code> and our <code class="docutils literal notranslate"><span class="pre">LangChainTextLoader</span></code> (or if you use <code class="docutils literal notranslate"><span class="pre">llama-index</span></code>, we also have <code class="docutils literal notranslate"><span class="pre">LlamaIndexTextLoader</span></code>). Under the hood, this process of loading data and chunking them is done by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">JSONLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">local_rqa.text_loaders.langchain_text_loader</span> <span class="kn">import</span> <span class="n">LangChainTextLoader</span>

<span class="c1"># other code omitted</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">loader_func</span><span class="p">,</span> <span class="n">splitter_func</span> <span class="o">=</span> <span class="n">JSONLoader</span><span class="p">,</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="o">.</span><span class="n">from_huggingface_tokenizer</span>

    <span class="c1">## configure how to load the data</span>
    <span class="n">loader_parameters</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;file_path&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;example/faire/raw/docs.jsonl&gt;,</span>
        <span class="s1">&#39;jq_schema&#39;</span><span class="p">:</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span>
        <span class="s1">&#39;content_key&#39;</span><span class="p">:</span> <span class="s1">&#39;text&#39;</span><span class="p">,</span>
        <span class="s1">&#39;json_lines&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;metadata_func&#39;</span><span class="p">:</span> <span class="n">metadata_func</span>
    <span class="p">}</span>

    <span class="c1">## configure how to chunk each piece of text</span>
    <span class="c1">## RecursiveCharacterTextSplitter requires a tokenizer. As an example we can use one from hugginface</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/contriever-msmarco&quot;</span><span class="p">)</span>
    <span class="n">splitter_parameters</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;tokenizer&#39;</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">,</span>
        <span class="s1">&#39;chunk_size&#39;</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
        <span class="s1">&#39;chunk_overlap&#39;</span><span class="p">:</span> <span class="mi">50</span>
    <span class="p">}</span>

    <span class="c1">## actually load and chunk the data</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loader_params&quot;</span><span class="p">:</span> <span class="n">loader_parameters</span><span class="p">,</span> <span class="s2">&quot;splitter_params&quot;</span><span class="p">:</span> <span class="n">splitter_parameters</span><span class="p">}</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">LangChainTextLoader</span><span class="p">(</span>
        <span class="n">save_folder</span><span class="o">=</span><span class="s2">&quot;&lt;example/faire&gt;&quot;</span><span class="p">,</span>
        <span class="n">save_filename</span><span class="o">=</span><span class="s2">&quot;&lt;documents&gt;&quot;</span><span class="p">,</span>
        <span class="n">loader_func</span><span class="o">=</span><span class="n">loader_func</span><span class="p">,</span>
        <span class="n">splitter_func</span><span class="o">=</span><span class="n">splitter_func</span>
    <span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">documents</span>  <span class="c1">## a document database</span>
</pre></div>
</div>
<p>Both of the above should result in a document database of 1,758 passages. The content inside <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/documents.pkl&gt;</span></code> looks like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span>
    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s2">&quot;Showroom is a collection of expertly curated ...&quot;</span><span class="p">,</span> <span class="n">fmt_content</span><span class="o">=</span><span class="s2">&quot;...&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="o">...</span><span class="p">}),</span>
    <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="s2">&quot;There are a few ways to find Showroom brands ...&quot;</span><span class="p">,</span> <span class="n">fmt_content</span><span class="o">=</span><span class="s2">&quot;...&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="o">...</span><span class="p">}),</span>
    <span class="o">...</span>
<span class="p">]</span>
</pre></div>
</div>
</section>
<section id="generating-qa">
<h3>Generating QA<a class="headerlink" href="#generating-qa" title="Link to this heading">#</a></h3>
<p>The above only gives us a document database. To train a QA system, we need question-passage-answer triplets. LocalRQA provides the following three-step method to generate QA pairs from a document database:</p>
<ol class="arabic simple">
<li><p>select a set of gold passages from the document database</p></li>
<li><p>for each gold passage, prompt an LLM to generate a question</p></li>
<li><p>for each gold passage and question, prompt an LLM to generate an answer</p></li>
</ol>
<p><strong>Generate Questions</strong></p>
<p>Step 1 and step 2 are done together by the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/data/doc_to_q.py<span class="w"> </span><span class="se">\</span>
-mode<span class="w"> </span>all<span class="w"> </span><span class="se">\</span>
-document_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="w"> </span><span class="se">\</span>
--prompt_model<span class="w"> </span>gpt-3.5-turbo<span class="w"> </span><span class="se">\</span>
--num_hard_negs_per_doc<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--num_train_data<span class="w"> </span><span class="m">600</span><span class="w"> </span><span class="se">\ </span><span class="w">   </span><span class="c1"># use a small number to test if it works first</span>
--num_eval_test_data<span class="w"> </span><span class="m">150</span><span class="w"> </span><span class="se">\ </span><span class="w">   </span><span class="c1"># use a small number to test if it works first</span>
--save_dir<span class="w"> </span>&lt;example/faire&gt;
</pre></div>
</div>
<p>This script first samples “(gold passage, hard negative passage 1, hard negative passage 2)” from the document database, and then prompts OpenAI’s GPT-3.5-turbo to generate two questions for each gold passage. Then, 600 will go to <code class="docutils literal notranslate"><span class="pre">train_w_q.jsonl</span></code>, and 150 will be split to become  <code class="docutils literal notranslate"><span class="pre">eval_w_q.jsonl</span></code>, <code class="docutils literal notranslate"><span class="pre">test_w_q.jsonl</span></code> under <code class="docutils literal notranslate"><span class="pre">&lt;example/faire&gt;</span></code> folder.</p>
<p>If you want to <strong>customize the question generation process</strong>, you can refer to <code class="docutils literal notranslate"><span class="pre">scripts/data/doc_to_q_databricks.py</span></code> as an example. We expose methods that allow you to customize the prompts and document selection process:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># scripts/data/doc_to_q_databricks.py</span>
<span class="kn">from</span> <span class="nn">scripts.data.doc_to_q</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">DATABRICKS_DOC2Q_PROMPT</span> <span class="o">=</span> <span class="o">...</span>

<span class="k">def</span> <span class="nf">databricks_filter_fn</span><span class="p">(</span><span class="n">doc</span><span class="p">:</span> <span class="n">Document</span><span class="p">):</span>
    <span class="c1"># decides if we should keep this doc for question generation or not</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;to customize how (doc, q) pairs would be created, simply copy this function over and modify the &quot;# customizable&quot; parts</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;init_eval_dset&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]:</span>
        <span class="n">documents_dataset</span> <span class="o">=</span> <span class="n">create_positive_n_negative_examples</span><span class="p">(</span>
            <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span>
            <span class="n">filter_fn</span><span class="o">=</span><span class="n">databricks_filter_fn</span>  <span class="c1"># customized</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">documents_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> &lt;gold document, hard negative documents&gt; pairs.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;create_eval_dset&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]:</span>
        <span class="n">eval_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">create_heldout_test_dset</span><span class="p">(</span>
            <span class="n">args</span><span class="p">,</span>
            <span class="n">doc2q_prompt</span><span class="o">=</span><span class="n">DATABRICKS_DOC2Q_PROMPT</span>  <span class="c1"># customized</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of eval samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of test samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;create_train_dset&quot;</span><span class="p">,</span> <span class="s2">&quot;all&quot;</span><span class="p">]:</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">create_train_dset</span><span class="p">(</span>
            <span class="n">args</span><span class="p">,</span>
            <span class="n">doc2q_prompt</span><span class="o">=</span><span class="n">DATABRICKS_DOC2Q_PROMPT</span>  <span class="c1"># customized</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of train samples: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
<p>In the end, the content of <code class="docutils literal notranslate"><span class="pre">train_w_q.jsonl</span></code> should look like:</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>[
    {&quot;chat_history&quot;: [], &quot;questions&quot;: [&quot;What are non-GMO products ...&quot;, &quot;What is ...&quot;], &quot;gold_docs&quot;: [...], &quot;hard_neg_docs&quot;: [...]},
    {&quot;chat_history&quot;: [], &quot;questions&quot;: [&quot;What should I do if ...&quot;, &quot;...&quot;], &quot;gold_docs&quot;: [...], &quot;hard_neg_docs&quot;: [...]},
    ...
]
</pre></div>
</div>
<p><strong>Generate Answers</strong></p>
<p>Finally, given a question and a gold passage, answer generation is straightforward. We can prompt another LLM to provide an answer given the question and the gold passage. This can be done using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/data/doc_q_to_a.py<span class="w"> </span><span class="se">\</span>
--prompt_model<span class="w"> </span>gpt-4-1106-preview<span class="w"> </span><span class="se">\</span>
--dataset_w_q<span class="w"> </span>&lt;example/faire/train_w_q.jsonl&gt;<span class="w"> </span><span class="se">\ </span><span class="w"> </span><span class="c1"># generated by the previous step</span>
--save_name<span class="w"> </span>train_w_qa.jsonl<span class="w"> </span><span class="se">\</span>
--save_dir<span class="w"> </span>&lt;example/faire&gt;<span class="w"> </span><span class="se">\</span>
--end_data_idx<span class="w"> </span><span class="m">4</span><span class="w">  </span><span class="c1"># a small number first to test if the answers are satisfactory</span>
</pre></div>
</div>
<p>This will prompt OpenAI’s GPT-4-turbo (<code class="docutils literal notranslate"><span class="pre">gpt-4-1106-preview</span></code>) to generate answers for each question and gold passage pair. The result data is saved to <code class="docutils literal notranslate"><span class="pre">train_w_qa.jsonl</span></code> under <code class="docutils literal notranslate"><span class="pre">&lt;example/faire&gt;</span></code> folder. The content of <code class="docutils literal notranslate"><span class="pre">train_w_qa.jsonl</span></code> will look like:</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>[
    {&quot;chat_history&quot;: [], &quot;question&quot;: &quot;What are non-GMO products ...&quot;, &quot;gold_docs&quot;: [...], &quot;hard_neg_docs&quot;: [...], &quot;gold_answer&quot;: &quot;...&quot;},
    {&quot;chat_history&quot;: [], &quot;question&quot;: &quot;What is ...&quot;, &quot;gold_docs&quot;: [...], &quot;hard_neg_docs&quot;: [...], &quot;gold_answer&quot;: &quot;...&quot;},
    ...
]
</pre></div>
</div>
<p>To obtain <code class="docutils literal notranslate"><span class="pre">eval_w_qa.jsonl</span></code> and <code class="docutils literal notranslate"><span class="pre">test_w_qa.jsonl</span></code>, you can simply replace the <code class="docutils literal notranslate"><span class="pre">--dataset_w_q</span></code> argument with <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/eval_w_q.jsonl&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/test_w_q.jsonl&gt;</span></code> respectively.</p>
</section>
</section>
<section id="train-a-retriever">
<h2>Train a Retriever<a class="headerlink" href="#train-a-retriever" title="Link to this heading">#</a></h2>
<p>Now we have all the data we need. We can first use it to fine-tune a retriever model.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this tutorial, we are using one A100 80GB GPU to train all of our models. You may want to adjust hyperparameters such as batch size and gradient accumulation steps if you are using a different setup.</p>
</div>
<p>In this example, we will use <code class="docutils literal notranslate"><span class="pre">BAAI/bge-base-en-v1.5</span></code> as the base model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/train/retriever/train_ctl_retriever.py<span class="w"> </span><span class="se">\</span>
--pooling_type<span class="w"> </span>mean<span class="w"> </span><span class="se">\</span>
--learning_rate<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
--per_device_train_batch_size<span class="w"> </span><span class="m">256</span><span class="w"> </span><span class="se">\</span>
--per_device_eval_batch_size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
--hard_neg_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
--metric_for_best_model<span class="w"> </span>eval_retr/document_recall/recall4<span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>BAAI/bge-base-en-v1.5<span class="w"> </span><span class="se">\</span>
--max_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
--eval_steps<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--save_steps<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--logging_steps<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--temperature<span class="w"> </span><span class="m">1</span>.2<span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>&lt;example/ctl/model/dir&gt;<span class="w"> </span><span class="se">\</span>
--train_file<span class="w"> </span>&lt;example/faire/train_w_q.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--eval_file<span class="w"> </span>&lt;example/faire/eval_w_q.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--test_file<span class="w"> </span>&lt;example/faire/test_w_q.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--full_dataset_file_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;
</pre></div>
</div>
<p>This will finetune the model using the <a class="reference internal" href="../modules/training/retriever/ctl.html#training-ret-ctl"><span class="std std-ref">Contrastive Learning (CTL)</span></a> algorithm for 100 steps, log the training process to <code class="docutils literal notranslate"><span class="pre">wandb</span></code>, and save the model with highest Recall&#64;4 score to <code class="docutils literal notranslate"><span class="pre">&lt;example/ctl/model/dir&gt;</span></code>. During training, it will also perform <span class="xref std std-ref">evaluation-ret</span> with <code class="docutils literal notranslate"><span class="pre">eval_embedding_model</span></code> using the <code class="docutils literal notranslate"><span class="pre">full_dataset_file_path</span></code>.</p>
<p>For more details on <strong>other training algorithms we currently support</strong>, please refer to <a class="reference internal" href="../modules/training/retriever.html#training-ret"><span class="std std-ref">Training a Retriever</span></a>.</p>
</section>
<section id="train-a-generator">
<h2>Train a Generator<a class="headerlink" href="#train-a-generator" title="Link to this heading">#</a></h2>
<p>Next, we can also fine-tune a generative model using the same data (and optionally the retriever we just trained). In this example, we will use <code class="docutils literal notranslate"><span class="pre">berkeley-nest/Starling-LM-7B-alpha</span></code> as the base model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/train/qa_llm/train_w_gt.py<span class="w"> </span><span class="se">\</span>
--use_flash_attention<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
--per_device_train_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
--per_device_eval_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
--deepspeed<span class="w"> </span>scripts/train/ds_config.json<span class="w"> </span><span class="se">\</span>
--learning_rate<span class="w"> </span>5e-6<span class="w"> </span><span class="se">\</span>
--num_train_epochs<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--gradient_accumulation_steps<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--bf16<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>berkeley-nest/Starling-LM-7B-alpha<span class="w"> </span><span class="se">\</span>
--assistant_prefix<span class="w"> </span><span class="s2">&quot;GPT4 Correct Assistant&quot;</span><span class="w"> </span><span class="se">\</span>
--user_prefix<span class="w"> </span><span class="s2">&quot;GPT4 Correct User&quot;</span><span class="w"> </span><span class="se">\</span>
--sep_user<span class="w"> </span><span class="s2">&quot;&lt;|end_of_turn|&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
--sep_sys<span class="w"> </span><span class="s2">&quot;&lt;|end_of_turn|&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
--eval_embedding_model<span class="w"> </span>&lt;example/ctl/model/dir&gt;<span class="w"> </span><span class="se">\</span>
--logging_steps<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
--eval_steps<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="se">\</span>
--save_steps<span class="w"> </span><span class="m">30</span><span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>&lt;example/sft/model/dir&gt;<span class="w"> </span><span class="se">\</span>
--run_group<span class="w"> </span>&lt;example_wandb_run_group_name&gt;<span class="w"> </span><span class="se">\</span>
--train_file<span class="w"> </span>&lt;example/faire/train_w_qa.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--eval_file<span class="w"> </span>&lt;example/faire/eval_w_qa.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--test_file<span class="w"> </span>&lt;example/faire/test_w_qa.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--full_dataset_file_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="w"> </span><span class="se">\</span>
--full_dataset_index_path<span class="w"> </span>&lt;example/faire/ctl/index&gt;
</pre></div>
</div>
<p>This will finetune the model using the <a class="reference internal" href="../modules/training/generator/sft.html#training-gen-sft"><span class="std std-ref">SFT with Gold Data (SFT)</span></a> algorithm for 2 epochs, log the training process to <code class="docutils literal notranslate"><span class="pre">wandb</span></code>, and save the model to <code class="docutils literal notranslate"><span class="pre">&lt;example/sft/model/dir&gt;</span></code>. During training, it will also perform <a class="reference internal" href="../modules/evaluation/eval_e2e.html#evaluation-e2e"><span class="std std-ref">End-to-End Evaluation</span></a> with <code class="docutils literal notranslate"><span class="pre">eval_embedding_model</span></code> using the <code class="docutils literal notranslate"><span class="pre">full_dataset_file_path</span></code> and <code class="docutils literal notranslate"><span class="pre">full_dataset_index_path</span></code>.</p>
<p>For more details on <strong>other training algorithms we currently support</strong>, please refer to <a class="reference internal" href="../modules/training/generator.html#training-gen"><span class="std std-ref">Training a Generator</span></a>.</p>
</section>
<section id="automatic-evaluation">
<h2>Automatic Evaluation<a class="headerlink" href="#automatic-evaluation" title="Link to this heading">#</a></h2>
<p>By default, our training scripts will perform automatic evaluation during training. However, there are circumstances where you may want to manually evaluate your model, for example, to swap in other embedding models for E2E evaluation. To this end, we provide standalone scripts for both retriever and generator evaluation.</p>
<p>To evaluate your retriever, for instance <code class="docutils literal notranslate"><span class="pre">&lt;example/ctl/model/dir&gt;</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/test/test_retriever.py<span class="w"> </span><span class="se">\</span>
--embedding_model_name_or_path<span class="w"> </span>&lt;example/ctl/model/dir/checkpoint-xxx&gt;<span class="w"> </span><span class="se">\</span>
--document_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="se">\</span>
--index_path<span class="w"> </span>&lt;example/faire/ctl/index&gt;<span class="w"> </span><span class="se">\</span>
--eval_data_path<span class="w"> </span>&lt;example/faire/test_w_q.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>&lt;example/retriever&gt;
</pre></div>
</div>
<p>By default, this will evaluate <code class="docutils literal notranslate"><span class="pre">embedding_model_name_or_path</span></code> model’s Recall&#64;1, Recall&#64;4 and runtime latency metrics using test data in <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/test_w_q.jsonl&gt;</span></code>. The result will be saved as <code class="docutils literal notranslate"><span class="pre">&lt;example/retriever/test-predictions.jsonl&gt;</span></code>. To enble <strong>nDCG</strong> metric, set <em>retr_ndcg = True</em> in setting <code class="docutils literal notranslate"><span class="pre">EvaluatorConfig</span></code>.</p>
<p>To evaluate the generator, for instance <code class="docutils literal notranslate"><span class="pre">&lt;example/sft/model/dir&gt;</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/test/test_e2e.py<span class="w"> </span><span class="se">\</span>
--qa_model_name_or_path<span class="w"> </span>&lt;example/sft/model/dir/checkpoint-xxx&gt;<span class="w"> </span><span class="se">\</span>
--assistant_prefix<span class="w"> </span><span class="s2">&quot;GPT4 Correct Assistant&quot;</span><span class="w"> </span><span class="se">\</span>
--user_prefix<span class="w"> </span><span class="s2">&quot;GPT4 Correct User&quot;</span><span class="w"> </span><span class="se">\</span>
--sep_user<span class="w"> </span><span class="s2">&quot;&lt;|end_of_turn|&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
--sep_sys<span class="w"> </span><span class="s2">&quot;&lt;|end_of_turn|&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
--embedding_model_name_or_path<span class="w"> </span>&lt;example/ctl/model/dir/checkpoint-xxx&gt;<span class="w"> </span><span class="se">\</span>
--document_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="w"> </span><span class="se">\</span>
--index_path<span class="w"> </span>&lt;example/faire/ctl/index&gt;<span class="w"> </span><span class="se">\</span>
--eval_data_path<span class="w"> </span>&lt;example/faire/test_w_qa.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>&lt;example/e2e&gt;
</pre></div>
</div>
<p>This will treat the <code class="docutils literal notranslate"><span class="pre">qa_model_name_or_path</span></code> and the <code class="docutils literal notranslate"><span class="pre">embedding_model_name_or_path</span></code> as an RQA system, and evaluate end-to-end using test data in <code class="docutils literal notranslate"><span class="pre">&lt;example/faire/test_w_qa.jsonl&gt;</span></code>. The result will be saved as <code class="docutils literal notranslate"><span class="pre">&lt;example/e2e/test-predictions.jsonl&gt;</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The evaluation command above does <strong>not</strong> perform GPT-4 based evaluation. To enable that option, you can pass in <code class="docutils literal notranslate"><span class="pre">--gen_gpt4eval</span> <span class="pre">true</span></code>. We note that this will incur additional costs, and is only recommended for final evaluation.</p>
<p>For more details on end-to-end evaluation, please refer to <a class="reference internal" href="../modules/evaluation/eval_e2e.html#evaluation-e2e"><span class="std std-ref">End-to-End Evaluation</span></a>.</p>
</div>
<p>As a baseline, you could also test the performance of GPT-4-turbo with text-ada-002:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/test/test_e2e.py<span class="w"> </span><span class="se">\</span>
--qa_model_name_or_path<span class="w"> </span>gpt-4-1106-preview<span class="w"> </span><span class="se">\</span>
--embedding_model_name_or_path<span class="w"> </span>text-embedding-ada-002<span class="w"> </span><span class="se">\</span>
--document_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="w"> </span><span class="se">\</span>
--index_path<span class="w"> </span>&lt;example/faire/openai/index&gt;<span class="w"> </span><span class="se">\</span>
--eval_data_path<span class="w"> </span>&lt;example/faire/test_w_qa.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>&lt;example/openai/e2e&gt;
</pre></div>
</div>
</section>
<section id="deploy-the-rqa-system">
<h2>Deploy the RQA system<a class="headerlink" href="#deploy-the-rqa-system" title="Link to this heading">#</a></h2>
<p>If you are satisfied with your current RQA system, you can deploy it for human evaluation or interactive free chat. Human evaluation results can be used to validate performance beyond automatic evaluation, and feedback from interactive free chat can be used to further improve the RQA system.</p>
<p><strong>To deploy the RQA system above for human evaluation</strong>, you can do:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>local_rqa/serve/gradio_static_server.py<span class="w"> </span><span class="se">\</span>
--file_path<span class="w"> </span>&lt;example/e2e/test-predictions.jsonl&gt;<span class="w"> </span><span class="se">\</span>
--include_idx<span class="w"> </span><span class="m">1</span>-50
</pre></div>
</div>
<p>This will launch a Gradio server at port <code class="docutils literal notranslate"><span class="pre">7861</span></code> and display the first 50 examples. You can access it by visiting <code class="docutils literal notranslate"><span class="pre">http://localhost:7861</span></code> in your browser, or share the link with others for human evaluation. For more details on our static human evaluation server, please refer to <a class="reference internal" href="../modules/serving/human_eval.html#serving-human-eval"><span class="std std-ref">Static Human Evaluation</span></a>.</p>
<p><strong>Deploying the system for interactive free chat</strong> is more complicated, as it requires hosting the model and managing asynchronous requests. We provide a quick example below. You may want to refer to <a class="reference internal" href="../modules/serving/interactive.html#serving-interactive-eval"><span class="std std-ref">Interactive Chat</span></a> for more details.</p>
<ol class="arabic">
<li><p>start a controller with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">local_rqa/serve/controller.py</span></code>.</p></li>
<li><p>start your model worker with</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>local_rqa/serve/model_worker.py<span class="w"> </span><span class="se">\</span>
--document_path<span class="w"> </span>&lt;example/faire/documents.pkl&gt;<span class="w"> </span><span class="se">\</span>
--index_path<span class="w"> </span>&lt;example/faire/openai/index&gt;<span class="w"> </span><span class="se">\</span>
--embedding_model_name_or_path<span class="w"> </span>&lt;example/ctl/model/dir/checkpoint-xxx&gt;<span class="w"> </span><span class="se">\</span>
--qa_model_name_or_path<span class="w"> </span>&lt;example/sft/model/dir/checkpoint-xxx&gt;<span class="w"> </span><span class="se">\</span>
--model_id<span class="w"> </span>simple_rqa
</pre></div>
</div>
</li>
<li><p>test if the model worker is alive: <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">local_rqa/serve/test_message.py</span> <span class="pre">--model_id</span> <span class="pre">simple_rqa</span></code></p></li>
<li><p>finally. launch the web server with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>local_rqa/serve/gradio_web_server.py<span class="w"> </span><span class="se">\</span>
--port<span class="w"> </span><span class="m">28888</span><span class="w"> </span><span class="se">\</span>
--model_id<span class="w"> </span>simple_rqa<span class="w"> </span><span class="se">\</span>
--example<span class="w"> </span><span class="s2">&quot;What is Faire?&quot;</span>
</pre></div>
</div>
</li>
</ol>
<p>You are all set! To access this server, you can visit <code class="docutils literal notranslate"><span class="pre">http://localhost:28888</span></code> in your browser. By default, any server log will be saved to the <code class="docutils literal notranslate"><span class="pre">logs/</span></code> folder. You can then access this log folder for chat histories and users’ feedback when chatting with your system!</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="databricks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Databricks</p>
      </div>
    </a>
    <a class="right-next"
       href="../api_reference/local_rqa.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">local_rqa namespace</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-data">Prepare Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunking-and-formatting">Chunking and Formatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generating-qa">Generating QA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-retriever">Train a Retriever</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-generator">Train a Generator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-evaluation">Automatic Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deploy-the-rqa-system">Deploy the RQA system</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Xiao Yu, Yunan Lu
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Xiao Yu, Yunan Lu.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>