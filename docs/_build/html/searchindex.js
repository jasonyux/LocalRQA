Search.setIndex({"docnames": ["_autosummary/open_rqa", "_autosummary/open_rqa.base", "_autosummary/open_rqa.constants", "_autosummary/open_rqa.evaluation", "_autosummary/open_rqa.evaluation.metrics", "_autosummary/open_rqa.evaluation.scores", "_autosummary/open_rqa.evaluation.utils", "_autosummary/open_rqa.guardrails", "_autosummary/open_rqa.guardrails.base", "_autosummary/open_rqa.pipelines", "_autosummary/open_rqa.pipelines.base", "_autosummary/open_rqa.pipelines.prompts", "_autosummary/open_rqa.pipelines.retrieval_qa", "_autosummary/open_rqa.qa_llms", "_autosummary/open_rqa.qa_llms.base", "_autosummary/open_rqa.qa_llms.fid", "_autosummary/open_rqa.qa_llms.huggingface", "_autosummary/open_rqa.qa_llms.openai", "_autosummary/open_rqa.qa_llms.prompts", "_autosummary/open_rqa.qa_llms.sglang", "_autosummary/open_rqa.qa_llms.tgi", "_autosummary/open_rqa.qa_llms.vllm", "_autosummary/open_rqa.retrievers", "_autosummary/open_rqa.retrievers.base", "_autosummary/open_rqa.schema", "_autosummary/open_rqa.schema.dialogue", "_autosummary/open_rqa.schema.document", "_autosummary/open_rqa.serve", "_autosummary/open_rqa.serve.base_model_worker", "_autosummary/open_rqa.serve.gradio_dialogue", "_autosummary/open_rqa.serve.test_message", "_autosummary/open_rqa.text_loaders", "_autosummary/open_rqa.text_loaders.base", "_autosummary/open_rqa.text_loaders.langchain_text_loader", "_autosummary/open_rqa.text_loaders.llamaindex_text_loader", "_autosummary/open_rqa.trainers", "_autosummary/open_rqa.trainers.dist_utils", "_autosummary/open_rqa.trainers.utils", "_autosummary/open_rqa.utils", "_autosummary/open_rqa.vectorstore", "autoapi/arguments/index", "autoapi/base/index", "autoapi/constants/index", "autoapi/datasets/index", "autoapi/dist_utils/index", "autoapi/embeddings/index", "autoapi/evaluation/evaluator/index", "autoapi/evaluation/index", "autoapi/evaluation/metrics/index", "autoapi/evaluation/scores/index", "autoapi/evaluation/utils/index", "autoapi/guardrails/base/index", "autoapi/guardrails/index", "autoapi/index", "autoapi/pipelines/base/index", "autoapi/pipelines/index", "autoapi/pipelines/prompts/index", "autoapi/pipelines/retrieval_qa/index", "autoapi/qa_llms/base/index", "autoapi/qa_llms/fid/index", "autoapi/qa_llms/huggingface/index", "autoapi/qa_llms/index", "autoapi/qa_llms/openai/index", "autoapi/qa_llms/prompts/index", "autoapi/qa_llms/sglang/index", "autoapi/qa_llms/tgi/index", "autoapi/qa_llms/vllm/index", "autoapi/retriever_config/index", "autoapi/retriever_fid_trainer/index", "autoapi/retriever_replug_trainer/index", "autoapi/retriever_trainer/index", "autoapi/retrievers/base/index", "autoapi/retrievers/bm25_retriever/index", "autoapi/retrievers/faiss_retriever/index", "autoapi/retrievers/index", "autoapi/schema/dialogue/index", "autoapi/schema/document/index", "autoapi/schema/index", "autoapi/serve/base_model_worker/index", "autoapi/serve/cli/index", "autoapi/serve/controller/index", "autoapi/serve/gradio_dialogue/index", "autoapi/serve/gradio_rqa/index", "autoapi/serve/gradio_static_server/index", "autoapi/serve/gradio_web_server/index", "autoapi/serve/index", "autoapi/serve/inference/index", "autoapi/serve/model_worker/index", "autoapi/serve/test_message/index", "autoapi/supervised_fid_trainer/index", "autoapi/supervised_trainer/index", "autoapi/text_loaders/base/index", "autoapi/text_loaders/index", "autoapi/text_loaders/langchain_text_loader/index", "autoapi/text_loaders/llamaindex_text_loader/index", "autoapi/utils/index", "autoapi/with_retriever_fid_trainer/index", "autoapi/with_retriever_trainer/index", "generated/open_rqa", "index"], "filenames": ["_autosummary/open_rqa.rst", "_autosummary/open_rqa.base.rst", "_autosummary/open_rqa.constants.rst", "_autosummary/open_rqa.evaluation.rst", "_autosummary/open_rqa.evaluation.metrics.rst", "_autosummary/open_rqa.evaluation.scores.rst", "_autosummary/open_rqa.evaluation.utils.rst", "_autosummary/open_rqa.guardrails.rst", "_autosummary/open_rqa.guardrails.base.rst", "_autosummary/open_rqa.pipelines.rst", "_autosummary/open_rqa.pipelines.base.rst", "_autosummary/open_rqa.pipelines.prompts.rst", "_autosummary/open_rqa.pipelines.retrieval_qa.rst", "_autosummary/open_rqa.qa_llms.rst", "_autosummary/open_rqa.qa_llms.base.rst", "_autosummary/open_rqa.qa_llms.fid.rst", "_autosummary/open_rqa.qa_llms.huggingface.rst", "_autosummary/open_rqa.qa_llms.openai.rst", "_autosummary/open_rqa.qa_llms.prompts.rst", "_autosummary/open_rqa.qa_llms.sglang.rst", "_autosummary/open_rqa.qa_llms.tgi.rst", "_autosummary/open_rqa.qa_llms.vllm.rst", "_autosummary/open_rqa.retrievers.rst", "_autosummary/open_rqa.retrievers.base.rst", "_autosummary/open_rqa.schema.rst", "_autosummary/open_rqa.schema.dialogue.rst", "_autosummary/open_rqa.schema.document.rst", "_autosummary/open_rqa.serve.rst", "_autosummary/open_rqa.serve.base_model_worker.rst", "_autosummary/open_rqa.serve.gradio_dialogue.rst", "_autosummary/open_rqa.serve.test_message.rst", "_autosummary/open_rqa.text_loaders.rst", "_autosummary/open_rqa.text_loaders.base.rst", "_autosummary/open_rqa.text_loaders.langchain_text_loader.rst", "_autosummary/open_rqa.text_loaders.llamaindex_text_loader.rst", "_autosummary/open_rqa.trainers.rst", "_autosummary/open_rqa.trainers.dist_utils.rst", "_autosummary/open_rqa.trainers.utils.rst", "_autosummary/open_rqa.utils.rst", "_autosummary/open_rqa.vectorstore.rst", "autoapi/arguments/index.rst", "autoapi/base/index.rst", "autoapi/constants/index.rst", "autoapi/datasets/index.rst", "autoapi/dist_utils/index.rst", "autoapi/embeddings/index.rst", "autoapi/evaluation/evaluator/index.rst", "autoapi/evaluation/index.rst", "autoapi/evaluation/metrics/index.rst", "autoapi/evaluation/scores/index.rst", "autoapi/evaluation/utils/index.rst", "autoapi/guardrails/base/index.rst", "autoapi/guardrails/index.rst", "autoapi/index.rst", "autoapi/pipelines/base/index.rst", "autoapi/pipelines/index.rst", "autoapi/pipelines/prompts/index.rst", "autoapi/pipelines/retrieval_qa/index.rst", "autoapi/qa_llms/base/index.rst", "autoapi/qa_llms/fid/index.rst", "autoapi/qa_llms/huggingface/index.rst", "autoapi/qa_llms/index.rst", "autoapi/qa_llms/openai/index.rst", "autoapi/qa_llms/prompts/index.rst", "autoapi/qa_llms/sglang/index.rst", "autoapi/qa_llms/tgi/index.rst", "autoapi/qa_llms/vllm/index.rst", "autoapi/retriever_config/index.rst", "autoapi/retriever_fid_trainer/index.rst", "autoapi/retriever_replug_trainer/index.rst", "autoapi/retriever_trainer/index.rst", "autoapi/retrievers/base/index.rst", "autoapi/retrievers/bm25_retriever/index.rst", "autoapi/retrievers/faiss_retriever/index.rst", "autoapi/retrievers/index.rst", "autoapi/schema/dialogue/index.rst", "autoapi/schema/document/index.rst", "autoapi/schema/index.rst", "autoapi/serve/base_model_worker/index.rst", "autoapi/serve/cli/index.rst", "autoapi/serve/controller/index.rst", "autoapi/serve/gradio_dialogue/index.rst", "autoapi/serve/gradio_rqa/index.rst", "autoapi/serve/gradio_static_server/index.rst", "autoapi/serve/gradio_web_server/index.rst", "autoapi/serve/index.rst", "autoapi/serve/inference/index.rst", "autoapi/serve/model_worker/index.rst", "autoapi/serve/test_message/index.rst", "autoapi/supervised_fid_trainer/index.rst", "autoapi/supervised_trainer/index.rst", "autoapi/text_loaders/base/index.rst", "autoapi/text_loaders/index.rst", "autoapi/text_loaders/langchain_text_loader/index.rst", "autoapi/text_loaders/llamaindex_text_loader/index.rst", "autoapi/utils/index.rst", "autoapi/with_retriever_fid_trainer/index.rst", "autoapi/with_retriever_trainer/index.rst", "generated/open_rqa.rst", "index.rst"], "titles": ["open_rqa", "open_rqa.base", "open_rqa.constants", "open_rqa.evaluation", "open_rqa.evaluation.metrics", "open_rqa.evaluation.scores", "open_rqa.evaluation.utils", "open_rqa.guardrails", "open_rqa.guardrails.base", "open_rqa.pipelines", "open_rqa.pipelines.base", "open_rqa.pipelines.prompts", "open_rqa.pipelines.retrieval_qa", "open_rqa.qa_llms", "open_rqa.qa_llms.base", "open_rqa.qa_llms.fid", "open_rqa.qa_llms.huggingface", "open_rqa.qa_llms.openai", "open_rqa.qa_llms.prompts", "open_rqa.qa_llms.sglang", "open_rqa.qa_llms.tgi", "open_rqa.qa_llms.vllm", "open_rqa.retrievers", "open_rqa.retrievers.base", "open_rqa.schema", "open_rqa.schema.dialogue", "open_rqa.schema.document", "open_rqa.serve", "open_rqa.serve.base_model_worker", "open_rqa.serve.gradio_dialogue", "open_rqa.serve.test_message", "open_rqa.text_loaders", "open_rqa.text_loaders.base", "open_rqa.text_loaders.langchain_text_loader", "open_rqa.text_loaders.llamaindex_text_loader", "open_rqa.trainers", "open_rqa.trainers.dist_utils", "open_rqa.trainers.utils", "open_rqa.utils", "open_rqa.vectorstore", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">arguments</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">dist_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.metrics</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.scores</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">guardrails.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">guardrails</span></code>", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.prompts</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.retrieval_qa</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.fid</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.huggingface</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.openai</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.prompts</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.sglang</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.tgi</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.vllm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_replug_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.bm25_retriever</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.faiss_retriever</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema.dialogue</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema.document</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.base_model_worker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.cli</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.controller</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_dialogue</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_rqa</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_static_server</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_web_server</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.inference</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.model_worker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.test_message</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">supervised_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">supervised_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.langchain_text_loader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.llamaindex_text_loader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">with_retriever_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">with_retriever_trainer</span></code>", "open_rqa", "Welcome to LocalRQA\u2019s documentation!"], "terms": {"modul": [0, 3, 7, 9, 13, 22, 24, 27, 31, 35, 99], "class": [1, 2, 4, 8, 10, 14, 15, 16, 17, 19, 20, 21, 23, 25, 26, 28, 29, 32, 33, 34], "function": [4, 5, 6, 15, 26, 28, 30, 36, 37, 38, 68, 69, 70], "logger": [41, 45, 48, 54, 57, 64, 65, 66, 73, 78, 80, 82, 83, 84, 87, 95], "compon": [41, 51, 54, 57, 58, 71], "abc": [41, 46, 48, 71, 82, 86, 91, 93, 94], "build": 41, "block": [41, 59], "pipelin": [41, 46, 53, 71, 82, 89, 90, 97, 99], "which": [41, 43, 59, 75], "call": [41, 48, 59, 68, 69, 70, 97], "run": [41, 51, 54, 57, 58, 59, 68, 69, 70, 71, 97], "method": [41, 43, 51, 54, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 82, 97], "iter": [41, 64, 66, 68, 69, 70, 97], "run_input_kei": [41, 51, 54, 58, 71], "abstract": [41, 43, 46, 48, 51, 54, 58, 59, 71, 78, 82, 86, 91], "arg": [41, 48, 51, 54, 58, 68, 69, 70, 71, 79, 82, 83, 84, 88, 91, 93, 94, 97], "kwarg": [41, 48, 51, 54, 58, 59, 69, 71, 73, 82, 87, 91, 93, 94], "main": [41, 51, 54, 58, 71, 79, 83, 84, 86, 88], "entrypoint": [41, 51, 54, 58, 71], "keyword": [41, 51, 54, 58, 71], "pass": [41, 51, 54, 58, 59, 68, 69, 70, 71, 97], "argument": [41, 51, 53, 54, 58, 59, 68, 69, 70, 71, 89, 90, 97, 99], "thi": [41, 42, 43, 48, 51, 53, 54, 58, 59, 68, 69, 70, 71, 75, 80, 82, 83, 84, 97], "baseanswerguardrail": [51, 57], "perform": [46, 51, 68, 69, 70, 89, 90, 97], "action": 51, "fact": 51, "check": [51, 59, 68, 69, 70, 84, 89, 90, 97], "safeti": [51, 83, 84], "filter": 51, "etc": [51, 68, 69, 70, 76, 97], "batch_quest": [48, 51, 54, 57, 58, 60, 62, 64, 65, 66, 71, 72, 73], "list": [43, 45, 46, 48, 51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 89, 90, 91, 93, 94, 97], "str": [40, 45, 46, 48, 49, 50, 51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 97], "batch_source_docu": [51, 58, 60, 62, 64, 65, 66, 71, 75], "open_rqa": [46, 48, 51, 54, 57, 58, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 81, 82, 83, 84, 87, 89, 90, 91, 93, 94, 97], "schema": [48, 51, 53, 54, 57, 58, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 83, 84, 91, 93, 94, 97, 99], "document": [46, 48, 51, 53, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 77, 83, 84, 89, 90, 91, 93, 94, 97], "batch_dialogue_histori": [], "dialogu": [51, 53, 54, 57, 58, 60, 62, 64, 65, 66, 72, 73, 77, 81, 83, 84], "dialoguesess": [51, 54, 57, 58, 60, 62, 64, 65, 66, 75, 81], "batch_answ": [51, 58, 75], "rqaoutput": [51, 54, 57, 75], "post": 51, "process": [51, 59, 68, 69, 70, 97], "respons": [51, 59, 64, 66, 69], "befor": [51, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 89, 90, 97], "return": [43, 48, 51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 82, 89, 90, 93, 94, 97], "user": [51, 57, 59, 60, 62, 64, 65, 66, 69, 75, 83, 84, 87], "paramet": [46, 48, 51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 82, 89, 90, 93, 94, 97], "_description_": [46, 48, 51, 54, 57, 58, 60, 62, 64, 65, 66, 71, 72, 73, 75, 76, 82, 89, 90], "rais": [51, 58, 60, 62, 64, 65, 66, 82, 93, 94], "notimplementederror": [51, 58, 60, 62, 64, 65, 66, 82], "type": [51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 79, 89, 90, 93, 94, 97], "noopanswerguardrail": 51, "dummi": 51, "answer": [48, 51, 54, 57, 58, 62, 64, 66, 69, 75, 83, 84], "through": [51, 54, 57, 59], "base": [40, 42, 43, 45, 46, 48, 52, 53, 55, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 79, 80, 82, 86, 87, 89, 90, 92, 93, 94, 97, 99], "page": [42, 53, 99], "contain": [53, 54, 57, 68, 69, 70, 97], "auto": [53, 87], "gener": [42, 53, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 80, 82, 83, 84, 86, 97], "1": [53, 59], "guardrail": [53, 57, 99], "trainer": [68, 69, 70, 89, 90, 97], "vectorstor": [], "qa_llm": [53, 57, 89, 90, 97, 99], "text_load": [53, 99], "evalu": [53, 68, 69, 70, 89, 90, 97, 99], "retrieval_qa": [46, 53, 55, 82, 89, 90, 97], "retriev": [46, 53, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 78, 82, 87, 89, 90, 97, 99], "creat": [46, 53, 59, 71, 86, 91, 93, 94], "sphinx": 53, "autoapi": 53, "rqapipelin": [46, 54, 57], "given": [43, 54, 57, 58, 62, 64, 66, 68, 69, 70, 71, 72, 73, 97], "question": [43, 48, 54, 57, 58, 59, 60, 62, 64, 65, 66, 69, 75, 82], "histori": [54, 57, 58, 60, 62, 64, 65, 66, 72, 73, 75, 79, 81, 82, 86], "an": [42, 43, 46, 48, 54, 57, 59, 68, 69, 70, 71, 79, 83, 84, 86, 89, 90, 91, 93, 94, 97], "qa": [46, 54, 57, 60], "model": [40, 45, 46, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 73, 79, 82, 83, 84, 86, 87, 89, 90, 97], "batch_dialogue_sess": [51, 54, 57, 58, 60, 62, 64, 65, 66, 75], "make": [43, 54, 59, 68, 69, 70, 97], "up": 54, "update_dialogue_sess": 54, "retrieval_qa_output": 54, "updat": [48, 54, 75], "session": [54, 75, 83], "from": [42, 43, 54, 59, 68, 69, 70, 71, 72, 73, 79, 80, 86, 97], "current": [54, 68, 69, 70, 97], "turn": [54, 75], "system": [54, 75], "_prepare_input": 54, "data_dict": 54, "dict": [43, 46, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 75, 76, 80, 81, 82, 86, 89, 90, 97], "kei": [43, 54, 68, 69, 70, 81, 82, 83, 89, 90, 97], "assum": [54, 57, 75, 89, 90], "you": [54, 57, 59, 68, 69, 70, 82, 83, 84, 97], "can": [54, 57, 59, 68, 69, 70, 97], "directli": [54, 57], "pipe": [54, 57], "all": [43, 54, 57, 59, 68, 69, 70, 81, 89, 90, 97], "dataclass": [54, 57], "sourc": [54, 57, 58, 60, 62, 64, 65, 66, 75], "baserqa": 57, "baseretriev": [57, 71, 72, 73, 89, 90], "baseqamodel": [57, 58, 60, 62, 64, 65, 66], "answer_guardrail": 57, "take": [57, 59, 68, 69, 70, 97], "exactli": 57, "three": 57, "them": [57, 59, 68, 69, 70, 97], "sequenc": [57, 59, 89, 90], "simplerqa": [57, 82, 89, 90, 97], "verbos": [57, 87], "fals": [43, 45, 48, 57, 58, 59, 64, 68, 69, 70, 79, 81, 86, 87, 89, 90, 95, 97], "rephrase_question_prompt": 56, "_batch_gener": 57, "input_prompt": 57, "generate_kwarg": [57, 64, 65, 66], "rephrase_quest": 57, "rephras": [57, 58, 60, 62, 64, 65, 66, 71], "everi": 57, "standalon": 57, "_rephrase_quest": 57, "chat_history_str": [57, 58, 60, 62, 64, 65, 66], "autorqa": 57, "generationoutput": [58, 60, 62, 64, 65, 66], "us": [46, 48, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 73, 75, 82, 83, 84, 86, 89, 90, 91, 93, 94, 97], "llm": [58, 62, 64, 66], "set": [58, 59, 62, 64, 66, 68, 69, 70, 97], "r_gener": [58, 60, 62, 64, 65, 66], "augement": [58, 60, 62, 64, 65, 66], "batched_prompt": [58, 60, 62, 64, 65, 66], "tokenization_kwarg": [58, 60, 62, 64, 65, 66], "generation_kwarg": [58, 60, 62, 64, 65, 66], "potenti": [58, 60, 62, 64, 65, 66, 83, 84], "other": [46, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 79, 97], "purpos": [58, 60, 62, 64, 65, 66, 83, 84], "e": [48, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 76, 97], "g": [48, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 76, 97], "retrievaloutput": [71, 72, 73, 82], "helper": [46, 71, 86, 91, 93, 94], "provid": [43, 46, 59, 68, 69, 70, 71, 83, 84, 86, 91, 93, 94, 97], "standard": [46, 71, 86, 91, 93, 94], "wai": [46, 68, 69, 70, 71, 86, 91, 93, 94, 97], "inherit": [46, 59, 71, 86, 91, 93, 94], "relev": [71, 72, 73, 75], "corpu": [71, 72, 73], "queri": [45, 71, 72, 73], "batch_queri": [], "batch": [43, 45, 59, 68, 69, 70, 71, 72, 73, 97], "i": [42, 43, 59, 68, 69, 70, 71, 82, 83, 84, 89, 90, 97, 99], "handl": [59, 71], "rqa": [57, 71, 82], "dummyretriev": 71, "mock": 71, "test": 71, "_type_": [46, 48, 57, 60, 65, 71, 73, 75, 76, 82, 89, 90], "ani": [46, 59, 68, 69, 70, 76, 83, 84, 89, 90, 91, 93, 94, 97], "to_str": 75, "format": [58, 59, 60, 62, 64, 65, 66, 75], "string": [68, 69, 70, 75, 76, 83, 84, 97], "add_user_messag": [75, 81], "user_messag": 75, "add": [68, 69, 70, 75, 97], "messag": [75, 79, 81], "add_system_messag": [75, 81], "system_messag": 75, "store": 75, "": [50, 57, 59, 60, 64, 65, 66, 68, 69, 70, 72, 75, 89, 90, 97], "default_document_formatt": 76, "convert": [75, 76], "object": [43, 59, 68, 69, 70, 75, 76, 97], "util": [43, 47, 53, 59, 68, 69, 70, 76, 89, 90, 97, 99], "metadata": [76, 81], "field": 76, "repres": [43, 59, 75, 76], "chunk": 76, "text": [42, 45, 57, 65, 71, 72, 73, 76, 79, 84, 86, 87, 91, 93, 94], "along": [68, 69, 70, 76, 97], "its": [65, 76, 83, 84], "titl": [43, 76], "author": 76, "url": [64, 65, 66, 76], "callabl": [49, 59, 68, 69, 70, 89, 90, 97], "framework": [82, 99], "index": [43, 57, 73, 87, 99], "search": [45, 59, 99], "modelargu": 40, "model_name_or_path": [40, 59, 60], "fidtrainingarg": [40, 68], "reader_model_path": 40, "with_scor": 40, "bool": [40, 46, 57, 59, 64, 68, 69, 70, 79, 80, 81, 86, 87, 89, 90, 97], "text_maxlength": [40, 43], "int": [40, 46, 59, 66, 78, 80, 81, 83, 84, 86, 87], "n_context": [40, 43], "apply_question_mask": 40, "apply_passage_mask": 40, "extract_cl": [40, 68], "project": 40, "reader_temperatur": 40, "float": [40, 45, 86], "reader_batch_s": 40, "indexing_dimens": 40, "search_algo": 40, "replugtrainingarg": [40, 69], "lm_model_path": 40, "lm_temperatur": 40, "retrieve_temperatur": 40, "num_doc": 40, "refresh_step": 40, "dataargu": [40, 68, 69, 70], "pertain": 40, "what": [40, 46], "data": [40, 43, 68, 69, 70, 83, 84, 89, 90, 93, 94, 97], "we": [40, 60, 83, 84, 89, 90], "ar": [40, 59, 68, 69, 70, 82, 83, 84, 97], "go": 40, "input": [40, 42, 48, 59, 68, 69, 70, 86, 89, 90, 97], "our": [40, 42, 73, 76, 83, 84], "train": [40, 59, 68, 69, 70, 89, 90, 97], "eval": [40, 46, 68, 69, 70, 89, 90, 97], "train_fil": 40, "eval_fil": 40, "test_fil": 40, "full_dataset_file_path": 40, "contrasitivetrainingarg": [40, 70], "hard_neg_ratio": 40, "contrastive_loss": 40, "temperatur": [40, 84, 86], "retrievalqatrainingargu": [40, 68, 69, 70, 89, 90, 97], "transform": [40, 57, 59, 60, 68, 69, 70, 86, 89, 90, 97], "trainingargu": [40, 68, 69, 70, 97], "overrid": [40, 59, 68, 69, 70, 89, 90, 97], "some": [40, 59, 68, 69, 70, 97], "default": [40, 43, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 89, 90, 97], "output_dir": [40, 68, 69, 70, 97], "do_train": 40, "remove_unused_column": 40, "do_ev": 40, "learning_r": 40, "weight_decai": 40, "max_step": 40, "per_device_train_batch_s": 40, "per_device_eval_batch_s": 40, "warmup_ratio": 40, "gradient_checkpoint": 40, "lr_scheduler_typ": 40, "logging_step": 40, "eval_step": 40, "save_step": 40, "report_to": 40, "evaluation_strategi": 40, "metric_for_best_model": 40, "save_strategi": 40, "save_total_limit": 40, "seed": [40, 68, 69, 70, 87, 97], "write_predict": 40, "pooling_typ": [40, 45], "openai_model_nam": 42, "gpt": [42, 57], "4": [42, 59, 84], "1106": 42, "preview": [42, 83, 84], "3": [42, 57, 59], "5": [42, 57, 79, 87], "turbo": [42, 57], "embed": [42, 53, 57, 68, 69, 70, 71, 73, 87, 89, 90, 99], "ada": [42, 57, 73, 87], "002": [42, 57, 73, 87], "accelerationframework": 42, "enum": [42, 75, 80], "enumer": [42, 80], "deriv": [42, 80], "defin": [42, 68, 69, 70, 80, 97], "new": [42, 68, 69, 70, 79, 80, 97], "vllm": [42, 53, 57, 61], "tgi": [42, 53, 61], "sglang": [42, 53, 57, 61], "server_logdir": 42, "log": 42, "controller_heart_beat_expir": 42, "worker_heart_beat_interv": 42, "15": 42, "server_error_msg": 42, "network": 42, "error": [42, 59], "due": 42, "TO": 42, "high": 42, "traffic": 42, "pleas": [42, 59, 83, 84], "regener": [42, 79, 84], "OR": 42, "refresh": 42, "qa_moderation_msg": 42, "your": [42, 59, 65, 68, 69, 70, 83, 84, 89, 90, 97], "violat": [42, 83, 84], "moder": [42, 83, 84], "guidelin": 42, "try": 42, "again": [42, 68, 69, 70, 97], "qa_error_msg": 42, "sorri": 42, "encount": 42, "later": [42, 75], "contact": [42, 83, 84], "support": [42, 43, 60], "errorcod": 42, "intenum": 42, "http": [42, 59, 83, 84], "platform": 42, "openai": [42, 53, 57, 61, 83, 84], "com": [42, 83, 84], "doc": [42, 45, 58, 59, 60, 62, 64, 65, 66, 69, 89, 90, 93, 94], "guid": [42, 59], "code": [42, 59, 83, 84], "api": [42, 59, 84, 99], "validation_type_error": 42, "40001": 42, "invalid_auth_kei": 42, "40101": 42, "incorrect_auth_kei": 42, "40102": 42, "no_permiss": 42, "40103": 42, "invalid_model": 42, "40301": 42, "param_out_of_rang": 42, "40302": 42, "context_overflow": 42, "40303": 42, "rate_limit": 42, "42901": 42, "quota_exceed": 42, "42902": 42, "engine_overload": 42, "42903": 42, "internal_error": 42, "50001": 42, "cuda_out_of_memori": 42, "50002": 42, "gradio_request_error": 42, "50003": 42, "gradio_stream_unknown_error": 42, "50004": 42, "controller_no_work": 42, "50005": 42, "controller_worker_timeout": 42, "50006": 42, "noopdatacol": 43, "__call__": [43, 72], "featur": [43, 59, 68, 69, 70, 97], "contrastiveretrievaldataset": 43, "raw_data": 43, "start_data_idx": 43, "0": [43, 45, 48, 59, 79], "end_data_idx": 43, "none": [43, 46, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 73, 78, 86, 87, 89, 90, 95, 97], "document_fmt_str": 43, "shuffl": [43, 45], "torch": [43, 59, 68, 69, 70, 86, 89, 90, 97], "map": 43, "sampl": 43, "should": [43, 59, 68, 69, 70, 89, 90, 97], "subclass": [43, 68, 69, 70, 89, 90, 97], "overwrit": 43, "__getitem__": 43, "fetch": 43, "could": 43, "also": 43, "option": [43, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 89, 90, 97], "__len__": 43, "expect": [43, 68, 69, 70, 89, 90, 97], "size": [43, 59, 68, 69, 70, 97], "mani": 43, "sampler": 43, "implement": [43, 82], "dataload": [43, 68, 69, 70, 89, 90, 97], "__getitems__": 43, "speedup": 43, "load": [43, 59, 79, 81, 82, 93, 94], "accept": [43, 68, 69, 70, 89, 90, 97], "indic": [43, 59], "construct": 43, "yield": 43, "integr": 43, "To": 43, "work": [43, 59, 68, 69, 70, 89, 90, 97], "style": [43, 75], "non": [43, 83, 84], "custom": [43, 59, 68, 69, 70, 89, 90, 97], "must": [43, 59, 68, 69, 70, 83, 84, 93, 94, 97], "prepare_data": 43, "idx": [43, 81, 83, 84], "replugdataset": 43, "get_target": 43, "exampl": [43, 59, 68, 69, 70, 97], "fiddataset": 43, "score_kei": 43, "score": [43, 47, 48, 53, 59, 68], "question_prefix": 43, "title_prefix": 43, "passage_prefix": 43, "context": [43, 69], "sort_data": 43, "get_exampl": 43, "encode_passag": 43, "batch_text_passag": 43, "token": [43, 45, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 86, 89, 90, 97], "max_length": [43, 59, 60], "fidcol": 43, "answer_maxlength": 43, "20": 43, "load_fid_data": 43, "data_path": 43, "retrievercol": 43, "passage_maxlength": 43, "512": 43, "question_maxlength": 43, "barrier": 44, "get_rank": 44, "is_main": [44, 95], "batch_iter": [45, 97], "dset": [45, 97], "batch_siz": [45, 46, 59, 97], "drop_last": [45, 97], "mean_pool": 45, "token_embed": 45, "mask": [45, 59], "compute_embed": 45, "encoded_input": 45, "output": [45, 59, 68, 69, 70, 79, 86, 89, 90, 97], "embed_document_batch": 45, "8": 45, "devic": [45, 68, 69, 70, 83, 84, 86, 87, 97], "cuda": [45, 87], "to_list": [45, 75], "localembed": 45, "mean": [45, 48, 68, 69, 70, 97], "langchain": [45, 73, 76, 93], "interfac": [45, 59, 79], "embed_docu": 45, "emb": [45, 73], "embed_queri": 45, "evaluatorconfig": [46, 68, 69, 70, 89, 90, 97], "control": [46, 53, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 85, 97], "metric": [46, 47, 53, 68, 69, 70, 97], "comput": [46, 48, 59, 68, 69, 70, 83, 84, 89, 90, 97], "dure": [46, 89, 90], "well": 46, "relat": 46, "config": [46, 59], "retr_document_accuraci": 46, "retr_document_recal": 46, "retr_lat": 46, "gen_f1": 46, "gen_precis": 46, "gen_roug": 46, "gen_bleu": 46, "gen_lat": 46, "gen_answer_stat": 46, "gen_gpt4ev": 46, "e2e_lat": 46, "assistant_prefix": [46, 57, 60, 62, 64, 65, 66, 75, 87], "user_prefix": [46, 57, 60, 62, 64, 65, 66, 75, 87], "sep_us": [46, 57, 60, 62, 64, 65, 66, 75], "sep_si": [46, 57, 60, 62, 64, 65, 66, 75], "test_data": 46, "_get_data_iter": 46, "_flatten_perform": 46, "prefix": [46, 59], "metric_typ": 46, "wrapped_model": 46, "tupl": [46, 68, 69, 70, 89, 90, 97], "retrieverevalu": 46, "init_metr": 46, "reset_all_metr": 46, "compute_perform": 46, "e2eevalu": 46, "end": [46, 48, 89, 90], "accuraci": 46, "accurarci": 46, "l": 48, "runningmet": 48, "each": [48, 59, 68, 69, 70, 89, 90, 97], "bach": 48, "overal": 48, "veri": 48, "averag": [48, 59], "reset": [48, 59, 69, 79], "monitoringmetr": 48, "start": [48, 68, 69, 70, 79, 97], "record": 48, "someth": 48, "time": 48, "elaps": 48, "between": [48, 59, 69], "stop": [48, 59], "differ": [48, 68, 69, 70, 75, 97], "is_same_docu": 48, "retrieved_doc": [48, 82], "gold_doc": 48, "document_similar": 48, "src_doc": 48, "target_doc": 48, "is_almost_same_docu": 48, "threshold": 48, "7": 48, "documentaccuraci": 48, "name": [48, 68, 69, 70, 80, 97], "document_accuraci": 48, "batch_retrieved_doc": 48, "batch_gold_doc": 48, "documentrecal": 48, "document_recal": 48, "f1": [48, 49], "batch_gen_answ": 48, "batch_gold_answ": 48, "precis": [48, 49], "roug": [48, 49], "bleu": 48, "answerstat": 48, "answer_stat": 48, "gpt_eval_acc_prompt": 48, "gpt_eval_noans_acc_prompt": 48, "gpt4eval": 48, "use_gold_answ": 48, "_gener": [48, 64, 65, 66], "prompt": [48, 53, 55, 58, 59, 60, 61, 62, 64, 65, 66, 69, 79, 86], "judg": 48, "refer": [48, 99], "latenc": 48, "num_samples_seen": 48, "em": 49, "predict": [49, 68, 69, 70, 89, 90, 97], "ground_truth": 49, "normalize_fn": 49, "recal": 49, "rouge_wrapp": 49, "f1_score": 49, "lambda": 49, "x": 49, "exact_match_scor": 49, "rouge_scor": 49, "normalize_answ": 50, "constant": [53, 99], "dist_util": [53, 99], "with_retriever_fid_train": [53, 99], "supervised_train": [53, 99], "supervised_fid_train": [53, 99], "dataset": [53, 68, 69, 70, 89, 90, 97, 99], "with_retriever_train": [53, 99], "retriever_train": [53, 99], "retriever_fid_train": [53, 99], "retriever_replug_train": [53, 99], "fid": [53, 60, 61], "huggingfac": [53, 57, 61], "langchain_text_load": [53, 92], "llamaindex_text_load": [53, 92], "bm25_retriev": [53, 74], "faiss_retriev": [53, 68, 69, 70, 74, 97], "retriever_config": [53, 99], "serv": [53, 99], "base_model_work": [53, 85, 87], "cli": [53, 85], "gradio_dialogu": [53, 83, 84, 85], "gradio_rqa": [53, 85], "gradio_static_serv": [53, 85], "gradio_web_serv": [53, 85], "infer": [53, 57, 59, 65, 79, 85], "model_work": [53, 85], "test_messag": [53, 85], "static": [57, 59, 73, 75, 76], "from_huggingfac": 57, "qa_model": [57, 89, 90, 97], "automodelforcausallm": [57, 60], "qa_token": 57, "autotoken": [57, 59, 60], "qa_model_name_or_path": [57, 87], "qa_model_init_kwarg": 57, "assist": [57, 59, 60, 62, 64, 65, 66, 69, 75, 87], "initi": [57, 59, 73], "simpl": [57, 59, 68, 69, 70, 97], "alreadi": [57, 59], "from_huggingface_fid": 57, "fusion": [57, 59, 60], "decod": [57, 59, 60], "from_openai": 57, "qa_model_nam": 57, "from_vllm": 57, "qa_model_url": 57, "intial": 57, "llama": [57, 83, 84], "2": [57, 59, 86, 87], "from_tgi": 57, "host": [57, 65], "from_sglang": 57, "classmethod": [57, 80, 82], "from_scratch": [57, 82], "database_path": [57, 73, 87], "document_path": [57, 68, 69, 70, 73, 87, 97], "index_path": [57, 68, 69, 70, 73, 87], "embedding_model_name_or_path": [57, 87], "lmsy": [57, 79, 87], "vicuna": [57, 79, 87], "7b": [57, 79, 87], "v1": [57, 79, 87], "qa_is_fid": [57, 87], "is_api_model": [58, 64, 65, 66], "_prepare_question_w_doc": [58, 60, 62, 64, 65, 66], "chat": [58, 60, 62, 64, 65, 66, 69, 79], "requir": [58, 60, 62, 64, 65, 66, 83, 84], "gradio": [58, 60, 62, 64, 65, 66, 82, 83, 84], "demo": [58, 60, 62, 64, 65, 66, 83, 84], "fidt5": [59, 60], "t5forconditionalgener": 59, "weight": 59, "download": 59, "pretrain": 59, "forward_": 59, "forward": [59, 68, 69, 70, 97], "input_id": 59, "attention_mask": 59, "label": [59, 68, 69, 70, 81, 89, 90, 97], "longtensor": 59, "shape": 59, "classif": 59, "regress": 59, "loss": [59, 68, 69, 70, 89, 90, 97], "100": 59, "vocab_s": 59, "ignor": [59, 68, 69, 70, 89, 90, 97], "onli": [59, 60, 68, 69, 70, 83, 84, 89, 90, 97], "python": 59, "import": [59, 68, 69, 70, 97], "from_pretrain": 59, "t5": [59, 60, 79], "small": 59, "The": [59, 68, 69, 70, 83, 84, 89, 90, 97], "extra_id_0": 59, "walk": 59, "extra_id_1": 59, "park": 59, "return_tensor": 59, "pt": 59, "cute": 59, "dog": 59, "extra_id_2": 59, "logit": [59, 68, 69, 70, 89, 90, 97], "summar": 59, "studi": 59, "have": [59, 68, 69, 70, 97], "shown": 59, "own": [59, 68, 69, 70, 97], "good": 59, "print": [59, 86], "skip_special_token": 59, "true": [59, 64, 65, 66, 86, 95], "max_new_token": [59, 84, 86], "id": 59, "languag": 59, "head": 59, "tip": [59, 68, 69, 70, 97], "warn": 59, "most": [59, 68, 69, 70, 89, 90, 97], "generation_config": 59, "configur": 59, "correspond": [59, 93, 94], "num_beam": 59, "do_sampl": 59, "For": [59, 60, 68, 69, 70, 83, 84, 97], "overview": 59, "strategi": 59, "out": 59, "follow": [59, 69, 83, 84], "generation_strategi": 59, "tensor": [59, 68, 69, 70, 89, 90, 97], "vari": 59, "depend": 59, "modal": 59, "encod": 59, "If": [59, 68, 69, 70, 97], "bos_token_id": 59, "input_valu": 59, "input_featur": 59, "pixel_valu": 59, "generationconfig": 59, "parametr": 59, "match": 59, "attribut": [59, 68, 70, 97], "had": 59, "prioriti": 59, "json": [59, 79], "file": [59, 79, 93, 94], "exist": 59, "note": [59, 68, 69, 70, 75, 97], "unspecifi": 59, "valu": [59, 68, 69, 70, 83, 84, 97], "whose": 59, "parameter": 59, "logits_processor": 59, "logitsprocessorlist": [59, 86], "processor": 59, "complement": 59, "built": 59, "thrown": 59, "intend": [59, 83, 84], "advanc": 59, "stopping_criteria": 59, "stoppingcriterialist": 59, "criteria": 59, "sure": 59, "return_dict_in_gener": 59, "output_scor": 59, "prefix_allowed_tokens_fn": 59, "constraint": 59, "beam": 59, "allow": 59, "step": [59, 68, 69, 70, 89, 90, 97], "appli": 59, "batch_id": 59, "It": [59, 80, 83, 84], "ha": [59, 68, 69, 70, 97], "next": 59, "condit": 59, "previous": 59, "inputs_id": 59, "constrain": 59, "describ": 59, "autoregress": 59, "entiti": 59, "arxiv": [59, 83, 84], "org": [59, 83, 84], "ab": [59, 83, 84], "2010": 59, "00904": 59, "synced_gpu": 59, "whether": [59, 68, 69, 70, 84, 89, 90, 97], "continu": 59, "while": [59, 68, 69, 70, 97], "loop": [59, 68, 69, 70, 89, 90, 97], "until": 59, "unless": 59, "overridden": [59, 68, 69, 70, 97], "flag": [59, 83, 84], "under": [59, 65, 68, 69, 70, 89, 90, 97], "deepspe": [59, 68, 69, 70, 97], "zero": [59, 68, 69, 70, 97], "stage": 59, "multipl": 59, "gpu": [59, 68, 69, 70, 97], "environ": 59, "avoid": 59, "hang": 59, "one": [59, 68, 69, 70, 97], "finish": 59, "otherwis": [59, 68, 69, 70, 82, 97], "ll": 59, "assistant_model": 59, "pretrainedmodel": [59, 68, 69, 70, 89, 90, 97], "acceler": [59, 82], "exact": 59, "same": [59, 68, 69, 70, 97], "achiev": 59, "when": [59, 68, 69, 70, 89, 90, 97], "forecast": 59, "candid": 59, "much": 59, "faster": 59, "than": 59, "re": 59, "As": 59, "smaller": 59, "streamer": 59, "basestream": 59, "stream": [59, 64, 79, 86], "put": 59, "token_id": 59, "further": 59, "negative_prompt_id": 59, "sequence_length": 59, "neg": 59, "need": 59, "cfg": 59, "experiment": 59, "subject": [59, 83, 84], "break": 59, "chang": 59, "futur": [59, 83, 84], "version": 59, "negative_prompt_attention_mask": 59, "ad": [59, 75], "hoc": 59, "generate_config": 59, "addit": 59, "specif": 59, "decoder_": 59, "A": [59, 68, 69, 70, 80, 81, 87, 89, 90, 97], "modeloutput": 59, "floattensor": 59, "is_encoder_decod": 59, "possibl": 59, "greedysearchdecoderonlyoutput": 59, "sampledecoderonlyoutput": 59, "beamsearchdecoderonlyoutput": 59, "beamsampledecoderonlyoutput": 59, "greedysearchencoderdecoderoutput": 59, "sampleencoderdecoderoutput": 59, "beamsearchencoderdecoderoutput": 59, "beamsampleencoderdecoderoutput": 59, "wrap_encod": 59, "use_checkpoint": 59, "wrap": [59, 68, 69, 70, 97], "obtain": 59, "unwrap_encod": 59, "unwrap": 59, "load_t5": 59, "state_dict": [59, 68, 69, 70], "set_checkpoint": 59, "enabl": 59, "disabl": 59, "checkpoint": 59, "see": 59, "pytorch": [59, 68, 69, 70, 97], "stabl": 59, "html": 59, "reset_score_storag": 59, "storag": 59, "cross": 59, "attent": 59, "save": [59, 68, 69, 70, 79, 93, 94, 97], "get_crossattention_scor": 59, "context_mask": 59, "aggreg": 59, "singl": [59, 68, 69, 70, 75, 97], "scalar": 59, "per": 59, "passag": 59, "seen": 59, "similar": 59, "first": [59, 68, 69, 70, 75, 89, 90, 97], "over": 59, "layer": [59, 68, 69, 70, 97], "more": [59, 68, 69, 70, 97], "detail": [59, 68, 69, 70, 83, 84, 97], "distil": 59, "knowledg": 59, "reader": 59, "2012": 59, "04584": 59, "overwrite_forward_crossattent": 59, "replac": 59, "from_t5": 59, "encoderwrapp": 59, "nn": [59, 68, 69, 70, 89, 90, 97], "wrapper": [59, 82], "checkpointwrapp": 59, "empti": [59, 79], "hidden_st": 59, "position_bia": 59, "apply_checkpoint_wrapp": 59, "t5stack": 59, "cross_attention_forward": 59, "self": [59, 68, 69, 70, 97], "key_value_st": 59, "layer_head_mask": 59, "past_key_valu": 59, "use_cach": 59, "query_length": 59, "output_attent": 59, "huggingfaceqamodel": 60, "model_init_kwarg": 60, "simpli": 60, "_init": 60, "huggingfacefidqamodel": 60, "now": 60, "architectur": [60, 68, 69, 70, 97], "pack_fid_input": 60, "batched_fid_prompt": 60, "unpack_fid_input": 60, "encode_fid_input": 60, "batch_q_w_passag": 60, "openaiqamodel": 62, "model_nam": [62, 78, 80, 87], "rqa_prompt": 63, "rqa_prompt_train": 63, "sglangclient": 64, "timeout": [64, 66], "60": [64, 66], "_post_http_request": [64, 66], "gen_arg": [64, 66], "request": [64, 66, 78, 80, 83, 84], "_get_streaming_respons": [64, 66], "_get_respons": [64, 66], "input_text": [64, 65, 66, 82], "generate_stream": [64, 66, 82, 86, 87], "sglangqamodel": 64, "prepare_gen_kwarg": [64, 65, 66], "input_kwarg": [64, 65, 66], "_generate_stream": [64, 65, 66], "rqa_model": [64, 66], "tgiqamodel": 65, "hood": 65, "vllmclient": 66, "offset": 66, "vllmqamodel": 66, "prod_search_config": 67, "search_config": 67, "fidretrievertrain": 68, "modeling_util": [68, 69, 70, 89, 90, 97], "training_arg": [68, 69, 70], "data_arg": [68, 69, 70], "fid_arg": 68, "eval_config": [68, 69, 70, 89, 90, 97], "eval_search_kwarg": [68, 69, 70], "data_col": [68, 69, 70, 89, 90, 97], "datacol": [68, 69, 70, 89, 90, 97], "train_dataset": [68, 69, 70, 89, 90, 97], "eval_dataset": [68, 69, 70, 89, 90, 97], "tokenization_utils_bas": [68, 69, 70, 89, 90, 97], "pretrainedtokenizerbas": [68, 69, 70, 89, 90, 97], "model_init": [68, 69, 70, 89, 90, 97], "compute_metr": [68, 69, 70, 89, 90, 97], "trainer_util": [68, 69, 70, 89, 90, 97], "evalpredict": [68, 69, 70, 89, 90, 97], "callback": [68, 69, 70, 89, 90, 97], "trainer_callback": [68, 69, 70, 89, 90, 97], "trainercallback": [68, 69, 70, 89, 90, 97], "optim": [68, 69, 70, 83, 84, 89, 90, 97], "lr_schedul": [68, 69, 70, 89, 90, 97], "lambdalr": [68, 69, 70, 89, 90, 97], "preprocess_logits_for_metr": [68, 69, 70, 89, 90, 97], "complet": [68, 69, 70, 97], "librari": [68, 69, 70, 97], "still": [68, 69, 70, 97], "long": [68, 69, 70, 97], "thei": [68, 69, 70, 97], "tweak": [68, 69, 70, 97], "Will": [68, 69, 70, 97], "basic": [68, 69, 70, 97], "instanc": [68, 69, 70, 97], "directori": [68, 69, 70, 97], "tmp_trainer": [68, 69, 70, 97], "form": [68, 69, 70, 97], "element": [68, 69, 70, 89, 90, 97], "default_data_col": [68, 69, 70, 97], "datacollatorwithpad": [68, 69, 70, 97], "iterabledataset": [68, 69, 70, 97], "column": [68, 69, 70, 97], "automat": [68, 69, 70, 97], "remov": [68, 69, 70, 79, 97], "random": [68, 69, 70, 97], "distribut": [68, 69, 70, 80, 97], "fashion": [68, 69, 70, 97], "either": [68, 69, 70, 82, 97], "intern": [68, 69, 70, 97], "ident": [68, 69, 70, 97], "manual": [68, 69, 70, 97], "epoch": [68, 69, 70, 97], "set_epoch": [68, 69, 70, 97], "rng": [68, 69, 70, 97], "union": [68, 69, 70, 89, 90, 97], "dictionari": [68, 69, 70, 75, 76, 89, 90, 97], "prepend": [68, 69, 70, 97], "preprocess": [68, 69, 70, 97], "pad": [68, 69, 70, 97], "maximum": [68, 69, 70, 97], "length": [68, 69, 70, 97], "easier": [68, 69, 70, 97], "rerun": [68, 69, 70, 97], "interrupt": [68, 69, 70, 97], "reus": [68, 69, 70, 97], "fine": [68, 69, 70, 97], "tune": [68, 69, 70, 97], "instanti": [68, 69, 70, 97], "mai": [68, 69, 70, 75, 83, 84, 97], "optuna": [68, 69, 70, 97], "rai": [68, 69, 70, 97], "sigopt": [68, 69, 70, 97], "trial": [68, 69, 70, 97], "abl": [68, 69, 70, 97], "choos": [68, 69, 70, 97], "accord": [68, 69, 70, 97], "hyper": [68, 69, 70, 97], "count": [68, 69, 70, 97], "inner": [68, 69, 70, 97], "dropout": [68, 69, 70, 97], "probabl": [68, 69, 70, 97], "those": [68, 69, 70, 83, 84, 97], "here": [68, 69, 70, 97], "want": [68, 69, 70, 97], "remove_callback": [68, 69, 70, 97], "schedul": [68, 69, 70, 97], "adamw": [68, 69, 70, 97], "get_linear_schedule_with_warmup": [68, 69, 70, 97], "right": [68, 69, 70, 97], "cach": [68, 69, 70, 97], "two": [68, 69, 70, 75, 97], "onc": [68, 69, 70, 97], "desir": [68, 69, 70, 97], "modif": [68, 69, 70, 97], "made": [68, 69, 70, 97], "reflect": [68, 69, 70, 97], "receiv": [68, 69, 70, 97], "second": [68, 69, 70, 97], "doe": [68, 69, 70, 97], "alwai": [68, 69, 70, 97], "point": [68, 69, 70, 97], "core": [68, 69, 70, 97], "model_wrap": [68, 69, 70, 97], "extern": [68, 69, 70, 97], "case": [68, 69, 70, 97], "origin": [68, 69, 70, 97], "distributeddataparallel": [68, 69, 70, 97], "hasn": [68, 69, 70, 97], "t": [68, 69, 70, 97], "been": [68, 69, 70, 97], "is_model_parallel": [68, 69, 70, 97], "switch": [68, 69, 70, 97], "parallel": [68, 69, 70, 97], "mode": [68, 69, 70, 97], "split": [68, 69, 70, 93, 94, 97], "place_model_on_devic": [68, 69, 70, 97], "place": [68, 69, 70, 97], "is_in_train": [68, 69, 70, 97], "embed_text": 68, "text_id": 68, "text_mask": 68, "apply_mask": 68, "kldivloss": [68, 69], "gold_scor": 68, "compute_loss": [68, 69, 70, 89, 90, 97], "return_output": [68, 69, 70, 89, 90, 97], "how": [68, 69, 70, 89, 90, 97], "By": [68, 69, 70, 83, 84, 89, 90, 97], "behavior": [68, 69, 70, 89, 90, 97], "prediction_step": [68, 69, 70, 89, 90, 97], "prediction_loss_onli": [68, 69, 70, 89, 90, 97], "ignore_kei": [68, 69, 70, 89, 90, 97], "inject": [68, 69, 70, 89, 90, 97], "target": [68, 69, 70, 89, 90, 97], "unpack": [68, 69, 70, 89, 90, 97], "being": [68, 69, 70, 89, 90, 97], "fed": [68, 69, 70, 89, 90, 97], "gather": [68, 69, 70, 89, 90, 97], "wrap_model_for_ev": [68, 69, 70, 89, 90, 97], "faissretriev": [68, 69, 70, 73, 97], "_load_all_doc": [68, 69, 70, 97], "_load_eval_data": [68, 69, 70, 89, 90, 97], "eval_data_path": [68, 69, 70, 89, 90, 97], "evaluation_loop": [68, 69, 70, 89, 90, 97], "descript": [68, 69, 70, 89, 90, 97], "metric_key_prefix": [68, 69, 70, 89, 90, 97], "evalloopoutput": [68, 69, 70, 89, 90, 97], "share": [68, 69, 70, 83, 84, 89, 90, 97], "both": [68, 69, 70, 89, 90, 97], "without": [68, 69, 70, 89, 90, 97], "_save": [68, 69, 70], "ignore_token_id": 69, "red": 69, "x1b": 69, "91m": 69, "green": 69, "92m": 69, "0m": 69, "multilin": [69, 79, 83, 84], "show": [69, 83, 84], "curiou": 69, "artifici": 69, "intellig": 69, "give": 69, "help": [69, 83], "polit": 69, "do": 69, "mention": 69, "sinc": 69, "visibl": 69, "formatted_docu": 69, "formatted_chat": 69, "endoftext": 69, "replugretrievertrain": 69, "replug_arg": 69, "instruct": 69, "label_str": 69, "get_seq_prob": 69, "logit_scor": 69, "retrieve_scor": 69, "lm_score": 69, "pred": 69, "retrievertrain": 70, "contrastive_arg": 70, "_inbatch_contrastive_w_hardneg": 70, "normalize_str": 72, "bm25token": 72, "bm25retriev": 72, "openaiembed": 73, "prepare_docs_for_retriev": 73, "prepar": 73, "so": [73, 82], "faiss": 73, "would": 73, "recogn": 73, "fmt_content": [73, 76], "_init_retriev": 73, "retrieve_w_scor": 73, "from_disk": 73, "dialogueturn": 75, "source_docu": [75, 81], "speaker": 75, "represent": 75, "from_dict": [75, 76], "dialogue_turn_dict": 75, "to_dict": [75, 76, 81], "clone": [75, 76, 81], "separatorstyl": 75, "separ": 75, "speak": 75, "sep_styl": 75, "from_list": 75, "dialogue_list": 75, "page_cont": 76, "__post_init__": 76, "document_dict": 76, "from_langchain_doc": 76, "to_langchain_doc": 76, "worker": [78, 80, 87], "app": [78, 80], "heart_beat_work": 78, "obj": 78, "basemodelwork": [78, 87], "controller_addr": [78, 87], "worker_addr": [78, 87], "worker_id": [78, 87], "model_path": [78, 86], "limit_worker_concurr": [78, 87], "conv_templ": [78, 81, 86, 87], "init_heart_beat": 78, "register_to_control": 78, "send_heart_beat": 78, "get_queue_length": 78, "get_statu": 78, "count_token": 78, "param": [78, 80, 86, 87], "generate_stream_g": [78, 87], "generate_g": [78, 87], "release_worker_semaphor": 78, "acquire_worker_semaphor": 78, "create_background_task": 78, "async": [78, 80], "api_generate_stream": 78, "fastapi": [78, 80], "api_gener": 78, "api_retriev": 78, "api_get_statu": 78, "api_count_token": 78, "api_get_conv": 78, "api_model_detail": 78, "command": 79, "line": 79, "usag": 79, "python3": 79, "m": 79, "fastchat": [79, 86], "3b": 79, "exit": 79, "convers": [79, 81], "last": 79, "regen": 79, "filenam": [79, 95], "simplechatio": 79, "chatio": [79, 86], "prompt_for_input": [79, 86], "role": [79, 86], "prompt_for_output": [79, 86], "stream_output": [79, 86], "output_stream": [79, 86], "print_output": [79, 86], "richchatio": 79, "mous": 79, "bind": 79, "_": 79, "programmaticchatio": 79, "parser": [79, 83, 84, 87, 88], "manag": 80, "send": 80, "address": 80, "client": 80, "dispatchmethod": 80, "lotteri": 80, "shortest_queu": 80, "from_str": 80, "workerinfo": 80, "speed": 80, "queue_length": 80, "check_heart_beat": 80, "last_heart_beat": 80, "heart_beat_control": 80, "dispatch_method": 80, "register_work": 80, "worker_nam": 80, "worker_statu": 80, "get_worker_statu": 80, "remove_work": 80, "refresh_all_work": 80, "list_model": 80, "get_worker_address": 80, "receive_heart_beat": 80, "remove_stale_workers_by_expir": 80, "handle_no_work": 80, "handle_worker_timeout": 80, "worker_address": 80, "worker_api_get_statu": 80, "worker_api_generate_stream": 80, "worker_api_retriev": 80, "create_control": 80, "gradiodialoguesess": [81, 83, 84], "keep": [81, 83, 84], "_session": 81, "_tmp_data": 81, "skip_next": 81, "get_prompt": 81, "to_gradio_chatbot": 81, "conv_vicuna_v1": 81, "default_convers": 81, "annotationhistori": [81, 83], "data_file_path": 81, "empty_sess": 81, "annotation_kei": 81, "data_indic": 81, "parse_int_rang": 81, "_data_idx_filt": 81, "get_next_idx": 81, "get_prev_idx": 81, "get_current_idx": 81, "update_label": 81, "get_current_label": 81, "get_num_label": 81, "get_num_to_label": 81, "is_all_label": 81, "to_jsonl": 81, "gradiorqa": 82, "rephrase_question_for_retriev": 82, "get_model": 82, "get_token": 82, "generate_stream_from_api": 82, "NOT": 82, "local": 82, "just": 82, "prepare_prompt_for_gener": 82, "gradiosimplerqa": 82, "header": [83, 84], "argpars": [83, 84], "namespac": [83, 84], "no_change_btn": [83, 84], "enable_btn": [83, 84], "disable_btn": [83, 84], "num_doc_to_retriev": [83, 84], "ann_correct": 83, "correct": 83, "ann_incorrect": 83, "incorrect": 83, "ann_help": 83, "ann_not_help": 83, "ann_harm": 83, "harm": [83, 84], "ann_not_harm": 83, "harmless": 83, "get_conv_log_filenam": [83, 84], "document_view": [83, 84], "render_single_sess": 83, "render_next_sess": 83, "state": [83, 84], "submit_btn": 83, "render_prev_sess": 83, "vote_respons": 83, "radio_choic": 83, "vote_correct": 83, "vote_help": 83, "vote_harmless": 83, "load_demo": [83, 84], "dummy_st": 83, "url_param": [83, 84], "chatbot": 83, "save_annot": 83, "title_markdown": [83, 84], "localrqa": [83, 84], "github": [83, 84], "jasonyux": [83, 84], "xxxxx": [83, 84], "tos_markdown": [83, 84], "term": [83, 84], "servic": [83, 84], "agre": [83, 84], "research": [83, 84], "commerci": [83, 84], "limit": [83, 84], "measur": [83, 84], "offens": [83, 84], "illeg": [83, 84], "violent": [83, 84], "racist": [83, 84], "sexual": [83, 84], "collect": [83, 84], "click": [83, 84], "button": [83, 84], "get": [83, 84], "inappropri": [83, 84], "improv": [83, 84], "experi": [83, 84], "desktop": [83, 84], "mobil": [83, 84], "compromis": [83, 84], "qualiti": [83, 84], "learn_more_markdown": [83, 84], "licens": [83, 84], "facebookresearch": [83, 84], "blob": [83, 84], "model_card": [83, 84], "md": [83, 84], "polici": [83, 84], "privaci": [83, 84], "practic": [83, 84], "chrome": [83, 84], "googl": [83, 84], "webstor": [83, 84], "sharegpt": [83, 84], "chatg": [83, 84], "daiacboceoaocpibfodeljbdfacokfjb": [83, 84], "u": [83, 84], "find": [83, 84], "block_css": [83, 84], "block_j": [83, 84], "build_demo": [83, 84], "embed_mod": [83, 84], "violates_moder": 84, "get_model_list": 84, "load_demo_refresh_model_list": 84, "vote_last_respons": 84, "vote_typ": 84, "upvote_last_respons": 84, "downvote_last_respons": 84, "flag_last_respons": 84, "clear_histori": 84, "add_text": 84, "http_retriev": 84, "http_gener": 84, "top_p": [84, 86], "prepare_logits_processor": 86, "repetition_penalti": 86, "top_k": 86, "logits_process": 86, "context_len": 86, "stream_interv": [86, 87], "judge_sent_end": 86, "chat_loop": 86, "num_gpu": 86, "max_gpu_memori": 86, "dtype": 86, "load_8bit": [86, 87], "cpu_offload": 86, "conv_system_msg": 86, "gptq_config": 86, "gptq": 86, "gptqconfig": 86, "awq_config": 86, "awq": 86, "awqconfig": 86, "exllama_config": 86, "exllama": 86, "exllamaconfig": 86, "xft_config": 86, "xfastertransform": 86, "xftconfig": 86, "revis": 86, "debug": [86, 87], "execut": 87, "load_model": 87, "load_4bit": 87, "device_map": 87, "add_model_arg": 87, "modelwork": 87, "no_regist": 87, "embed_in_trunc": 87, "create_model_work": 87, "supervisedfidtrain": 89, "train_arg": [89, 90, 97], "eval_retriev": [89, 90], "equival": [89, 90], "fix": [89, 90], "includ": [89, 90], "gold": [89, 90], "choic": [89, 90], "supervisedtrain": 90, "basetextload": [91, 93, 94], "load_data": [91, 93, 94], "save_text": [91, 93, 94], "_convert_doc": 91, "langchaintextload": 93, "save_fold": [93, 94], "save_filenam": [93, 94], "parsed_doc": [93, 94], "loader_func": [93, 94], "directoryload": 93, "splitter_func": 93, "charactertextsplitt": 93, "text_splitt": 93, "specifi": [93, 94], "valueerror": [93, 94], "loader_param": [93, 94], "splitter_param": 93, "loader_funct": [93, 94], "splitter_funct": 93, "pickl": [93, 94], "loader_paramet": 93, "llamaindextextload": 94, "simpledirectoryread": 94, "init_logg": 95, "is_distribut": 95, "create_dir_if_not_exist": 95, "path": 95, "remove_optimizer_weight": 95, "save_dir": 95, "fixedretrievertrain": 97, "retriever_model": 97, "eval_wrapper_class": 97}, "objects": {"": [[40, 0, 0, "-", "arguments"], [41, 0, 0, "-", "base"], [42, 0, 0, "-", "constants"], [43, 0, 0, "-", "datasets"], [44, 0, 0, "-", "dist_utils"], [45, 0, 0, "-", "embeddings"], [47, 0, 0, "-", "evaluation"], [52, 0, 0, "-", "guardrails"], [98, 0, 0, "-", "open_rqa"], [55, 0, 0, "-", "pipelines"], [61, 0, 0, "-", "qa_llms"], [67, 0, 0, "-", "retriever_config"], [68, 0, 0, "-", "retriever_fid_trainer"], [69, 0, 0, "-", "retriever_replug_trainer"], [70, 0, 0, "-", "retriever_trainer"], [74, 0, 0, "-", "retrievers"], [77, 0, 0, "-", "schema"], [85, 0, 0, "-", "serve"], [89, 0, 0, "-", "supervised_fid_trainer"], [90, 0, 0, "-", "supervised_trainer"], [92, 0, 0, "-", "text_loaders"], [95, 0, 0, "-", "utils"], [96, 0, 0, "-", "with_retriever_fid_trainer"], [97, 0, 0, "-", "with_retriever_trainer"]], "arguments": [[40, 1, 1, "", "ContrasitiveTrainingArgs"], [40, 1, 1, "", "DataArguments"], [40, 1, 1, "", "FidTrainingArgs"], [40, 1, 1, "", "ModelArguments"], [40, 1, 1, "", "ReplugTrainingArgs"], [40, 1, 1, "", "RetrievalQATrainingArguments"]], "arguments.ContrasitiveTrainingArgs": [[40, 2, 1, "", "contrastive_loss"], [40, 2, 1, "", "hard_neg_ratio"], [40, 2, 1, "", "search_algo"], [40, 2, 1, "", "temperature"]], "arguments.DataArguments": [[40, 2, 1, "", "eval_file"], [40, 2, 1, "", "full_dataset_file_path"], [40, 2, 1, "", "test_file"], [40, 2, 1, "", "train_file"]], "arguments.FidTrainingArgs": [[40, 2, 1, "", "apply_passage_mask"], [40, 2, 1, "", "apply_question_mask"], [40, 2, 1, "", "extract_cls"], [40, 2, 1, "", "indexing_dimension"], [40, 2, 1, "", "n_context"], [40, 2, 1, "", "projection"], [40, 2, 1, "", "reader_batch_size"], [40, 2, 1, "", "reader_model_path"], [40, 2, 1, "", "reader_temperature"], [40, 2, 1, "", "search_algo"], [40, 2, 1, "", "text_maxlength"], [40, 2, 1, "", "with_score"]], "arguments.ModelArguments": [[40, 2, 1, "", "model_name_or_path"]], "arguments.ReplugTrainingArgs": [[40, 2, 1, "", "lm_model_path"], [40, 2, 1, "", "lm_temperature"], [40, 2, 1, "", "num_docs"], [40, 2, 1, "", "refresh_step"], [40, 2, 1, "", "retrieve_temperature"], [40, 2, 1, "", "search_algo"], [40, 2, 1, "", "text_maxlength"]], "arguments.RetrievalQATrainingArguments": [[40, 2, 1, "", "do_eval"], [40, 2, 1, "", "do_train"], [40, 2, 1, "", "eval_steps"], [40, 2, 1, "", "evaluation_strategy"], [40, 2, 1, "", "gradient_checkpointing"], [40, 2, 1, "", "learning_rate"], [40, 2, 1, "", "logging_steps"], [40, 2, 1, "", "lr_scheduler_type"], [40, 2, 1, "", "max_steps"], [40, 2, 1, "", "metric_for_best_model"], [40, 2, 1, "", "output_dir"], [40, 2, 1, "", "per_device_eval_batch_size"], [40, 2, 1, "", "per_device_train_batch_size"], [40, 2, 1, "", "pooling_type"], [40, 2, 1, "", "remove_unused_columns"], [40, 2, 1, "", "report_to"], [40, 2, 1, "", "save_steps"], [40, 2, 1, "", "save_strategy"], [40, 2, 1, "", "save_total_limit"], [40, 2, 1, "", "seed"], [40, 2, 1, "", "warmup_ratio"], [40, 2, 1, "", "weight_decay"], [40, 2, 1, "", "write_predictions"]], "base": [[41, 1, 1, "", "Component"], [41, 4, 1, "", "logger"]], "base.Component": [[41, 3, 1, "", "run"], [41, 2, 1, "", "run_input_keys"]], "constants": [[42, 1, 1, "", "AccelerationFramework"], [42, 4, 1, "", "CONTROLLER_HEART_BEAT_EXPIRATION"], [42, 1, 1, "", "ErrorCode"], [42, 4, 1, "", "OPENAI_MODEL_NAMES"], [42, 4, 1, "", "QA_ERROR_MSG"], [42, 4, 1, "", "QA_MODERATION_MSG"], [42, 4, 1, "", "SERVER_ERROR_MSG"], [42, 4, 1, "", "SERVER_LOGDIR"], [42, 4, 1, "", "WORKER_HEART_BEAT_INTERVAL"]], "constants.AccelerationFramework": [[42, 2, 1, "", "SGLANG"], [42, 2, 1, "", "TGI"], [42, 2, 1, "", "VLLM"]], "constants.ErrorCode": [[42, 2, 1, "", "CONTEXT_OVERFLOW"], [42, 2, 1, "", "CONTROLLER_NO_WORKER"], [42, 2, 1, "", "CONTROLLER_WORKER_TIMEOUT"], [42, 2, 1, "", "CUDA_OUT_OF_MEMORY"], [42, 2, 1, "", "ENGINE_OVERLOADED"], [42, 2, 1, "", "GRADIO_REQUEST_ERROR"], [42, 2, 1, "", "GRADIO_STREAM_UNKNOWN_ERROR"], [42, 2, 1, "", "INCORRECT_AUTH_KEY"], [42, 2, 1, "", "INTERNAL_ERROR"], [42, 2, 1, "", "INVALID_AUTH_KEY"], [42, 2, 1, "", "INVALID_MODEL"], [42, 2, 1, "", "NO_PERMISSION"], [42, 2, 1, "", "PARAM_OUT_OF_RANGE"], [42, 2, 1, "", "QUOTA_EXCEEDED"], [42, 2, 1, "", "RATE_LIMIT"], [42, 2, 1, "", "VALIDATION_TYPE_ERROR"]], "datasets": [[43, 1, 1, "", "ContrastiveRetrievalDataset"], [43, 1, 1, "", "FidCollator"], [43, 1, 1, "", "FidDataset"], [43, 1, 1, "", "NoopDataCollator"], [43, 1, 1, "", "ReplugDataset"], [43, 1, 1, "", "RetrieverCollator"], [43, 5, 1, "", "encode_passages"], [43, 5, 1, "", "load_fid_data"]], "datasets.ContrastiveRetrievalDataset": [[43, 3, 1, "", "__getitem__"], [43, 3, 1, "", "__len__"], [43, 3, 1, "", "prepare_data"]], "datasets.FidCollator": [[43, 3, 1, "", "__call__"]], "datasets.FidDataset": [[43, 3, 1, "", "__getitem__"], [43, 3, 1, "", "__len__"], [43, 3, 1, "", "get_example"], [43, 3, 1, "", "get_target"], [43, 3, 1, "", "sort_data"]], "datasets.NoopDataCollator": [[43, 3, 1, "", "__call__"]], "datasets.ReplugDataset": [[43, 3, 1, "", "__getitem__"], [43, 3, 1, "", "__len__"], [43, 3, 1, "", "get_target"]], "datasets.RetrieverCollator": [[43, 3, 1, "", "__call__"]], "dist_utils": [[44, 5, 1, "", "barrier"], [44, 5, 1, "", "get_rank"], [44, 5, 1, "", "is_main"]], "embeddings": [[45, 1, 1, "", "LocalEmbeddings"], [45, 5, 1, "", "batch_iterator"], [45, 5, 1, "", "compute_embedding"], [45, 5, 1, "", "embed_document_batch"], [45, 4, 1, "", "logger"], [45, 5, 1, "", "mean_pooling"]], "embeddings.LocalEmbeddings": [[45, 3, 1, "", "embed_documents"], [45, 3, 1, "", "embed_query"]], "evaluation": [[46, 0, 0, "-", "evaluator"], [48, 0, 0, "-", "metrics"], [49, 0, 0, "-", "scores"], [50, 0, 0, "-", "utils"]], "evaluation.evaluator": [[46, 1, 1, "", "E2EEvaluator"], [46, 1, 1, "", "Evaluator"], [46, 1, 1, "", "EvaluatorConfig"], [46, 1, 1, "", "RetrieverEvaluator"]], "evaluation.evaluator.E2EEvaluator": [[46, 3, 1, "", "compute_performance"], [46, 3, 1, "", "evaluate"], [46, 3, 1, "", "init_metrics"], [46, 3, 1, "", "reset_all_metrics"]], "evaluation.evaluator.Evaluator": [[46, 3, 1, "", "_flatten_performance"], [46, 3, 1, "", "_get_data_iterator"], [46, 3, 1, "", "evaluate"]], "evaluation.evaluator.EvaluatorConfig": [[46, 2, 1, "", "assistant_prefix"], [46, 2, 1, "", "batch_size"], [46, 2, 1, "", "e2e_latency"], [46, 2, 1, "", "gen_answer_stats"], [46, 2, 1, "", "gen_bleu"], [46, 2, 1, "", "gen_f1"], [46, 2, 1, "", "gen_gpt4eval"], [46, 2, 1, "", "gen_latency"], [46, 2, 1, "", "gen_precision"], [46, 2, 1, "", "gen_rouge"], [46, 2, 1, "", "retr_document_accuracy"], [46, 2, 1, "", "retr_document_recall"], [46, 2, 1, "", "retr_latency"], [46, 2, 1, "", "sep_sys"], [46, 2, 1, "", "sep_user"], [46, 2, 1, "", "user_prefix"]], "evaluation.evaluator.RetrieverEvaluator": [[46, 3, 1, "", "compute_performance"], [46, 3, 1, "", "evaluate"], [46, 3, 1, "", "init_metrics"], [46, 3, 1, "", "reset_all_metrics"]], "evaluation.metrics": [[48, 1, 1, "", "AnswerStats"], [48, 1, 1, "", "BLEU"], [48, 1, 1, "", "DocumentAccuracy"], [48, 1, 1, "", "DocumentRecall"], [48, 1, 1, "", "F1"], [48, 1, 1, "", "GPT4Eval"], [48, 4, 1, "", "GPT_EVAL_ACC_PROMPT"], [48, 4, 1, "", "GPT_EVAL_NOANS_ACC_PROMPT"], [48, 1, 1, "", "Latency"], [48, 4, 1, "", "METRICS"], [48, 1, 1, "", "MonitoringMetric"], [48, 1, 1, "", "Precision"], [48, 1, 1, "", "ROUGE"], [48, 1, 1, "", "RunningMetic"], [48, 5, 1, "", "document_similarity"], [48, 5, 1, "", "is_almost_same_document"], [48, 5, 1, "", "is_same_document"], [48, 4, 1, "", "logger"], [48, 5, 1, "", "mean"]], "evaluation.metrics.AnswerStats": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.BLEU": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.DocumentAccuracy": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.DocumentRecall": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.F1": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.GPT4Eval": [[48, 3, 1, "", "_generate"], [48, 3, 1, "", "compute"], [48, 3, 1, "", "judge"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.Latency": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "start"], [48, 3, 1, "", "stop"]], "evaluation.metrics.MonitoringMetric": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "start"], [48, 3, 1, "", "stop"]], "evaluation.metrics.Precision": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.ROUGE": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.metrics.RunningMetic": [[48, 3, 1, "", "compute"], [48, 3, 1, "", "reset"], [48, 3, 1, "", "update"]], "evaluation.scores": [[49, 5, 1, "", "em"], [49, 5, 1, "", "exact_match_score"], [49, 5, 1, "", "f1"], [49, 5, 1, "", "f1_score"], [49, 5, 1, "", "precision"], [49, 5, 1, "", "recall"], [49, 4, 1, "", "rouge"], [49, 5, 1, "", "rouge_score"], [49, 5, 1, "", "rouge_wrapper"]], "evaluation.utils": [[50, 5, 1, "", "normalize_answer"]], "guardrails": [[51, 0, 0, "-", "base"]], "guardrails.base": [[51, 1, 1, "", "BaseAnswerGuardrail"], [51, 1, 1, "", "NoopAnswerGuardrail"]], "guardrails.base.BaseAnswerGuardrail": [[51, 3, 1, "", "guardrail"], [51, 3, 1, "", "run"], [51, 2, 1, "", "run_input_keys"]], "guardrails.base.NoopAnswerGuardrail": [[51, 3, 1, "", "guardrail"]], "open_rqa": [[1, 0, 0, "-", "base"], [2, 0, 0, "-", "constants"], [3, 0, 0, "-", "evaluation"], [7, 0, 0, "-", "guardrails"], [9, 0, 0, "-", "pipelines"], [13, 0, 0, "-", "qa_llms"], [22, 0, 0, "-", "retrievers"], [24, 0, 0, "-", "schema"], [27, 0, 0, "-", "serve"], [31, 0, 0, "-", "text_loaders"], [35, 0, 0, "-", "trainers"], [38, 0, 0, "-", "utils"], [39, 0, 0, "-", "vectorstore"]], "open_rqa.evaluation": [[4, 0, 0, "-", "metrics"], [5, 0, 0, "-", "scores"], [6, 0, 0, "-", "utils"]], "open_rqa.guardrails": [[8, 0, 0, "-", "base"]], "open_rqa.pipelines": [[10, 0, 0, "-", "base"], [11, 0, 0, "-", "prompts"]], "open_rqa.qa_llms": [[14, 0, 0, "-", "base"], [15, 0, 0, "-", "fid"], [16, 0, 0, "-", "huggingface"], [17, 0, 0, "-", "openai"], [18, 0, 0, "-", "prompts"], [19, 0, 0, "-", "sglang"], [20, 0, 0, "-", "tgi"], [21, 0, 0, "-", "vllm"]], "open_rqa.retrievers": [[23, 0, 0, "-", "base"]], "open_rqa.schema": [[25, 0, 0, "-", "dialogue"], [26, 0, 0, "-", "document"]], "open_rqa.serve": [[28, 0, 0, "-", "base_model_worker"], [29, 0, 0, "-", "gradio_dialogue"], [30, 0, 0, "-", "test_message"]], "open_rqa.text_loaders": [[32, 0, 0, "-", "base"], [33, 0, 0, "-", "langchain_text_loader"], [34, 0, 0, "-", "llamaindex_text_loader"]], "open_rqa.trainers": [[36, 0, 0, "-", "dist_utils"], [37, 0, 0, "-", "utils"]], "pipelines": [[54, 0, 0, "-", "base"], [56, 0, 0, "-", "prompts"], [57, 0, 0, "-", "retrieval_qa"]], "pipelines.base": [[54, 1, 1, "", "RQAPipeline"], [54, 4, 1, "", "logger"]], "pipelines.base.RQAPipeline": [[54, 3, 1, "", "_prepare_input"], [54, 3, 1, "", "components"], [54, 3, 1, "", "qa"], [54, 3, 1, "", "run"], [54, 2, 1, "", "run_input_keys"], [54, 3, 1, "", "update_dialogue_session"]], "pipelines.prompts": [[56, 4, 1, "", "REPHRASE_QUESTION_PROMPT"]], "pipelines.retrieval_qa": [[57, 1, 1, "", "AutoRQA"], [57, 1, 1, "", "BaseRQA"], [57, 1, 1, "", "SimpleRQA"], [57, 4, 1, "", "logger"]], "pipelines.retrieval_qa.SimpleRQA": [[57, 3, 1, "", "_batch_generate"], [57, 3, 1, "", "_rephrase_questions"], [57, 3, 1, "", "from_huggingface"], [57, 3, 1, "", "from_huggingface_fid"], [57, 3, 1, "", "from_openai"], [57, 3, 1, "", "from_scratch"], [57, 3, 1, "", "from_sglang"], [57, 3, 1, "", "from_tgi"], [57, 3, 1, "", "from_vllm"], [57, 3, 1, "", "qa"], [57, 3, 1, "", "rephrase_questions"]], "qa_llms": [[58, 0, 0, "-", "base"], [59, 0, 0, "-", "fid"], [60, 0, 0, "-", "huggingface"], [62, 0, 0, "-", "openai"], [63, 0, 0, "-", "prompts"], [64, 0, 0, "-", "sglang"], [65, 0, 0, "-", "tgi"], [66, 0, 0, "-", "vllm"]], "qa_llms.base": [[58, 1, 1, "", "BaseQAModel"], [58, 1, 1, "", "GenerationOutput"]], "qa_llms.base.BaseQAModel": [[58, 3, 1, "", "_prepare_question_w_docs"], [58, 3, 1, "", "generate"], [58, 2, 1, "", "is_api_model"], [58, 3, 1, "", "r_generate"], [58, 3, 1, "", "run"], [58, 2, 1, "", "run_input_keys"]], "qa_llms.base.GenerationOutput": [[58, 2, 1, "", "batch_answers"]], "qa_llms.fid": [[59, 1, 1, "", "CheckpointWrapper"], [59, 1, 1, "", "EncoderWrapper"], [59, 1, 1, "", "FiDT5"], [59, 5, 1, "", "apply_checkpoint_wrapper"], [59, 5, 1, "", "cross_attention_forward"]], "qa_llms.fid.CheckpointWrapper": [[59, 3, 1, "", "forward"]], "qa_llms.fid.EncoderWrapper": [[59, 3, 1, "", "forward"]], "qa_llms.fid.FiDT5": [[59, 3, 1, "", "forward"], [59, 3, 1, "", "forward_"], [59, 3, 1, "", "from_t5"], [59, 3, 1, "", "generate"], [59, 3, 1, "", "get_crossattention_scores"], [59, 3, 1, "", "load_t5"], [59, 3, 1, "", "overwrite_forward_crossattention"], [59, 3, 1, "", "reset_score_storage"], [59, 3, 1, "", "set_checkpoint"], [59, 3, 1, "", "unwrap_encoder"], [59, 3, 1, "", "wrap_encoder"]], "qa_llms.huggingface": [[60, 1, 1, "", "HuggingFaceFiDQAModel"], [60, 1, 1, "", "HuggingFaceQAModel"]], "qa_llms.huggingface.HuggingFaceFiDQAModel": [[60, 3, 1, "", "_init"], [60, 3, 1, "", "_prepare_question_w_docs"], [60, 3, 1, "", "encode_fid_inputs"], [60, 3, 1, "", "generate"], [60, 3, 1, "", "pack_fid_inputs"], [60, 3, 1, "", "r_generate"], [60, 3, 1, "", "unpack_fid_inputs"]], "qa_llms.huggingface.HuggingFaceQAModel": [[60, 3, 1, "", "_init"], [60, 3, 1, "", "_prepare_question_w_docs"], [60, 3, 1, "", "generate"], [60, 3, 1, "", "r_generate"]], "qa_llms.openai": [[62, 1, 1, "", "OpenAIQAModel"]], "qa_llms.openai.OpenAIQAModel": [[62, 3, 1, "", "_prepare_question_w_docs"], [62, 3, 1, "", "generate"], [62, 3, 1, "", "r_generate"]], "qa_llms.prompts": [[63, 4, 1, "", "RQA_PROMPT"], [63, 4, 1, "", "RQA_PROMPT_TRAIN"]], "qa_llms.sglang": [[64, 1, 1, "", "SGLangClient"], [64, 1, 1, "", "SGLangQAModel"], [64, 4, 1, "", "logger"], [64, 4, 1, "", "rqa_model"]], "qa_llms.sglang.SGLangClient": [[64, 3, 1, "", "_get_response"], [64, 3, 1, "", "_get_streaming_response"], [64, 3, 1, "", "_post_http_request"], [64, 3, 1, "", "generate"], [64, 3, 1, "", "generate_stream"]], "qa_llms.sglang.SGLangQAModel": [[64, 3, 1, "", "_generate"], [64, 3, 1, "", "_generate_stream"], [64, 3, 1, "", "_prepare_question_w_docs"], [64, 3, 1, "", "generate"], [64, 2, 1, "", "is_api_model"], [64, 3, 1, "", "prepare_gen_kwargs"], [64, 3, 1, "", "r_generate"]], "qa_llms.tgi": [[65, 1, 1, "", "TGIQAModel"], [65, 4, 1, "", "logger"]], "qa_llms.tgi.TGIQAModel": [[65, 3, 1, "", "_generate"], [65, 3, 1, "", "_generate_stream"], [65, 3, 1, "", "_prepare_question_w_docs"], [65, 3, 1, "", "generate"], [65, 2, 1, "", "is_api_model"], [65, 3, 1, "", "prepare_gen_kwargs"], [65, 3, 1, "", "r_generate"]], "qa_llms.vllm": [[66, 1, 1, "", "VLLMClient"], [66, 4, 1, "", "logger"], [66, 4, 1, "", "rqa_model"], [66, 1, 1, "", "vLLMQAModel"]], "qa_llms.vllm.VLLMClient": [[66, 3, 1, "", "_get_response"], [66, 3, 1, "", "_get_streaming_response"], [66, 3, 1, "", "_post_http_request"], [66, 3, 1, "", "generate"], [66, 3, 1, "", "generate_stream"]], "qa_llms.vllm.vLLMQAModel": [[66, 3, 1, "", "_generate"], [66, 3, 1, "", "_generate_stream"], [66, 3, 1, "", "_prepare_question_w_docs"], [66, 3, 1, "", "generate"], [66, 2, 1, "", "is_api_model"], [66, 3, 1, "", "prepare_gen_kwargs"], [66, 3, 1, "", "r_generate"]], "retriever_config": [[67, 4, 1, "", "PROD_SEARCH_CONFIG"], [67, 4, 1, "", "SEARCH_CONFIG"]], "retriever_fid_trainer": [[68, 1, 1, "", "FidRetrieverTrainer"]], "retriever_fid_trainer.FidRetrieverTrainer": [[68, 3, 1, "", "_load_all_docs"], [68, 3, 1, "", "_load_eval_data"], [68, 3, 1, "", "_save"], [68, 3, 1, "", "compute_loss"], [68, 3, 1, "", "embed_text"], [68, 3, 1, "", "evaluation_loop"], [68, 3, 1, "", "kldivloss"], [68, 3, 1, "", "prediction_step"], [68, 3, 1, "", "wrap_model_for_eval"]], "retriever_replug_trainer": [[69, 4, 1, "", "GREEN"], [69, 4, 1, "", "IGNORE_TOKEN_ID"], [69, 4, 1, "", "PROMPT"], [69, 4, 1, "", "RED"], [69, 4, 1, "", "RESET"], [69, 1, 1, "", "ReplugRetrieverTrainer"]], "retriever_replug_trainer.ReplugRetrieverTrainer": [[69, 3, 1, "", "_load_all_docs"], [69, 3, 1, "", "_load_eval_data"], [69, 3, 1, "", "_save"], [69, 3, 1, "", "compute_loss"], [69, 3, 1, "", "evaluation_loop"], [69, 3, 1, "", "get_seq_prob"], [69, 3, 1, "", "instruct"], [69, 3, 1, "", "kldivloss"], [69, 3, 1, "", "prediction_step"], [69, 3, 1, "", "wrap_model_for_eval"]], "retriever_trainer": [[70, 1, 1, "", "RetrieverTrainer"]], "retriever_trainer.RetrieverTrainer": [[70, 3, 1, "", "_inbatch_contrastive_w_hardneg"], [70, 3, 1, "", "_load_all_docs"], [70, 3, 1, "", "_load_eval_data"], [70, 3, 1, "", "_save"], [70, 3, 1, "", "compute_loss"], [70, 3, 1, "", "evaluation_loop"], [70, 3, 1, "", "prediction_step"], [70, 3, 1, "", "wrap_model_for_eval"]], "retrievers": [[71, 0, 0, "-", "base"], [72, 0, 0, "-", "bm25_retriever"], [73, 0, 0, "-", "faiss_retriever"]], "retrievers.base": [[71, 1, 1, "", "BaseRetriever"], [71, 1, 1, "", "DummyRetriever"], [71, 1, 1, "", "RetrievalOutput"]], "retrievers.base.BaseRetriever": [[71, 3, 1, "", "retrieve"], [71, 3, 1, "", "run"], [71, 2, 1, "", "run_input_keys"]], "retrievers.base.DummyRetriever": [[71, 3, 1, "", "retrieve"]], "retrievers.base.RetrievalOutput": [[71, 2, 1, "", "batch_source_documents"]], "retrievers.bm25_retriever": [[72, 1, 1, "", "BM25Retriever"], [72, 1, 1, "", "BM25Tokenizer"], [72, 5, 1, "", "normalize_string"]], "retrievers.bm25_retriever.BM25Retriever": [[72, 3, 1, "", "retrieve"]], "retrievers.bm25_retriever.BM25Tokenizer": [[72, 3, 1, "", "__call__"]], "retrievers.faiss_retriever": [[73, 1, 1, "", "FaissRetriever"], [73, 4, 1, "", "logger"]], "retrievers.faiss_retriever.FaissRetriever": [[73, 3, 1, "", "_init_retriever"], [73, 3, 1, "", "from_disk"], [73, 3, 1, "", "prepare_docs_for_retrieval"], [73, 3, 1, "", "retrieve"], [73, 3, 1, "", "retrieve_w_score"]], "schema": [[75, 0, 0, "-", "dialogue"], [76, 0, 0, "-", "document"]], "schema.dialogue": [[75, 1, 1, "", "DialogueSession"], [75, 1, 1, "", "DialogueTurn"], [75, 1, 1, "", "RQAOutput"], [75, 1, 1, "", "SeparatorStyle"]], "schema.dialogue.DialogueSession": [[75, 3, 1, "", "add_system_message"], [75, 3, 1, "", "add_user_message"], [75, 2, 1, "", "assistant_prefix"], [75, 3, 1, "", "clone"], [75, 3, 1, "", "from_list"], [75, 2, 1, "", "history"], [75, 2, 1, "", "sep_style"], [75, 2, 1, "", "sep_sys"], [75, 2, 1, "", "sep_user"], [75, 3, 1, "", "to_list"], [75, 3, 1, "", "to_string"], [75, 2, 1, "", "user_prefix"]], "schema.dialogue.DialogueTurn": [[75, 3, 1, "", "clone"], [75, 3, 1, "", "from_dict"], [75, 2, 1, "", "message"], [75, 2, 1, "", "source_documents"], [75, 2, 1, "", "speaker"], [75, 3, 1, "", "to_dict"], [75, 3, 1, "", "to_string"]], "schema.dialogue.RQAOutput": [[75, 2, 1, "", "batch_answers"], [75, 2, 1, "", "batch_dialogue_session"], [75, 2, 1, "", "batch_source_documents"]], "schema.dialogue.SeparatorStyle": [[75, 2, 1, "", "SINGLE"], [75, 2, 1, "", "TWO"]], "schema.document": [[76, 1, 1, "", "Document"], [76, 5, 1, "", "default_document_formatter"]], "schema.document.Document": [[76, 3, 1, "", "__post_init__"], [76, 3, 1, "", "clone"], [76, 2, 1, "", "fmt_content"], [76, 3, 1, "", "from_dict"], [76, 3, 1, "", "from_langchain_doc"], [76, 2, 1, "", "metadata"], [76, 2, 1, "", "page_content"], [76, 3, 1, "", "to_dict"], [76, 3, 1, "", "to_langchain_doc"]], "serve": [[78, 0, 0, "-", "base_model_worker"], [79, 0, 0, "-", "cli"], [80, 0, 0, "-", "controller"], [81, 0, 0, "-", "gradio_dialogue"], [82, 0, 0, "-", "gradio_rqa"], [83, 0, 0, "-", "gradio_static_server"], [84, 0, 0, "-", "gradio_web_server"], [86, 0, 0, "-", "inference"], [87, 0, 0, "-", "model_worker"], [88, 0, 0, "-", "test_message"]], "serve.base_model_worker": [[78, 1, 1, "", "BaseModelWorker"], [78, 5, 1, "", "acquire_worker_semaphore"], [78, 5, 1, "", "api_count_token"], [78, 5, 1, "", "api_generate"], [78, 5, 1, "", "api_generate_stream"], [78, 5, 1, "", "api_get_conv"], [78, 5, 1, "", "api_get_status"], [78, 5, 1, "", "api_model_details"], [78, 5, 1, "", "api_retrieval"], [78, 4, 1, "", "app"], [78, 5, 1, "", "create_background_tasks"], [78, 5, 1, "", "heart_beat_worker"], [78, 4, 1, "", "logger"], [78, 5, 1, "", "release_worker_semaphore"], [78, 4, 1, "", "worker"]], "serve.base_model_worker.BaseModelWorker": [[78, 3, 1, "", "count_token"], [78, 3, 1, "", "generate_gate"], [78, 3, 1, "", "generate_stream_gate"], [78, 3, 1, "", "get_queue_length"], [78, 3, 1, "", "get_status"], [78, 3, 1, "", "init_heart_beat"], [78, 3, 1, "", "register_to_controller"], [78, 3, 1, "", "retrieve"], [78, 3, 1, "", "send_heart_beat"]], "serve.cli": [[79, 1, 1, "", "ProgrammaticChatIO"], [79, 1, 1, "", "RichChatIO"], [79, 1, 1, "", "SimpleChatIO"], [79, 5, 1, "", "main"], [79, 4, 1, "", "parser"]], "serve.cli.ProgrammaticChatIO": [[79, 3, 1, "", "print_output"], [79, 3, 1, "", "prompt_for_input"], [79, 3, 1, "", "prompt_for_output"], [79, 3, 1, "", "stream_output"]], "serve.cli.RichChatIO": [[79, 3, 1, "", "_"], [79, 2, 1, "", "bindings"], [79, 3, 1, "", "print_output"], [79, 3, 1, "", "prompt_for_input"], [79, 3, 1, "", "prompt_for_output"], [79, 3, 1, "", "stream_output"]], "serve.cli.SimpleChatIO": [[79, 3, 1, "", "print_output"], [79, 3, 1, "", "prompt_for_input"], [79, 3, 1, "", "prompt_for_output"], [79, 3, 1, "", "stream_output"]], "serve.controller": [[80, 1, 1, "", "Controller"], [80, 1, 1, "", "DispatchMethod"], [80, 1, 1, "", "WorkerInfo"], [80, 4, 1, "", "app"], [80, 5, 1, "", "create_controller"], [80, 5, 1, "", "get_worker_address"], [80, 5, 1, "", "heart_beat_controller"], [80, 5, 1, "", "list_models"], [80, 4, 1, "", "logger"], [80, 5, 1, "", "receive_heart_beat"], [80, 5, 1, "", "refresh_all_workers"], [80, 5, 1, "", "register_worker"], [80, 5, 1, "", "worker_api_generate_stream"], [80, 5, 1, "id0", "worker_api_get_status"], [80, 5, 1, "", "worker_api_retrieval"]], "serve.controller.Controller": [[80, 3, 1, "", "get_worker_address"], [80, 3, 1, "", "get_worker_status"], [80, 3, 1, "", "handle_no_worker"], [80, 3, 1, "", "handle_worker_timeout"], [80, 3, 1, "", "list_models"], [80, 3, 1, "", "receive_heart_beat"], [80, 3, 1, "", "refresh_all_workers"], [80, 3, 1, "", "register_worker"], [80, 3, 1, "", "remove_stale_workers_by_expiration"], [80, 3, 1, "", "remove_worker"], [80, 3, 1, "", "worker_api_generate_stream"], [80, 3, 1, "", "worker_api_get_status"], [80, 3, 1, "", "worker_api_retrieval"]], "serve.controller.DispatchMethod": [[80, 2, 1, "", "LOTTERY"], [80, 2, 1, "", "SHORTEST_QUEUE"], [80, 3, 1, "", "from_str"]], "serve.controller.WorkerInfo": [[80, 2, 1, "", "check_heart_beat"], [80, 2, 1, "", "last_heart_beat"], [80, 2, 1, "", "model_names"], [80, 2, 1, "", "queue_length"], [80, 2, 1, "", "speed"]], "serve.gradio_dialogue": [[81, 1, 1, "", "AnnotationHistory"], [81, 1, 1, "", "GradioDialogueSession"], [81, 4, 1, "", "conv_templates"], [81, 4, 1, "", "conv_vicuna_v1"], [81, 4, 1, "", "default_conversation"]], "serve.gradio_dialogue.AnnotationHistory": [[81, 3, 1, "", "_data_idx_filter"], [81, 3, 1, "", "get_current_idx"], [81, 3, 1, "", "get_current_label"], [81, 3, 1, "", "get_next_idx"], [81, 3, 1, "", "get_num_labeled"], [81, 3, 1, "", "get_num_to_label"], [81, 3, 1, "", "get_prev_idx"], [81, 3, 1, "", "is_all_labeled"], [81, 3, 1, "", "load"], [81, 3, 1, "", "parse_int_range"], [81, 3, 1, "", "to_jsonl"], [81, 3, 1, "", "update_label"]], "serve.gradio_dialogue.GradioDialogueSession": [[81, 2, 1, "", "_session"], [81, 2, 1, "", "_tmp_data"], [81, 3, 1, "", "add_system_message"], [81, 3, 1, "", "add_user_message"], [81, 3, 1, "", "clone"], [81, 3, 1, "", "get_prompt"], [81, 2, 1, "", "skip_next"], [81, 3, 1, "", "to_dict"], [81, 3, 1, "", "to_gradio_chatbot"]], "serve.gradio_rqa": [[82, 1, 1, "", "GradioRQA"], [82, 1, 1, "", "GradioSimpleRQA"], [82, 4, 1, "", "logger"]], "serve.gradio_rqa.GradioRQA": [[82, 3, 1, "", "generate_stream_from_api"], [82, 3, 1, "", "get_model"], [82, 3, 1, "", "get_tokenizer"], [82, 3, 1, "", "prepare_prompt_for_generation"], [82, 3, 1, "", "rephrase_question_for_retrieval"], [82, 3, 1, "", "retrieve"]], "serve.gradio_rqa.GradioSimpleRQA": [[82, 3, 1, "", "from_scratch"], [82, 3, 1, "", "generate_stream_from_api"], [82, 3, 1, "", "get_model"], [82, 3, 1, "", "get_tokenizer"], [82, 3, 1, "", "prepare_prompt_for_generation"], [82, 3, 1, "", "rephrase_question_for_retrieval"], [82, 3, 1, "", "retrieve"]], "serve.gradio_static_server": [[83, 4, 1, "", "ANN_CORRECT"], [83, 4, 1, "", "ANN_HARMFUL"], [83, 4, 1, "", "ANN_HELPFUL"], [83, 4, 1, "", "ANN_INCORRECT"], [83, 4, 1, "", "ANN_NOT_HARMFUL"], [83, 4, 1, "", "ANN_NOT_HELPFUL"], [83, 4, 1, "", "NUM_DOC_TO_RETRIEVE"], [83, 4, 1, "", "args"], [83, 4, 1, "", "block_css"], [83, 4, 1, "", "block_js"], [83, 5, 1, "", "build_demo"], [83, 4, 1, "", "disable_btn"], [83, 5, 1, "", "document_view"], [83, 4, 1, "", "enable_btn"], [83, 5, 1, "", "get_conv_log_filename"], [83, 4, 1, "", "headers"], [83, 4, 1, "", "learn_more_markdown"], [83, 5, 1, "", "load_demo"], [83, 4, 1, "", "logger"], [83, 4, 1, "", "no_change_btn"], [83, 4, 1, "", "parser"], [83, 5, 1, "", "render_next_session"], [83, 5, 1, "", "render_prev_session"], [83, 5, 1, "", "render_single_session"], [83, 5, 1, "", "save_annotations"], [83, 4, 1, "", "title_markdown"], [83, 4, 1, "", "tos_markdown"], [83, 5, 1, "", "vote_correctness"], [83, 5, 1, "", "vote_harmlessness"], [83, 5, 1, "", "vote_helpfulness"], [83, 5, 1, "", "vote_response"]], "serve.gradio_web_server": [[84, 4, 1, "", "NUM_DOC_TO_RETRIEVE"], [84, 5, 1, "", "add_text"], [84, 4, 1, "", "args"], [84, 4, 1, "", "block_css"], [84, 4, 1, "", "block_js"], [84, 5, 1, "", "build_demo"], [84, 5, 1, "", "clear_history"], [84, 4, 1, "", "disable_btn"], [84, 5, 1, "", "document_view"], [84, 5, 1, "", "downvote_last_response"], [84, 4, 1, "", "enable_btn"], [84, 5, 1, "", "flag_last_response"], [84, 5, 1, "", "get_conv_log_filename"], [84, 5, 1, "", "get_model_list"], [84, 4, 1, "", "headers"], [84, 5, 1, "", "http_generate"], [84, 5, 1, "", "http_retrieve"], [84, 4, 1, "", "learn_more_markdown"], [84, 5, 1, "", "load_demo"], [84, 5, 1, "", "load_demo_refresh_model_list"], [84, 4, 1, "", "logger"], [84, 4, 1, "", "no_change_btn"], [84, 4, 1, "", "parser"], [84, 5, 1, "", "regenerate"], [84, 4, 1, "", "title_markdown"], [84, 4, 1, "", "tos_markdown"], [84, 5, 1, "", "upvote_last_response"], [84, 5, 1, "", "violates_moderation"], [84, 5, 1, "", "vote_last_response"]], "serve.inference": [[86, 1, 1, "", "ChatIO"], [86, 5, 1, "", "chat_loop"], [86, 5, 1, "", "generate_stream"], [86, 5, 1, "", "prepare_logits_processor"]], "serve.inference.ChatIO": [[86, 3, 1, "", "print_output"], [86, 3, 1, "", "prompt_for_input"], [86, 3, 1, "", "prompt_for_output"], [86, 3, 1, "", "stream_output"]], "serve.model_worker": [[87, 1, 1, "", "ModelWorker"], [87, 5, 1, "", "add_model_args"], [87, 5, 1, "", "create_model_worker"], [87, 5, 1, "", "load_model"], [87, 4, 1, "", "logger"], [87, 4, 1, "", "worker_id"]], "serve.model_worker.ModelWorker": [[87, 3, 1, "", "generate_gate"], [87, 3, 1, "", "generate_stream"], [87, 3, 1, "", "generate_stream_gate"], [87, 3, 1, "", "retrieve"]], "serve.test_message": [[88, 5, 1, "", "main"], [88, 4, 1, "", "parser"]], "supervised_fid_trainer": [[89, 1, 1, "", "SupervisedFiDTrainer"]], "supervised_fid_trainer.SupervisedFiDTrainer": [[89, 3, 1, "", "_load_eval_data"], [89, 3, 1, "", "compute_loss"], [89, 3, 1, "", "evaluation_loop"], [89, 3, 1, "", "prediction_step"], [89, 3, 1, "", "wrap_model_for_eval"]], "supervised_trainer": [[90, 1, 1, "", "SupervisedTrainer"]], "supervised_trainer.SupervisedTrainer": [[90, 3, 1, "", "_load_eval_data"], [90, 3, 1, "", "compute_loss"], [90, 3, 1, "", "evaluation_loop"], [90, 3, 1, "", "prediction_step"], [90, 3, 1, "", "wrap_model_for_eval"]], "text_loaders": [[91, 0, 0, "-", "base"], [93, 0, 0, "-", "langchain_text_loader"], [94, 0, 0, "-", "llamaindex_text_loader"]], "text_loaders.base": [[91, 1, 1, "", "BaseTextLoader"]], "text_loaders.base.BaseTextLoader": [[91, 3, 1, "", "_convert_doc"], [91, 3, 1, "", "load_data"], [91, 3, 1, "", "save_texts"]], "text_loaders.langchain_text_loader": [[93, 1, 1, "", "LangChainTextLoader"], [93, 4, 1, "", "loader_parameters"]], "text_loaders.langchain_text_loader.LangChainTextLoader": [[93, 3, 1, "", "load_data"], [93, 3, 1, "", "save_texts"]], "text_loaders.llamaindex_text_loader": [[94, 1, 1, "", "LlamaIndexTextLoader"], [94, 4, 1, "", "loader_func"]], "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader": [[94, 3, 1, "", "load_data"], [94, 3, 1, "", "save_texts"]], "utils": [[95, 5, 1, "", "create_dir_if_not_exists"], [95, 5, 1, "", "init_logger"], [95, 4, 1, "", "logger"], [95, 5, 1, "", "remove_optimizer_weights"]], "with_retriever_trainer": [[97, 1, 1, "", "FixedRetrieverTrainer"], [97, 5, 1, "", "batch_iterator"]], "with_retriever_trainer.FixedRetrieverTrainer": [[97, 3, 1, "", "_load_all_docs"], [97, 3, 1, "", "_load_eval_data"], [97, 3, 1, "", "compute_loss"], [97, 3, 1, "", "evaluation_loop"], [97, 3, 1, "", "prediction_step"], [97, 3, 1, "", "wrap_model_for_eval"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:data", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "data", "Python data"], "5": ["py", "function", "Python function"]}, "titleterms": {"open_rqa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 98], "base": [1, 8, 10, 14, 23, 32, 41, 51, 54, 58, 71, 91], "evalu": [3, 4, 5, 6, 46, 47, 48, 49, 50], "guardrail": [7, 8, 51, 52], "pipelin": [9, 10, 11, 12, 54, 55, 56, 57], "retrieval_qa": [12, 57], "qa_llm": [13, 14, 15, 16, 17, 18, 19, 20, 21, 58, 59, 60, 61, 62, 63, 64, 65, 66], "retriev": [22, 23, 71, 72, 73, 74], "schema": [24, 25, 26, 75, 76, 77], "dialogu": [25, 75], "document": [26, 76, 99], "text_load": [31, 32, 33, 34, 91, 92, 93, 94], "trainer": [35, 36, 37], "vectorstor": 39, "modul": [40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97], "content": [40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 99], "class": [40, 41, 42, 43, 45, 46, 48, 51, 54, 57, 58, 59, 60, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 82, 86, 87, 89, 90, 91, 93, 94, 97], "attribut": [41, 42, 45, 48, 49, 54, 57, 64, 65, 66, 69, 73, 78, 79, 80, 81, 82, 83, 84, 87, 88, 93, 94, 95], "submodul": [47, 52, 55, 61, 74, 77, 85, 92], "api": 53, "refer": 53, "function": [43, 44, 45, 48, 49, 50, 59, 72, 76, 78, 79, 80, 83, 84, 86, 87, 88, 95, 97], "welcom": 99, "openrqa": [], "": 99, "indic": 99, "tabl": 99, "constant": [2, 42], "metric": [4, 48], "score": [5, 49], "util": [6, 37, 38, 50, 95], "prompt": [11, 18, 56, 63], "fid": [15, 59], "huggingfac": [16, 60], "openai": [17, 62], "sglang": [19, 64], "tgi": [20, 65], "vllm": [21, 66], "serv": [27, 28, 29, 30, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88], "base_model_work": [28, 78], "gradio_dialogu": [29, 81], "test_messag": [30, 88], "langchain_text_load": [33, 93], "llamaindex_text_load": [34, 94], "dist_util": [36, 44], "argument": 40, "dataset": 43, "embed": 45, "retriever_config": 67, "retriever_fid_train": 68, "retriever_replug_train": 69, "retriever_train": 70, "bm25_retriev": 72, "faiss_retriev": 73, "cli": 79, "control": 80, "gradio_rqa": 82, "gradio_static_serv": 83, "gradio_web_serv": 84, "infer": 86, "model_work": 87, "supervised_fid_train": 89, "supervised_train": 90, "with_retriever_fid_train": 96, "with_retriever_train": 97, "localrqa": 99}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"open_rqa": [[0, "module-open_rqa"], [98, "module-open_rqa"]], "open_rqa.base": [[1, "module-open_rqa.base"]], "open_rqa.constants": [[2, "module-open_rqa.constants"]], "open_rqa.evaluation": [[3, "module-open_rqa.evaluation"]], "open_rqa.evaluation.metrics": [[4, "module-open_rqa.evaluation.metrics"]], "open_rqa.evaluation.scores": [[5, "module-open_rqa.evaluation.scores"]], "open_rqa.evaluation.utils": [[6, "module-open_rqa.evaluation.utils"]], "open_rqa.guardrails": [[7, "module-open_rqa.guardrails"]], "open_rqa.guardrails.base": [[8, "module-open_rqa.guardrails.base"]], "open_rqa.pipelines": [[9, "module-open_rqa.pipelines"]], "open_rqa.pipelines.base": [[10, "module-open_rqa.pipelines.base"]], "open_rqa.pipelines.prompts": [[11, "module-open_rqa.pipelines.prompts"]], "open_rqa.pipelines.retrieval_qa": [[12, "open-rqa-pipelines-retrieval-qa"]], "open_rqa.qa_llms": [[13, "module-open_rqa.qa_llms"]], "open_rqa.qa_llms.base": [[14, "module-open_rqa.qa_llms.base"]], "open_rqa.qa_llms.fid": [[15, "module-open_rqa.qa_llms.fid"]], "open_rqa.qa_llms.huggingface": [[16, "module-open_rqa.qa_llms.huggingface"]], "open_rqa.qa_llms.openai": [[17, "module-open_rqa.qa_llms.openai"]], "open_rqa.qa_llms.prompts": [[18, "module-open_rqa.qa_llms.prompts"]], "open_rqa.qa_llms.sglang": [[19, "module-open_rqa.qa_llms.sglang"]], "open_rqa.qa_llms.tgi": [[20, "module-open_rqa.qa_llms.tgi"]], "open_rqa.qa_llms.vllm": [[21, "module-open_rqa.qa_llms.vllm"]], "open_rqa.retrievers": [[22, "module-open_rqa.retrievers"]], "open_rqa.retrievers.base": [[23, "module-open_rqa.retrievers.base"]], "open_rqa.schema": [[24, "module-open_rqa.schema"]], "open_rqa.schema.dialogue": [[25, "module-open_rqa.schema.dialogue"]], "open_rqa.schema.document": [[26, "module-open_rqa.schema.document"]], "open_rqa.serve": [[27, "module-open_rqa.serve"]], "open_rqa.serve.base_model_worker": [[28, "module-open_rqa.serve.base_model_worker"]], "open_rqa.serve.gradio_dialogue": [[29, "module-open_rqa.serve.gradio_dialogue"]], "open_rqa.serve.test_message": [[30, "module-open_rqa.serve.test_message"]], "open_rqa.text_loaders": [[31, "module-open_rqa.text_loaders"]], "open_rqa.text_loaders.base": [[32, "module-open_rqa.text_loaders.base"]], "open_rqa.text_loaders.langchain_text_loader": [[33, "module-open_rqa.text_loaders.langchain_text_loader"]], "open_rqa.text_loaders.llamaindex_text_loader": [[34, "module-open_rqa.text_loaders.llamaindex_text_loader"]], "open_rqa.trainers": [[35, "module-open_rqa.trainers"]], "open_rqa.trainers.dist_utils": [[36, "module-open_rqa.trainers.dist_utils"]], "open_rqa.trainers.utils": [[37, "module-open_rqa.trainers.utils"]], "open_rqa.utils": [[38, "module-open_rqa.utils"]], "open_rqa.vectorstore": [[39, "module-open_rqa.vectorstore"]], "arguments": [[40, "module-arguments"]], "Module Contents": [[40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [54, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [75, "module-contents"], [76, "module-contents"], [78, "module-contents"], [79, "module-contents"], [80, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [97, "module-contents"]], "Classes": [[40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [45, "classes"], [46, "classes"], [48, "classes"], [51, "classes"], [54, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [62, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [75, "classes"], [76, "classes"], [78, "classes"], [79, "classes"], [80, "classes"], [81, "classes"], [82, "classes"], [86, "classes"], [87, "classes"], [89, "classes"], [90, "classes"], [91, "classes"], [93, "classes"], [94, "classes"], [97, "classes"]], "base": [[41, "module-base"]], "Attributes": [[41, "attributes"], [42, "attributes"], [45, "attributes"], [48, "attributes"], [49, "attributes"], [54, "attributes"], [57, "attributes"], [64, "attributes"], [65, "attributes"], [66, "attributes"], [69, "attributes"], [73, "attributes"], [78, "attributes"], [79, "attributes"], [80, "attributes"], [81, "attributes"], [82, "attributes"], [83, "attributes"], [84, "attributes"], [87, "attributes"], [88, "attributes"], [93, "attributes"], [94, "attributes"], [95, "attributes"]], "constants": [[42, "module-constants"]], "datasets": [[43, "module-datasets"]], "Functions": [[43, "functions"], [44, "functions"], [45, "functions"], [48, "functions"], [49, "functions"], [50, "functions"], [59, "functions"], [72, "functions"], [76, "functions"], [78, "functions"], [79, "functions"], [80, "functions"], [83, "functions"], [84, "functions"], [86, "functions"], [87, "functions"], [88, "functions"], [95, "functions"], [97, "functions"]], "dist_utils": [[44, "module-dist_utils"]], "embeddings": [[45, "module-embeddings"]], "evaluation.evaluator": [[46, "module-evaluation.evaluator"]], "evaluation": [[47, "module-evaluation"]], "Submodules": [[47, "submodules"], [52, "submodules"], [55, "submodules"], [61, "submodules"], [74, "submodules"], [77, "submodules"], [85, "submodules"], [92, "submodules"]], "evaluation.metrics": [[48, "module-evaluation.metrics"]], "evaluation.scores": [[49, "module-evaluation.scores"]], "evaluation.utils": [[50, "module-evaluation.utils"]], "guardrails.base": [[51, "module-guardrails.base"]], "guardrails": [[52, "module-guardrails"]], "API Reference": [[53, "api-reference"]], "pipelines.base": [[54, "module-pipelines.base"]], "pipelines": [[55, "module-pipelines"]], "pipelines.prompts": [[56, "module-pipelines.prompts"]], "pipelines.retrieval_qa": [[57, "module-pipelines.retrieval_qa"]], "qa_llms.base": [[58, "module-qa_llms.base"]], "qa_llms.fid": [[59, "module-qa_llms.fid"]], "qa_llms.huggingface": [[60, "module-qa_llms.huggingface"]], "qa_llms": [[61, "module-qa_llms"]], "qa_llms.openai": [[62, "module-qa_llms.openai"]], "qa_llms.prompts": [[63, "module-qa_llms.prompts"]], "qa_llms.sglang": [[64, "module-qa_llms.sglang"]], "qa_llms.tgi": [[65, "module-qa_llms.tgi"]], "qa_llms.vllm": [[66, "module-qa_llms.vllm"]], "retriever_config": [[67, "module-retriever_config"]], "retriever_fid_trainer": [[68, "module-retriever_fid_trainer"]], "retriever_replug_trainer": [[69, "module-retriever_replug_trainer"]], "retriever_trainer": [[70, "module-retriever_trainer"]], "retrievers.base": [[71, "module-retrievers.base"]], "retrievers.bm25_retriever": [[72, "module-retrievers.bm25_retriever"]], "retrievers.faiss_retriever": [[73, "module-retrievers.faiss_retriever"]], "retrievers": [[74, "module-retrievers"]], "schema.dialogue": [[75, "module-schema.dialogue"]], "schema.document": [[76, "module-schema.document"]], "schema": [[77, "module-schema"]], "serve.base_model_worker": [[78, "module-serve.base_model_worker"]], "serve.cli": [[79, "module-serve.cli"]], "serve.controller": [[80, "module-serve.controller"]], "serve.gradio_dialogue": [[81, "module-serve.gradio_dialogue"]], "serve.gradio_rqa": [[82, "module-serve.gradio_rqa"]], "serve.gradio_static_server": [[83, "module-serve.gradio_static_server"]], "serve.gradio_web_server": [[84, "module-serve.gradio_web_server"]], "serve": [[85, "module-serve"]], "serve.inference": [[86, "module-serve.inference"]], "serve.model_worker": [[87, "module-serve.model_worker"]], "serve.test_message": [[88, "module-serve.test_message"]], "supervised_fid_trainer": [[89, "module-supervised_fid_trainer"]], "supervised_trainer": [[90, "module-supervised_trainer"]], "text_loaders.base": [[91, "module-text_loaders.base"]], "text_loaders": [[92, "module-text_loaders"]], "text_loaders.langchain_text_loader": [[93, "module-text_loaders.langchain_text_loader"]], "text_loaders.llamaindex_text_loader": [[94, "module-text_loaders.llamaindex_text_loader"]], "utils": [[95, "module-utils"]], "with_retriever_fid_trainer": [[96, "module-with_retriever_fid_trainer"]], "with_retriever_trainer": [[97, "module-with_retriever_trainer"]], "Welcome to LocalRQA\u2019s documentation!": [[99, "welcome-to-localrqa-s-documentation"]], "Contents:": [[99, null]], "Indices and tables": [[99, "indices-and-tables"]]}, "indexentries": {"module": [[0, "module-open_rqa"], [1, "module-open_rqa.base"], [2, "module-open_rqa.constants"], [3, "module-open_rqa.evaluation"], [4, "module-open_rqa.evaluation.metrics"], [5, "module-open_rqa.evaluation.scores"], [6, "module-open_rqa.evaluation.utils"], [7, "module-open_rqa.guardrails"], [8, "module-open_rqa.guardrails.base"], [9, "module-open_rqa.pipelines"], [10, "module-open_rqa.pipelines.base"], [11, "module-open_rqa.pipelines.prompts"], [13, "module-open_rqa.qa_llms"], [14, "module-open_rqa.qa_llms.base"], [15, "module-open_rqa.qa_llms.fid"], [16, "module-open_rqa.qa_llms.huggingface"], [17, "module-open_rqa.qa_llms.openai"], [18, "module-open_rqa.qa_llms.prompts"], [19, "module-open_rqa.qa_llms.sglang"], [20, "module-open_rqa.qa_llms.tgi"], [21, "module-open_rqa.qa_llms.vllm"], [22, "module-open_rqa.retrievers"], [23, "module-open_rqa.retrievers.base"], [24, "module-open_rqa.schema"], [25, "module-open_rqa.schema.dialogue"], [26, "module-open_rqa.schema.document"], [27, "module-open_rqa.serve"], [28, "module-open_rqa.serve.base_model_worker"], [29, "module-open_rqa.serve.gradio_dialogue"], [30, "module-open_rqa.serve.test_message"], [31, "module-open_rqa.text_loaders"], [32, "module-open_rqa.text_loaders.base"], [33, "module-open_rqa.text_loaders.langchain_text_loader"], [34, "module-open_rqa.text_loaders.llamaindex_text_loader"], [35, "module-open_rqa.trainers"], [36, "module-open_rqa.trainers.dist_utils"], [37, "module-open_rqa.trainers.utils"], [38, "module-open_rqa.utils"], [39, "module-open_rqa.vectorstore"], [40, "module-arguments"], [41, "module-base"], [42, "module-constants"], [43, "module-datasets"], [44, "module-dist_utils"], [45, "module-embeddings"], [46, "module-evaluation.evaluator"], [47, "module-evaluation"], [48, "module-evaluation.metrics"], [49, "module-evaluation.scores"], [50, "module-evaluation.utils"], [51, "module-guardrails.base"], [52, "module-guardrails"], [54, "module-pipelines.base"], [55, "module-pipelines"], [56, "module-pipelines.prompts"], [57, "module-pipelines.retrieval_qa"], [58, "module-qa_llms.base"], [59, "module-qa_llms.fid"], [60, "module-qa_llms.huggingface"], [61, "module-qa_llms"], [62, "module-qa_llms.openai"], [63, "module-qa_llms.prompts"], [64, "module-qa_llms.sglang"], [65, "module-qa_llms.tgi"], [66, "module-qa_llms.vllm"], [67, "module-retriever_config"], [68, "module-retriever_fid_trainer"], [69, "module-retriever_replug_trainer"], [70, "module-retriever_trainer"], [71, "module-retrievers.base"], [72, "module-retrievers.bm25_retriever"], [73, "module-retrievers.faiss_retriever"], [74, "module-retrievers"], [75, "module-schema.dialogue"], [76, "module-schema.document"], [77, "module-schema"], [78, "module-serve.base_model_worker"], [79, "module-serve.cli"], [80, "module-serve.controller"], [81, "module-serve.gradio_dialogue"], [82, "module-serve.gradio_rqa"], [83, "module-serve.gradio_static_server"], [84, "module-serve.gradio_web_server"], [85, "module-serve"], [86, "module-serve.inference"], [87, "module-serve.model_worker"], [88, "module-serve.test_message"], [89, "module-supervised_fid_trainer"], [90, "module-supervised_trainer"], [91, "module-text_loaders.base"], [92, "module-text_loaders"], [93, "module-text_loaders.langchain_text_loader"], [94, "module-text_loaders.llamaindex_text_loader"], [95, "module-utils"], [96, "module-with_retriever_fid_trainer"], [97, "module-with_retriever_trainer"], [98, "module-open_rqa"]], "open_rqa": [[0, "module-open_rqa"], [98, "module-open_rqa"]], "open_rqa.base": [[1, "module-open_rqa.base"]], "open_rqa.constants": [[2, "module-open_rqa.constants"]], "open_rqa.evaluation": [[3, "module-open_rqa.evaluation"]], "open_rqa.evaluation.metrics": [[4, "module-open_rqa.evaluation.metrics"]], "open_rqa.evaluation.scores": [[5, "module-open_rqa.evaluation.scores"]], "open_rqa.evaluation.utils": [[6, "module-open_rqa.evaluation.utils"]], "open_rqa.guardrails": [[7, "module-open_rqa.guardrails"]], "open_rqa.guardrails.base": [[8, "module-open_rqa.guardrails.base"]], "open_rqa.pipelines": [[9, "module-open_rqa.pipelines"]], "open_rqa.pipelines.base": [[10, "module-open_rqa.pipelines.base"]], "open_rqa.pipelines.prompts": [[11, "module-open_rqa.pipelines.prompts"]], "open_rqa.qa_llms": [[13, "module-open_rqa.qa_llms"]], "open_rqa.qa_llms.base": [[14, "module-open_rqa.qa_llms.base"]], "open_rqa.qa_llms.fid": [[15, "module-open_rqa.qa_llms.fid"]], "open_rqa.qa_llms.huggingface": [[16, "module-open_rqa.qa_llms.huggingface"]], "open_rqa.qa_llms.openai": [[17, "module-open_rqa.qa_llms.openai"]], "open_rqa.qa_llms.prompts": [[18, "module-open_rqa.qa_llms.prompts"]], "open_rqa.qa_llms.sglang": [[19, "module-open_rqa.qa_llms.sglang"]], "open_rqa.qa_llms.tgi": [[20, "module-open_rqa.qa_llms.tgi"]], "open_rqa.qa_llms.vllm": [[21, "module-open_rqa.qa_llms.vllm"]], "open_rqa.retrievers": [[22, "module-open_rqa.retrievers"]], "open_rqa.retrievers.base": [[23, "module-open_rqa.retrievers.base"]], "open_rqa.schema": [[24, "module-open_rqa.schema"]], "open_rqa.schema.dialogue": [[25, "module-open_rqa.schema.dialogue"]], "open_rqa.schema.document": [[26, "module-open_rqa.schema.document"]], "open_rqa.serve": [[27, "module-open_rqa.serve"]], "open_rqa.serve.base_model_worker": [[28, "module-open_rqa.serve.base_model_worker"]], "open_rqa.serve.gradio_dialogue": [[29, "module-open_rqa.serve.gradio_dialogue"]], "open_rqa.serve.test_message": [[30, "module-open_rqa.serve.test_message"]], "open_rqa.text_loaders": [[31, "module-open_rqa.text_loaders"]], "open_rqa.text_loaders.base": [[32, "module-open_rqa.text_loaders.base"]], "open_rqa.text_loaders.langchain_text_loader": [[33, "module-open_rqa.text_loaders.langchain_text_loader"]], "open_rqa.text_loaders.llamaindex_text_loader": [[34, "module-open_rqa.text_loaders.llamaindex_text_loader"]], "open_rqa.trainers": [[35, "module-open_rqa.trainers"]], "open_rqa.trainers.dist_utils": [[36, "module-open_rqa.trainers.dist_utils"]], "open_rqa.trainers.utils": [[37, "module-open_rqa.trainers.utils"]], "open_rqa.utils": [[38, "module-open_rqa.utils"]], "open_rqa.vectorstore": [[39, "module-open_rqa.vectorstore"]], "contrasitivetrainingargs (class in arguments)": [[40, "arguments.ContrasitiveTrainingArgs"]], "dataarguments (class in arguments)": [[40, "arguments.DataArguments"]], "fidtrainingargs (class in arguments)": [[40, "arguments.FidTrainingArgs"]], "modelarguments (class in arguments)": [[40, "arguments.ModelArguments"]], "replugtrainingargs (class in arguments)": [[40, "arguments.ReplugTrainingArgs"]], "retrievalqatrainingarguments (class in arguments)": [[40, "arguments.RetrievalQATrainingArguments"]], "apply_passage_mask (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.apply_passage_mask"]], "apply_question_mask (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.apply_question_mask"]], "arguments": [[40, "module-arguments"]], "contrastive_loss (arguments.contrasitivetrainingargs attribute)": [[40, "arguments.ContrasitiveTrainingArgs.contrastive_loss"]], "do_eval (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.do_eval"]], "do_train (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.do_train"]], "eval_file (arguments.dataarguments attribute)": [[40, "arguments.DataArguments.eval_file"]], "eval_steps (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.eval_steps"]], "evaluation_strategy (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.evaluation_strategy"]], "extract_cls (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.extract_cls"]], "full_dataset_file_path (arguments.dataarguments attribute)": [[40, "arguments.DataArguments.full_dataset_file_path"]], "gradient_checkpointing (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.gradient_checkpointing"]], "hard_neg_ratio (arguments.contrasitivetrainingargs attribute)": [[40, "arguments.ContrasitiveTrainingArgs.hard_neg_ratio"]], "indexing_dimension (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.indexing_dimension"]], "learning_rate (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.learning_rate"]], "lm_model_path (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.lm_model_path"]], "lm_temperature (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.lm_temperature"]], "logging_steps (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.logging_steps"]], "lr_scheduler_type (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.lr_scheduler_type"]], "max_steps (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.max_steps"]], "metric_for_best_model (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.metric_for_best_model"]], "model_name_or_path (arguments.modelarguments attribute)": [[40, "arguments.ModelArguments.model_name_or_path"]], "n_context (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.n_context"]], "num_docs (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.num_docs"]], "output_dir (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.output_dir"]], "per_device_eval_batch_size (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.per_device_eval_batch_size"]], "per_device_train_batch_size (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.per_device_train_batch_size"]], "pooling_type (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.pooling_type"]], "projection (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.projection"]], "reader_batch_size (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.reader_batch_size"]], "reader_model_path (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.reader_model_path"]], "reader_temperature (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.reader_temperature"]], "refresh_step (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.refresh_step"]], "remove_unused_columns (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.remove_unused_columns"]], "report_to (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.report_to"]], "retrieve_temperature (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.retrieve_temperature"]], "save_steps (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.save_steps"]], "save_strategy (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.save_strategy"]], "save_total_limit (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.save_total_limit"]], "search_algo (arguments.contrasitivetrainingargs attribute)": [[40, "arguments.ContrasitiveTrainingArgs.search_algo"]], "search_algo (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.search_algo"]], "search_algo (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.search_algo"]], "seed (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.seed"]], "temperature (arguments.contrasitivetrainingargs attribute)": [[40, "arguments.ContrasitiveTrainingArgs.temperature"]], "test_file (arguments.dataarguments attribute)": [[40, "arguments.DataArguments.test_file"]], "text_maxlength (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.text_maxlength"]], "text_maxlength (arguments.replugtrainingargs attribute)": [[40, "arguments.ReplugTrainingArgs.text_maxlength"]], "train_file (arguments.dataarguments attribute)": [[40, "arguments.DataArguments.train_file"]], "warmup_ratio (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.warmup_ratio"]], "weight_decay (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.weight_decay"]], "with_score (arguments.fidtrainingargs attribute)": [[40, "arguments.FidTrainingArgs.with_score"]], "write_predictions (arguments.retrievalqatrainingarguments attribute)": [[40, "arguments.RetrievalQATrainingArguments.write_predictions"]], "component (class in base)": [[41, "base.Component"]], "base": [[41, "module-base"]], "logger (in module base)": [[41, "base.logger"]], "run() (base.component method)": [[41, "base.Component.run"]], "run_input_keys (base.component attribute)": [[41, "base.Component.run_input_keys"]], "accelerationframework (class in constants)": [[42, "constants.AccelerationFramework"]], "context_overflow (constants.errorcode attribute)": [[42, "constants.ErrorCode.CONTEXT_OVERFLOW"]], "controller_heart_beat_expiration (in module constants)": [[42, "constants.CONTROLLER_HEART_BEAT_EXPIRATION"]], "controller_no_worker (constants.errorcode attribute)": [[42, "constants.ErrorCode.CONTROLLER_NO_WORKER"]], "controller_worker_timeout (constants.errorcode attribute)": [[42, "constants.ErrorCode.CONTROLLER_WORKER_TIMEOUT"]], "cuda_out_of_memory (constants.errorcode attribute)": [[42, "constants.ErrorCode.CUDA_OUT_OF_MEMORY"]], "engine_overloaded (constants.errorcode attribute)": [[42, "constants.ErrorCode.ENGINE_OVERLOADED"]], "errorcode (class in constants)": [[42, "constants.ErrorCode"]], "gradio_request_error (constants.errorcode attribute)": [[42, "constants.ErrorCode.GRADIO_REQUEST_ERROR"]], "gradio_stream_unknown_error (constants.errorcode attribute)": [[42, "constants.ErrorCode.GRADIO_STREAM_UNKNOWN_ERROR"]], "incorrect_auth_key (constants.errorcode attribute)": [[42, "constants.ErrorCode.INCORRECT_AUTH_KEY"]], "internal_error (constants.errorcode attribute)": [[42, "constants.ErrorCode.INTERNAL_ERROR"]], "invalid_auth_key (constants.errorcode attribute)": [[42, "constants.ErrorCode.INVALID_AUTH_KEY"]], "invalid_model (constants.errorcode attribute)": [[42, "constants.ErrorCode.INVALID_MODEL"]], "no_permission (constants.errorcode attribute)": [[42, "constants.ErrorCode.NO_PERMISSION"]], "openai_model_names (in module constants)": [[42, "constants.OPENAI_MODEL_NAMES"]], "param_out_of_range (constants.errorcode attribute)": [[42, "constants.ErrorCode.PARAM_OUT_OF_RANGE"]], "qa_error_msg (in module constants)": [[42, "constants.QA_ERROR_MSG"]], "qa_moderation_msg (in module constants)": [[42, "constants.QA_MODERATION_MSG"]], "quota_exceeded (constants.errorcode attribute)": [[42, "constants.ErrorCode.QUOTA_EXCEEDED"]], "rate_limit (constants.errorcode attribute)": [[42, "constants.ErrorCode.RATE_LIMIT"]], "server_error_msg (in module constants)": [[42, "constants.SERVER_ERROR_MSG"]], "server_logdir (in module constants)": [[42, "constants.SERVER_LOGDIR"]], "sglang (constants.accelerationframework attribute)": [[42, "constants.AccelerationFramework.SGLANG"]], "tgi (constants.accelerationframework attribute)": [[42, "constants.AccelerationFramework.TGI"]], "validation_type_error (constants.errorcode attribute)": [[42, "constants.ErrorCode.VALIDATION_TYPE_ERROR"]], "vllm (constants.accelerationframework attribute)": [[42, "constants.AccelerationFramework.VLLM"]], "worker_heart_beat_interval (in module constants)": [[42, "constants.WORKER_HEART_BEAT_INTERVAL"]], "constants": [[42, "module-constants"]], "contrastiveretrievaldataset (class in datasets)": [[43, "datasets.ContrastiveRetrievalDataset"]], "fidcollator (class in datasets)": [[43, "datasets.FidCollator"]], "fiddataset (class in datasets)": [[43, "datasets.FidDataset"]], "noopdatacollator (class in datasets)": [[43, "datasets.NoopDataCollator"]], "replugdataset (class in datasets)": [[43, "datasets.ReplugDataset"]], "retrievercollator (class in datasets)": [[43, "datasets.RetrieverCollator"]], "__call__() (datasets.fidcollator method)": [[43, "datasets.FidCollator.__call__"]], "__call__() (datasets.noopdatacollator method)": [[43, "datasets.NoopDataCollator.__call__"]], "__call__() (datasets.retrievercollator method)": [[43, "datasets.RetrieverCollator.__call__"]], "__getitem__() (datasets.contrastiveretrievaldataset method)": [[43, "datasets.ContrastiveRetrievalDataset.__getitem__"]], "__getitem__() (datasets.fiddataset method)": [[43, "datasets.FidDataset.__getitem__"]], "__getitem__() (datasets.replugdataset method)": [[43, "datasets.ReplugDataset.__getitem__"]], "__len__() (datasets.contrastiveretrievaldataset method)": [[43, "datasets.ContrastiveRetrievalDataset.__len__"]], "__len__() (datasets.fiddataset method)": [[43, "datasets.FidDataset.__len__"]], "__len__() (datasets.replugdataset method)": [[43, "datasets.ReplugDataset.__len__"]], "datasets": [[43, "module-datasets"]], "encode_passages() (in module datasets)": [[43, "datasets.encode_passages"]], "get_example() (datasets.fiddataset method)": [[43, "datasets.FidDataset.get_example"]], "get_target() (datasets.fiddataset method)": [[43, "datasets.FidDataset.get_target"]], "get_target() (datasets.replugdataset method)": [[43, "datasets.ReplugDataset.get_target"]], "load_fid_data() (in module datasets)": [[43, "datasets.load_fid_data"]], "prepare_data() (datasets.contrastiveretrievaldataset method)": [[43, "datasets.ContrastiveRetrievalDataset.prepare_data"]], "sort_data() (datasets.fiddataset method)": [[43, "datasets.FidDataset.sort_data"]], "barrier() (in module dist_utils)": [[44, "dist_utils.barrier"]], "dist_utils": [[44, "module-dist_utils"]], "get_rank() (in module dist_utils)": [[44, "dist_utils.get_rank"]], "is_main() (in module dist_utils)": [[44, "dist_utils.is_main"]], "localembeddings (class in embeddings)": [[45, "embeddings.LocalEmbeddings"]], "batch_iterator() (in module embeddings)": [[45, "embeddings.batch_iterator"]], "compute_embedding() (in module embeddings)": [[45, "embeddings.compute_embedding"]], "embed_document_batch() (in module embeddings)": [[45, "embeddings.embed_document_batch"]], "embed_documents() (embeddings.localembeddings method)": [[45, "embeddings.LocalEmbeddings.embed_documents"]], "embed_query() (embeddings.localembeddings method)": [[45, "embeddings.LocalEmbeddings.embed_query"]], "embeddings": [[45, "module-embeddings"]], "logger (in module embeddings)": [[45, "embeddings.logger"]], "mean_pooling() (in module embeddings)": [[45, "embeddings.mean_pooling"]], "e2eevaluator (class in evaluation.evaluator)": [[46, "evaluation.evaluator.E2EEvaluator"]], "evaluator (class in evaluation.evaluator)": [[46, "evaluation.evaluator.Evaluator"]], "evaluatorconfig (class in evaluation.evaluator)": [[46, "evaluation.evaluator.EvaluatorConfig"]], "retrieverevaluator (class in evaluation.evaluator)": [[46, "evaluation.evaluator.RetrieverEvaluator"]], "_flatten_performance() (evaluation.evaluator.evaluator method)": [[46, "evaluation.evaluator.Evaluator._flatten_performance"]], "_get_data_iterator() (evaluation.evaluator.evaluator method)": [[46, "evaluation.evaluator.Evaluator._get_data_iterator"]], "assistant_prefix (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.assistant_prefix"]], "batch_size (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.batch_size"]], "compute_performance() (evaluation.evaluator.e2eevaluator method)": [[46, "evaluation.evaluator.E2EEvaluator.compute_performance"]], "compute_performance() (evaluation.evaluator.retrieverevaluator method)": [[46, "evaluation.evaluator.RetrieverEvaluator.compute_performance"]], "e2e_latency (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.e2e_latency"]], "evaluate() (evaluation.evaluator.e2eevaluator method)": [[46, "evaluation.evaluator.E2EEvaluator.evaluate"]], "evaluate() (evaluation.evaluator.evaluator method)": [[46, "evaluation.evaluator.Evaluator.evaluate"]], "evaluate() (evaluation.evaluator.retrieverevaluator method)": [[46, "evaluation.evaluator.RetrieverEvaluator.evaluate"]], "evaluation.evaluator": [[46, "module-evaluation.evaluator"]], "gen_answer_stats (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_answer_stats"]], "gen_bleu (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_bleu"]], "gen_f1 (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_f1"]], "gen_gpt4eval (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_gpt4eval"]], "gen_latency (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_latency"]], "gen_precision (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_precision"]], "gen_rouge (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.gen_rouge"]], "init_metrics() (evaluation.evaluator.e2eevaluator method)": [[46, "evaluation.evaluator.E2EEvaluator.init_metrics"]], "init_metrics() (evaluation.evaluator.retrieverevaluator method)": [[46, "evaluation.evaluator.RetrieverEvaluator.init_metrics"]], "reset_all_metrics() (evaluation.evaluator.e2eevaluator method)": [[46, "evaluation.evaluator.E2EEvaluator.reset_all_metrics"]], "reset_all_metrics() (evaluation.evaluator.retrieverevaluator method)": [[46, "evaluation.evaluator.RetrieverEvaluator.reset_all_metrics"]], "retr_document_accuracy (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.retr_document_accuracy"]], "retr_document_recall (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.retr_document_recall"]], "retr_latency (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.retr_latency"]], "sep_sys (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.sep_sys"]], "sep_user (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.sep_user"]], "user_prefix (evaluation.evaluator.evaluatorconfig attribute)": [[46, "evaluation.evaluator.EvaluatorConfig.user_prefix"]], "evaluation": [[47, "module-evaluation"]], "answerstats (class in evaluation.metrics)": [[48, "evaluation.metrics.AnswerStats"]], "bleu (class in evaluation.metrics)": [[48, "evaluation.metrics.BLEU"]], "documentaccuracy (class in evaluation.metrics)": [[48, "evaluation.metrics.DocumentAccuracy"]], "documentrecall (class in evaluation.metrics)": [[48, "evaluation.metrics.DocumentRecall"]], "f1 (class in evaluation.metrics)": [[48, "evaluation.metrics.F1"]], "gpt4eval (class in evaluation.metrics)": [[48, "evaluation.metrics.GPT4Eval"]], "gpt_eval_acc_prompt (in module evaluation.metrics)": [[48, "evaluation.metrics.GPT_EVAL_ACC_PROMPT"]], "gpt_eval_noans_acc_prompt (in module evaluation.metrics)": [[48, "evaluation.metrics.GPT_EVAL_NOANS_ACC_PROMPT"]], "latency (class in evaluation.metrics)": [[48, "evaluation.metrics.Latency"]], "metrics (in module evaluation.metrics)": [[48, "evaluation.metrics.METRICS"]], "monitoringmetric (class in evaluation.metrics)": [[48, "evaluation.metrics.MonitoringMetric"]], "precision (class in evaluation.metrics)": [[48, "evaluation.metrics.Precision"]], "rouge (class in evaluation.metrics)": [[48, "evaluation.metrics.ROUGE"]], "runningmetic (class in evaluation.metrics)": [[48, "evaluation.metrics.RunningMetic"]], "_generate() (evaluation.metrics.gpt4eval method)": [[48, "evaluation.metrics.GPT4Eval._generate"]], "compute() (evaluation.metrics.answerstats method)": [[48, "evaluation.metrics.AnswerStats.compute"]], "compute() (evaluation.metrics.bleu method)": [[48, "evaluation.metrics.BLEU.compute"]], "compute() (evaluation.metrics.documentaccuracy method)": [[48, "evaluation.metrics.DocumentAccuracy.compute"]], "compute() (evaluation.metrics.documentrecall method)": [[48, "evaluation.metrics.DocumentRecall.compute"]], "compute() (evaluation.metrics.f1 method)": [[48, "evaluation.metrics.F1.compute"]], "compute() (evaluation.metrics.gpt4eval method)": [[48, "evaluation.metrics.GPT4Eval.compute"]], "compute() (evaluation.metrics.latency method)": [[48, "evaluation.metrics.Latency.compute"]], "compute() (evaluation.metrics.monitoringmetric method)": [[48, "evaluation.metrics.MonitoringMetric.compute"]], "compute() (evaluation.metrics.precision method)": [[48, "evaluation.metrics.Precision.compute"]], "compute() (evaluation.metrics.rouge method)": [[48, "evaluation.metrics.ROUGE.compute"]], "compute() (evaluation.metrics.runningmetic method)": [[48, "evaluation.metrics.RunningMetic.compute"]], "document_similarity() (in module evaluation.metrics)": [[48, "evaluation.metrics.document_similarity"]], "evaluation.metrics": [[48, "module-evaluation.metrics"]], "is_almost_same_document() (in module evaluation.metrics)": [[48, "evaluation.metrics.is_almost_same_document"]], "is_same_document() (in module evaluation.metrics)": [[48, "evaluation.metrics.is_same_document"]], "judge() (evaluation.metrics.gpt4eval method)": [[48, "evaluation.metrics.GPT4Eval.judge"]], "logger (in module evaluation.metrics)": [[48, "evaluation.metrics.logger"]], "mean() (in module evaluation.metrics)": [[48, "evaluation.metrics.mean"]], "reset() (evaluation.metrics.answerstats method)": [[48, "evaluation.metrics.AnswerStats.reset"]], "reset() (evaluation.metrics.bleu method)": [[48, "evaluation.metrics.BLEU.reset"]], "reset() (evaluation.metrics.documentaccuracy method)": [[48, "evaluation.metrics.DocumentAccuracy.reset"]], "reset() (evaluation.metrics.documentrecall method)": [[48, "evaluation.metrics.DocumentRecall.reset"]], "reset() (evaluation.metrics.f1 method)": [[48, "evaluation.metrics.F1.reset"]], "reset() (evaluation.metrics.gpt4eval method)": [[48, "evaluation.metrics.GPT4Eval.reset"]], "reset() (evaluation.metrics.latency method)": [[48, "evaluation.metrics.Latency.reset"]], "reset() (evaluation.metrics.monitoringmetric method)": [[48, "evaluation.metrics.MonitoringMetric.reset"]], "reset() (evaluation.metrics.precision method)": [[48, "evaluation.metrics.Precision.reset"]], "reset() (evaluation.metrics.rouge method)": [[48, "evaluation.metrics.ROUGE.reset"]], "reset() (evaluation.metrics.runningmetic method)": [[48, "evaluation.metrics.RunningMetic.reset"]], "start() (evaluation.metrics.latency method)": [[48, "evaluation.metrics.Latency.start"]], "start() (evaluation.metrics.monitoringmetric method)": [[48, "evaluation.metrics.MonitoringMetric.start"]], "stop() (evaluation.metrics.latency method)": [[48, "evaluation.metrics.Latency.stop"]], "stop() (evaluation.metrics.monitoringmetric method)": [[48, "evaluation.metrics.MonitoringMetric.stop"]], "update() (evaluation.metrics.answerstats method)": [[48, "evaluation.metrics.AnswerStats.update"]], "update() (evaluation.metrics.bleu method)": [[48, "evaluation.metrics.BLEU.update"]], "update() (evaluation.metrics.documentaccuracy method)": [[48, "evaluation.metrics.DocumentAccuracy.update"]], "update() (evaluation.metrics.documentrecall method)": [[48, "evaluation.metrics.DocumentRecall.update"]], "update() (evaluation.metrics.f1 method)": [[48, "evaluation.metrics.F1.update"]], "update() (evaluation.metrics.gpt4eval method)": [[48, "evaluation.metrics.GPT4Eval.update"]], "update() (evaluation.metrics.precision method)": [[48, "evaluation.metrics.Precision.update"]], "update() (evaluation.metrics.rouge method)": [[48, "evaluation.metrics.ROUGE.update"]], "update() (evaluation.metrics.runningmetic method)": [[48, "evaluation.metrics.RunningMetic.update"]], "em() (in module evaluation.scores)": [[49, "evaluation.scores.em"]], "evaluation.scores": [[49, "module-evaluation.scores"]], "exact_match_score() (in module evaluation.scores)": [[49, "evaluation.scores.exact_match_score"]], "f1() (in module evaluation.scores)": [[49, "evaluation.scores.f1"]], "f1_score() (in module evaluation.scores)": [[49, "evaluation.scores.f1_score"]], "precision() (in module evaluation.scores)": [[49, "evaluation.scores.precision"]], "recall() (in module evaluation.scores)": [[49, "evaluation.scores.recall"]], "rouge (in module evaluation.scores)": [[49, "evaluation.scores.rouge"]], "rouge_score() (in module evaluation.scores)": [[49, "evaluation.scores.rouge_score"]], "rouge_wrapper() (in module evaluation.scores)": [[49, "evaluation.scores.rouge_wrapper"]], "evaluation.utils": [[50, "module-evaluation.utils"]], "normalize_answer() (in module evaluation.utils)": [[50, "evaluation.utils.normalize_answer"]], "baseanswerguardrail (class in guardrails.base)": [[51, "guardrails.base.BaseAnswerGuardrail"]], "noopanswerguardrail (class in guardrails.base)": [[51, "guardrails.base.NoopAnswerGuardrail"]], "guardrail() (guardrails.base.baseanswerguardrail method)": [[51, "guardrails.base.BaseAnswerGuardrail.guardrail"]], "guardrail() (guardrails.base.noopanswerguardrail method)": [[51, "guardrails.base.NoopAnswerGuardrail.guardrail"]], "guardrails.base": [[51, "module-guardrails.base"]], "run() (guardrails.base.baseanswerguardrail method)": [[51, "guardrails.base.BaseAnswerGuardrail.run"]], "run_input_keys (guardrails.base.baseanswerguardrail attribute)": [[51, "guardrails.base.BaseAnswerGuardrail.run_input_keys"]], "guardrails": [[52, "module-guardrails"]], "rqapipeline (class in pipelines.base)": [[54, "pipelines.base.RQAPipeline"]], "_prepare_input() (pipelines.base.rqapipeline method)": [[54, "pipelines.base.RQAPipeline._prepare_input"]], "components() (pipelines.base.rqapipeline method)": [[54, "pipelines.base.RQAPipeline.components"]], "logger (in module pipelines.base)": [[54, "pipelines.base.logger"]], "pipelines.base": [[54, "module-pipelines.base"]], "qa() (pipelines.base.rqapipeline method)": [[54, "pipelines.base.RQAPipeline.qa"]], "run() (pipelines.base.rqapipeline method)": [[54, "pipelines.base.RQAPipeline.run"]], "run_input_keys (pipelines.base.rqapipeline attribute)": [[54, "pipelines.base.RQAPipeline.run_input_keys"]], "update_dialogue_session() (pipelines.base.rqapipeline method)": [[54, "pipelines.base.RQAPipeline.update_dialogue_session"]], "pipelines": [[55, "module-pipelines"]], "rephrase_question_prompt (in module pipelines.prompts)": [[56, "pipelines.prompts.REPHRASE_QUESTION_PROMPT"]], "pipelines.prompts": [[56, "module-pipelines.prompts"]], "autorqa (class in pipelines.retrieval_qa)": [[57, "pipelines.retrieval_qa.AutoRQA"]], "baserqa (class in pipelines.retrieval_qa)": [[57, "pipelines.retrieval_qa.BaseRQA"]], "simplerqa (class in pipelines.retrieval_qa)": [[57, "pipelines.retrieval_qa.SimpleRQA"]], "_batch_generate() (pipelines.retrieval_qa.simplerqa method)": [[57, "pipelines.retrieval_qa.SimpleRQA._batch_generate"]], "_rephrase_questions() (pipelines.retrieval_qa.simplerqa method)": [[57, "pipelines.retrieval_qa.SimpleRQA._rephrase_questions"]], "from_huggingface() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_huggingface"]], "from_huggingface_fid() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_huggingface_fid"]], "from_openai() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_openai"]], "from_scratch() (pipelines.retrieval_qa.simplerqa class method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_scratch"]], "from_sglang() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_sglang"]], "from_tgi() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_tgi"]], "from_vllm() (pipelines.retrieval_qa.simplerqa static method)": [[57, "pipelines.retrieval_qa.SimpleRQA.from_vllm"]], "logger (in module pipelines.retrieval_qa)": [[57, "pipelines.retrieval_qa.logger"]], "pipelines.retrieval_qa": [[57, "module-pipelines.retrieval_qa"]], "qa() (pipelines.retrieval_qa.simplerqa method)": [[57, "pipelines.retrieval_qa.SimpleRQA.qa"]], "rephrase_questions() (pipelines.retrieval_qa.simplerqa method)": [[57, "pipelines.retrieval_qa.SimpleRQA.rephrase_questions"]], "baseqamodel (class in qa_llms.base)": [[58, "qa_llms.base.BaseQAModel"]], "generationoutput (class in qa_llms.base)": [[58, "qa_llms.base.GenerationOutput"]], "_prepare_question_w_docs() (qa_llms.base.baseqamodel method)": [[58, "qa_llms.base.BaseQAModel._prepare_question_w_docs"]], "batch_answers (qa_llms.base.generationoutput attribute)": [[58, "qa_llms.base.GenerationOutput.batch_answers"]], "generate() (qa_llms.base.baseqamodel method)": [[58, "qa_llms.base.BaseQAModel.generate"]], "is_api_model (qa_llms.base.baseqamodel attribute)": [[58, "qa_llms.base.BaseQAModel.is_api_model"]], "qa_llms.base": [[58, "module-qa_llms.base"]], "r_generate() (qa_llms.base.baseqamodel method)": [[58, "qa_llms.base.BaseQAModel.r_generate"]], "run() (qa_llms.base.baseqamodel method)": [[58, "qa_llms.base.BaseQAModel.run"]], "run_input_keys (qa_llms.base.baseqamodel attribute)": [[58, "qa_llms.base.BaseQAModel.run_input_keys"]], "checkpointwrapper (class in qa_llms.fid)": [[59, "qa_llms.fid.CheckpointWrapper"]], "encoderwrapper (class in qa_llms.fid)": [[59, "qa_llms.fid.EncoderWrapper"]], "fidt5 (class in qa_llms.fid)": [[59, "qa_llms.fid.FiDT5"]], "apply_checkpoint_wrapper() (in module qa_llms.fid)": [[59, "qa_llms.fid.apply_checkpoint_wrapper"]], "cross_attention_forward() (in module qa_llms.fid)": [[59, "qa_llms.fid.cross_attention_forward"]], "forward() (qa_llms.fid.checkpointwrapper method)": [[59, "qa_llms.fid.CheckpointWrapper.forward"]], "forward() (qa_llms.fid.encoderwrapper method)": [[59, "qa_llms.fid.EncoderWrapper.forward"]], "forward() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.forward"]], "forward_() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.forward_"]], "from_t5() (qa_llms.fid.fidt5 static method)": [[59, "qa_llms.fid.FiDT5.from_t5"]], "generate() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.generate"]], "get_crossattention_scores() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.get_crossattention_scores"]], "load_t5() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.load_t5"]], "overwrite_forward_crossattention() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.overwrite_forward_crossattention"]], "qa_llms.fid": [[59, "module-qa_llms.fid"]], "reset_score_storage() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.reset_score_storage"]], "set_checkpoint() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.set_checkpoint"]], "unwrap_encoder() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.unwrap_encoder"]], "wrap_encoder() (qa_llms.fid.fidt5 method)": [[59, "qa_llms.fid.FiDT5.wrap_encoder"]], "huggingfacefidqamodel (class in qa_llms.huggingface)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel"]], "huggingfaceqamodel (class in qa_llms.huggingface)": [[60, "qa_llms.huggingface.HuggingFaceQAModel"]], "_init() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel._init"]], "_init() (qa_llms.huggingface.huggingfaceqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceQAModel._init"]], "_prepare_question_w_docs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel._prepare_question_w_docs"]], "_prepare_question_w_docs() (qa_llms.huggingface.huggingfaceqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceQAModel._prepare_question_w_docs"]], "encode_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel.encode_fid_inputs"]], "generate() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel.generate"]], "generate() (qa_llms.huggingface.huggingfaceqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceQAModel.generate"]], "pack_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel.pack_fid_inputs"]], "qa_llms.huggingface": [[60, "module-qa_llms.huggingface"]], "r_generate() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel.r_generate"]], "r_generate() (qa_llms.huggingface.huggingfaceqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceQAModel.r_generate"]], "unpack_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[60, "qa_llms.huggingface.HuggingFaceFiDQAModel.unpack_fid_inputs"]], "qa_llms": [[61, "module-qa_llms"]], "openaiqamodel (class in qa_llms.openai)": [[62, "qa_llms.openai.OpenAIQAModel"]], "_prepare_question_w_docs() (qa_llms.openai.openaiqamodel method)": [[62, "qa_llms.openai.OpenAIQAModel._prepare_question_w_docs"]], "generate() (qa_llms.openai.openaiqamodel method)": [[62, "qa_llms.openai.OpenAIQAModel.generate"]], "qa_llms.openai": [[62, "module-qa_llms.openai"]], "r_generate() (qa_llms.openai.openaiqamodel method)": [[62, "qa_llms.openai.OpenAIQAModel.r_generate"]], "rqa_prompt (in module qa_llms.prompts)": [[63, "qa_llms.prompts.RQA_PROMPT"]], "rqa_prompt_train (in module qa_llms.prompts)": [[63, "qa_llms.prompts.RQA_PROMPT_TRAIN"]], "qa_llms.prompts": [[63, "module-qa_llms.prompts"]], "sglangclient (class in qa_llms.sglang)": [[64, "qa_llms.sglang.SGLangClient"]], "sglangqamodel (class in qa_llms.sglang)": [[64, "qa_llms.sglang.SGLangQAModel"]], "_generate() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel._generate"]], "_generate_stream() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel._generate_stream"]], "_get_response() (qa_llms.sglang.sglangclient method)": [[64, "qa_llms.sglang.SGLangClient._get_response"]], "_get_streaming_response() (qa_llms.sglang.sglangclient method)": [[64, "qa_llms.sglang.SGLangClient._get_streaming_response"]], "_post_http_request() (qa_llms.sglang.sglangclient method)": [[64, "qa_llms.sglang.SGLangClient._post_http_request"]], "_prepare_question_w_docs() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel._prepare_question_w_docs"]], "generate() (qa_llms.sglang.sglangclient method)": [[64, "qa_llms.sglang.SGLangClient.generate"]], "generate() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel.generate"]], "generate_stream() (qa_llms.sglang.sglangclient method)": [[64, "qa_llms.sglang.SGLangClient.generate_stream"]], "is_api_model (qa_llms.sglang.sglangqamodel attribute)": [[64, "qa_llms.sglang.SGLangQAModel.is_api_model"]], "logger (in module qa_llms.sglang)": [[64, "qa_llms.sglang.logger"]], "prepare_gen_kwargs() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel.prepare_gen_kwargs"]], "qa_llms.sglang": [[64, "module-qa_llms.sglang"]], "r_generate() (qa_llms.sglang.sglangqamodel method)": [[64, "qa_llms.sglang.SGLangQAModel.r_generate"]], "rqa_model (in module qa_llms.sglang)": [[64, "qa_llms.sglang.rqa_model"]], "tgiqamodel (class in qa_llms.tgi)": [[65, "qa_llms.tgi.TGIQAModel"]], "_generate() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel._generate"]], "_generate_stream() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel._generate_stream"]], "_prepare_question_w_docs() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel._prepare_question_w_docs"]], "generate() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel.generate"]], "is_api_model (qa_llms.tgi.tgiqamodel attribute)": [[65, "qa_llms.tgi.TGIQAModel.is_api_model"]], "logger (in module qa_llms.tgi)": [[65, "qa_llms.tgi.logger"]], "prepare_gen_kwargs() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel.prepare_gen_kwargs"]], "qa_llms.tgi": [[65, "module-qa_llms.tgi"]], "r_generate() (qa_llms.tgi.tgiqamodel method)": [[65, "qa_llms.tgi.TGIQAModel.r_generate"]], "vllmclient (class in qa_llms.vllm)": [[66, "qa_llms.vllm.VLLMClient"]], "_generate() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel._generate"]], "_generate_stream() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel._generate_stream"]], "_get_response() (qa_llms.vllm.vllmclient method)": [[66, "qa_llms.vllm.VLLMClient._get_response"]], "_get_streaming_response() (qa_llms.vllm.vllmclient method)": [[66, "qa_llms.vllm.VLLMClient._get_streaming_response"]], "_post_http_request() (qa_llms.vllm.vllmclient method)": [[66, "qa_llms.vllm.VLLMClient._post_http_request"]], "_prepare_question_w_docs() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel._prepare_question_w_docs"]], "generate() (qa_llms.vllm.vllmclient method)": [[66, "qa_llms.vllm.VLLMClient.generate"]], "generate() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel.generate"]], "generate_stream() (qa_llms.vllm.vllmclient method)": [[66, "qa_llms.vllm.VLLMClient.generate_stream"]], "is_api_model (qa_llms.vllm.vllmqamodel attribute)": [[66, "qa_llms.vllm.vLLMQAModel.is_api_model"]], "logger (in module qa_llms.vllm)": [[66, "qa_llms.vllm.logger"]], "prepare_gen_kwargs() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel.prepare_gen_kwargs"]], "qa_llms.vllm": [[66, "module-qa_llms.vllm"]], "r_generate() (qa_llms.vllm.vllmqamodel method)": [[66, "qa_llms.vllm.vLLMQAModel.r_generate"]], "rqa_model (in module qa_llms.vllm)": [[66, "qa_llms.vllm.rqa_model"]], "vllmqamodel (class in qa_llms.vllm)": [[66, "qa_llms.vllm.vLLMQAModel"]], "prod_search_config (in module retriever_config)": [[67, "retriever_config.PROD_SEARCH_CONFIG"]], "search_config (in module retriever_config)": [[67, "retriever_config.SEARCH_CONFIG"]], "retriever_config": [[67, "module-retriever_config"]], "fidretrievertrainer (class in retriever_fid_trainer)": [[68, "retriever_fid_trainer.FidRetrieverTrainer"]], "_load_all_docs() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer._load_eval_data"]], "_save() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer._save"]], "compute_loss() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.compute_loss"]], "embed_text() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.embed_text"]], "evaluation_loop() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.evaluation_loop"]], "kldivloss() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.kldivloss"]], "prediction_step() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.prediction_step"]], "retriever_fid_trainer": [[68, "module-retriever_fid_trainer"]], "wrap_model_for_eval() (retriever_fid_trainer.fidretrievertrainer method)": [[68, "retriever_fid_trainer.FidRetrieverTrainer.wrap_model_for_eval"]], "green (in module retriever_replug_trainer)": [[69, "retriever_replug_trainer.GREEN"]], "ignore_token_id (in module retriever_replug_trainer)": [[69, "retriever_replug_trainer.IGNORE_TOKEN_ID"]], "prompt (in module retriever_replug_trainer)": [[69, "retriever_replug_trainer.PROMPT"]], "red (in module retriever_replug_trainer)": [[69, "retriever_replug_trainer.RED"]], "reset (in module retriever_replug_trainer)": [[69, "retriever_replug_trainer.RESET"]], "replugretrievertrainer (class in retriever_replug_trainer)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer"]], "_load_all_docs() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer._load_eval_data"]], "_save() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer._save"]], "compute_loss() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.compute_loss"]], "evaluation_loop() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.evaluation_loop"]], "get_seq_prob() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.get_seq_prob"]], "instruct() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.instruct"]], "kldivloss() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.kldivloss"]], "prediction_step() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.prediction_step"]], "retriever_replug_trainer": [[69, "module-retriever_replug_trainer"]], "wrap_model_for_eval() (retriever_replug_trainer.replugretrievertrainer method)": [[69, "retriever_replug_trainer.ReplugRetrieverTrainer.wrap_model_for_eval"]], "retrievertrainer (class in retriever_trainer)": [[70, "retriever_trainer.RetrieverTrainer"]], "_inbatch_contrastive_w_hardneg() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer._inbatch_contrastive_w_hardneg"]], "_load_all_docs() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer._load_eval_data"]], "_save() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer._save"]], "compute_loss() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer.compute_loss"]], "evaluation_loop() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer.evaluation_loop"]], "prediction_step() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer.prediction_step"]], "retriever_trainer": [[70, "module-retriever_trainer"]], "wrap_model_for_eval() (retriever_trainer.retrievertrainer method)": [[70, "retriever_trainer.RetrieverTrainer.wrap_model_for_eval"]], "baseretriever (class in retrievers.base)": [[71, "retrievers.base.BaseRetriever"]], "dummyretriever (class in retrievers.base)": [[71, "retrievers.base.DummyRetriever"]], "retrievaloutput (class in retrievers.base)": [[71, "retrievers.base.RetrievalOutput"]], "batch_source_documents (retrievers.base.retrievaloutput attribute)": [[71, "retrievers.base.RetrievalOutput.batch_source_documents"]], "retrieve() (retrievers.base.baseretriever method)": [[71, "retrievers.base.BaseRetriever.retrieve"]], "retrieve() (retrievers.base.dummyretriever method)": [[71, "retrievers.base.DummyRetriever.retrieve"]], "retrievers.base": [[71, "module-retrievers.base"]], "run() (retrievers.base.baseretriever method)": [[71, "retrievers.base.BaseRetriever.run"]], "run_input_keys (retrievers.base.baseretriever attribute)": [[71, "retrievers.base.BaseRetriever.run_input_keys"]], "bm25retriever (class in retrievers.bm25_retriever)": [[72, "retrievers.bm25_retriever.BM25Retriever"]], "bm25tokenizer (class in retrievers.bm25_retriever)": [[72, "retrievers.bm25_retriever.BM25Tokenizer"]], "__call__() (retrievers.bm25_retriever.bm25tokenizer method)": [[72, "retrievers.bm25_retriever.BM25Tokenizer.__call__"]], "normalize_string() (in module retrievers.bm25_retriever)": [[72, "retrievers.bm25_retriever.normalize_string"]], "retrieve() (retrievers.bm25_retriever.bm25retriever method)": [[72, "retrievers.bm25_retriever.BM25Retriever.retrieve"]], "retrievers.bm25_retriever": [[72, "module-retrievers.bm25_retriever"]], "faissretriever (class in retrievers.faiss_retriever)": [[73, "retrievers.faiss_retriever.FaissRetriever"]], "_init_retriever() (retrievers.faiss_retriever.faissretriever method)": [[73, "retrievers.faiss_retriever.FaissRetriever._init_retriever"]], "from_disk() (retrievers.faiss_retriever.faissretriever static method)": [[73, "retrievers.faiss_retriever.FaissRetriever.from_disk"]], "logger (in module retrievers.faiss_retriever)": [[73, "retrievers.faiss_retriever.logger"]], "prepare_docs_for_retrieval() (retrievers.faiss_retriever.faissretriever method)": [[73, "retrievers.faiss_retriever.FaissRetriever.prepare_docs_for_retrieval"]], "retrieve() (retrievers.faiss_retriever.faissretriever method)": [[73, "retrievers.faiss_retriever.FaissRetriever.retrieve"]], "retrieve_w_score() (retrievers.faiss_retriever.faissretriever method)": [[73, "retrievers.faiss_retriever.FaissRetriever.retrieve_w_score"]], "retrievers.faiss_retriever": [[73, "module-retrievers.faiss_retriever"]], "retrievers": [[74, "module-retrievers"]], "dialoguesession (class in schema.dialogue)": [[75, "schema.dialogue.DialogueSession"]], "dialogueturn (class in schema.dialogue)": [[75, "schema.dialogue.DialogueTurn"]], "rqaoutput (class in schema.dialogue)": [[75, "schema.dialogue.RQAOutput"]], "single (schema.dialogue.separatorstyle attribute)": [[75, "schema.dialogue.SeparatorStyle.SINGLE"]], "separatorstyle (class in schema.dialogue)": [[75, "schema.dialogue.SeparatorStyle"]], "two (schema.dialogue.separatorstyle attribute)": [[75, "schema.dialogue.SeparatorStyle.TWO"]], "add_system_message() (schema.dialogue.dialoguesession method)": [[75, "schema.dialogue.DialogueSession.add_system_message"]], "add_user_message() (schema.dialogue.dialoguesession method)": [[75, "schema.dialogue.DialogueSession.add_user_message"]], "assistant_prefix (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.assistant_prefix"]], "batch_answers (schema.dialogue.rqaoutput attribute)": [[75, "schema.dialogue.RQAOutput.batch_answers"]], "batch_dialogue_session (schema.dialogue.rqaoutput attribute)": [[75, "schema.dialogue.RQAOutput.batch_dialogue_session"]], "batch_source_documents (schema.dialogue.rqaoutput attribute)": [[75, "schema.dialogue.RQAOutput.batch_source_documents"]], "clone() (schema.dialogue.dialoguesession method)": [[75, "schema.dialogue.DialogueSession.clone"]], "clone() (schema.dialogue.dialogueturn method)": [[75, "schema.dialogue.DialogueTurn.clone"]], "from_dict() (schema.dialogue.dialogueturn static method)": [[75, "schema.dialogue.DialogueTurn.from_dict"]], "from_list() (schema.dialogue.dialoguesession static method)": [[75, "schema.dialogue.DialogueSession.from_list"]], "history (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.history"]], "message (schema.dialogue.dialogueturn attribute)": [[75, "schema.dialogue.DialogueTurn.message"]], "schema.dialogue": [[75, "module-schema.dialogue"]], "sep_style (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.sep_style"]], "sep_sys (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.sep_sys"]], "sep_user (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.sep_user"]], "source_documents (schema.dialogue.dialogueturn attribute)": [[75, "schema.dialogue.DialogueTurn.source_documents"]], "speaker (schema.dialogue.dialogueturn attribute)": [[75, "schema.dialogue.DialogueTurn.speaker"]], "to_dict() (schema.dialogue.dialogueturn method)": [[75, "schema.dialogue.DialogueTurn.to_dict"]], "to_list() (schema.dialogue.dialoguesession method)": [[75, "schema.dialogue.DialogueSession.to_list"]], "to_string() (schema.dialogue.dialoguesession method)": [[75, "schema.dialogue.DialogueSession.to_string"]], "to_string() (schema.dialogue.dialogueturn method)": [[75, "schema.dialogue.DialogueTurn.to_string"]], "user_prefix (schema.dialogue.dialoguesession attribute)": [[75, "schema.dialogue.DialogueSession.user_prefix"]], "document (class in schema.document)": [[76, "schema.document.Document"]], "__post_init__() (schema.document.document method)": [[76, "schema.document.Document.__post_init__"]], "clone() (schema.document.document method)": [[76, "schema.document.Document.clone"]], "default_document_formatter() (in module schema.document)": [[76, "schema.document.default_document_formatter"]], "fmt_content (schema.document.document attribute)": [[76, "schema.document.Document.fmt_content"]], "from_dict() (schema.document.document static method)": [[76, "schema.document.Document.from_dict"]], "from_langchain_doc() (schema.document.document static method)": [[76, "schema.document.Document.from_langchain_doc"]], "metadata (schema.document.document attribute)": [[76, "schema.document.Document.metadata"]], "page_content (schema.document.document attribute)": [[76, "schema.document.Document.page_content"]], "schema.document": [[76, "module-schema.document"]], "to_dict() (schema.document.document method)": [[76, "schema.document.Document.to_dict"]], "to_langchain_doc() (schema.document.document method)": [[76, "schema.document.Document.to_langchain_doc"]], "schema": [[77, "module-schema"]], "basemodelworker (class in serve.base_model_worker)": [[78, "serve.base_model_worker.BaseModelWorker"]], "acquire_worker_semaphore() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.acquire_worker_semaphore"]], "api_count_token() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_count_token"]], "api_generate() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_generate"]], "api_generate_stream() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_generate_stream"]], "api_get_conv() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_get_conv"]], "api_get_status() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_get_status"]], "api_model_details() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_model_details"]], "api_retrieval() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.api_retrieval"]], "app (in module serve.base_model_worker)": [[78, "serve.base_model_worker.app"]], "count_token() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.count_token"]], "create_background_tasks() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.create_background_tasks"]], "generate_gate() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.generate_gate"]], "generate_stream_gate() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.generate_stream_gate"]], "get_queue_length() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.get_queue_length"]], "get_status() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.get_status"]], "heart_beat_worker() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.heart_beat_worker"]], "init_heart_beat() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.init_heart_beat"]], "logger (in module serve.base_model_worker)": [[78, "serve.base_model_worker.logger"]], "register_to_controller() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.register_to_controller"]], "release_worker_semaphore() (in module serve.base_model_worker)": [[78, "serve.base_model_worker.release_worker_semaphore"]], "retrieve() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.retrieve"]], "send_heart_beat() (serve.base_model_worker.basemodelworker method)": [[78, "serve.base_model_worker.BaseModelWorker.send_heart_beat"]], "serve.base_model_worker": [[78, "module-serve.base_model_worker"]], "worker (in module serve.base_model_worker)": [[78, "serve.base_model_worker.worker"]], "programmaticchatio (class in serve.cli)": [[79, "serve.cli.ProgrammaticChatIO"]], "richchatio (class in serve.cli)": [[79, "serve.cli.RichChatIO"]], "simplechatio (class in serve.cli)": [[79, "serve.cli.SimpleChatIO"]], "_() (serve.cli.richchatio method)": [[79, "serve.cli.RichChatIO._"]], "bindings (serve.cli.richchatio attribute)": [[79, "serve.cli.RichChatIO.bindings"]], "main() (in module serve.cli)": [[79, "serve.cli.main"]], "parser (in module serve.cli)": [[79, "serve.cli.parser"]], "print_output() (serve.cli.programmaticchatio method)": [[79, "serve.cli.ProgrammaticChatIO.print_output"]], "print_output() (serve.cli.richchatio method)": [[79, "serve.cli.RichChatIO.print_output"]], "print_output() (serve.cli.simplechatio method)": [[79, "serve.cli.SimpleChatIO.print_output"]], "prompt_for_input() (serve.cli.programmaticchatio method)": [[79, "serve.cli.ProgrammaticChatIO.prompt_for_input"]], "prompt_for_input() (serve.cli.richchatio method)": [[79, "serve.cli.RichChatIO.prompt_for_input"]], "prompt_for_input() (serve.cli.simplechatio method)": [[79, "serve.cli.SimpleChatIO.prompt_for_input"]], "prompt_for_output() (serve.cli.programmaticchatio method)": [[79, "serve.cli.ProgrammaticChatIO.prompt_for_output"]], "prompt_for_output() (serve.cli.richchatio method)": [[79, "serve.cli.RichChatIO.prompt_for_output"]], "prompt_for_output() (serve.cli.simplechatio method)": [[79, "serve.cli.SimpleChatIO.prompt_for_output"]], "serve.cli": [[79, "module-serve.cli"]], "stream_output() (serve.cli.programmaticchatio method)": [[79, "serve.cli.ProgrammaticChatIO.stream_output"]], "stream_output() (serve.cli.richchatio method)": [[79, "serve.cli.RichChatIO.stream_output"]], "stream_output() (serve.cli.simplechatio method)": [[79, "serve.cli.SimpleChatIO.stream_output"]], "controller (class in serve.controller)": [[80, "serve.controller.Controller"]], "dispatchmethod (class in serve.controller)": [[80, "serve.controller.DispatchMethod"]], "lottery (serve.controller.dispatchmethod attribute)": [[80, "serve.controller.DispatchMethod.LOTTERY"]], "shortest_queue (serve.controller.dispatchmethod attribute)": [[80, "serve.controller.DispatchMethod.SHORTEST_QUEUE"]], "workerinfo (class in serve.controller)": [[80, "serve.controller.WorkerInfo"]], "app (in module serve.controller)": [[80, "serve.controller.app"]], "check_heart_beat (serve.controller.workerinfo attribute)": [[80, "serve.controller.WorkerInfo.check_heart_beat"]], "create_controller() (in module serve.controller)": [[80, "serve.controller.create_controller"]], "from_str() (serve.controller.dispatchmethod class method)": [[80, "serve.controller.DispatchMethod.from_str"]], "get_worker_address() (in module serve.controller)": [[80, "serve.controller.get_worker_address"]], "get_worker_address() (serve.controller.controller method)": [[80, "serve.controller.Controller.get_worker_address"]], "get_worker_status() (serve.controller.controller method)": [[80, "serve.controller.Controller.get_worker_status"]], "handle_no_worker() (serve.controller.controller method)": [[80, "serve.controller.Controller.handle_no_worker"]], "handle_worker_timeout() (serve.controller.controller method)": [[80, "serve.controller.Controller.handle_worker_timeout"]], "heart_beat_controller() (in module serve.controller)": [[80, "serve.controller.heart_beat_controller"]], "last_heart_beat (serve.controller.workerinfo attribute)": [[80, "serve.controller.WorkerInfo.last_heart_beat"]], "list_models() (in module serve.controller)": [[80, "serve.controller.list_models"]], "list_models() (serve.controller.controller method)": [[80, "serve.controller.Controller.list_models"]], "logger (in module serve.controller)": [[80, "serve.controller.logger"]], "model_names (serve.controller.workerinfo attribute)": [[80, "serve.controller.WorkerInfo.model_names"]], "queue_length (serve.controller.workerinfo attribute)": [[80, "serve.controller.WorkerInfo.queue_length"]], "receive_heart_beat() (in module serve.controller)": [[80, "serve.controller.receive_heart_beat"]], "receive_heart_beat() (serve.controller.controller method)": [[80, "serve.controller.Controller.receive_heart_beat"]], "refresh_all_workers() (in module serve.controller)": [[80, "serve.controller.refresh_all_workers"]], "refresh_all_workers() (serve.controller.controller method)": [[80, "serve.controller.Controller.refresh_all_workers"]], "register_worker() (in module serve.controller)": [[80, "serve.controller.register_worker"]], "register_worker() (serve.controller.controller method)": [[80, "serve.controller.Controller.register_worker"]], "remove_stale_workers_by_expiration() (serve.controller.controller method)": [[80, "serve.controller.Controller.remove_stale_workers_by_expiration"]], "remove_worker() (serve.controller.controller method)": [[80, "serve.controller.Controller.remove_worker"]], "serve.controller": [[80, "module-serve.controller"]], "speed (serve.controller.workerinfo attribute)": [[80, "serve.controller.WorkerInfo.speed"]], "worker_api_generate_stream() (in module serve.controller)": [[80, "serve.controller.worker_api_generate_stream"]], "worker_api_generate_stream() (serve.controller.controller method)": [[80, "serve.controller.Controller.worker_api_generate_stream"]], "worker_api_get_status() (in module serve.controller)": [[80, "id0"], [80, "serve.controller.worker_api_get_status"]], "worker_api_get_status() (serve.controller.controller method)": [[80, "serve.controller.Controller.worker_api_get_status"]], "worker_api_retrieval() (in module serve.controller)": [[80, "serve.controller.worker_api_retrieval"]], "worker_api_retrieval() (serve.controller.controller method)": [[80, "serve.controller.Controller.worker_api_retrieval"]], "annotationhistory (class in serve.gradio_dialogue)": [[81, "serve.gradio_dialogue.AnnotationHistory"]], "gradiodialoguesession (class in serve.gradio_dialogue)": [[81, "serve.gradio_dialogue.GradioDialogueSession"]], "_data_idx_filter() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory._data_idx_filter"]], "_session (serve.gradio_dialogue.gradiodialoguesession attribute)": [[81, "serve.gradio_dialogue.GradioDialogueSession._session"]], "_tmp_data (serve.gradio_dialogue.gradiodialoguesession attribute)": [[81, "serve.gradio_dialogue.GradioDialogueSession._tmp_data"]], "add_system_message() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.add_system_message"]], "add_user_message() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.add_user_message"]], "clone() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.clone"]], "conv_templates (in module serve.gradio_dialogue)": [[81, "serve.gradio_dialogue.conv_templates"]], "conv_vicuna_v1 (in module serve.gradio_dialogue)": [[81, "serve.gradio_dialogue.conv_vicuna_v1"]], "default_conversation (in module serve.gradio_dialogue)": [[81, "serve.gradio_dialogue.default_conversation"]], "get_current_idx() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_current_idx"]], "get_current_label() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_current_label"]], "get_next_idx() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_next_idx"]], "get_num_labeled() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_num_labeled"]], "get_num_to_label() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_num_to_label"]], "get_prev_idx() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.get_prev_idx"]], "get_prompt() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.get_prompt"]], "is_all_labeled() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.is_all_labeled"]], "load() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.load"]], "parse_int_range() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.parse_int_range"]], "serve.gradio_dialogue": [[81, "module-serve.gradio_dialogue"]], "skip_next (serve.gradio_dialogue.gradiodialoguesession attribute)": [[81, "serve.gradio_dialogue.GradioDialogueSession.skip_next"]], "to_dict() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.to_dict"]], "to_gradio_chatbot() (serve.gradio_dialogue.gradiodialoguesession method)": [[81, "serve.gradio_dialogue.GradioDialogueSession.to_gradio_chatbot"]], "to_jsonl() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.to_jsonl"]], "update_label() (serve.gradio_dialogue.annotationhistory method)": [[81, "serve.gradio_dialogue.AnnotationHistory.update_label"]], "gradiorqa (class in serve.gradio_rqa)": [[82, "serve.gradio_rqa.GradioRQA"]], "gradiosimplerqa (class in serve.gradio_rqa)": [[82, "serve.gradio_rqa.GradioSimpleRQA"]], "from_scratch() (serve.gradio_rqa.gradiosimplerqa class method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.from_scratch"]], "generate_stream_from_api() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.generate_stream_from_api"]], "generate_stream_from_api() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.generate_stream_from_api"]], "get_model() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.get_model"]], "get_model() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.get_model"]], "get_tokenizer() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.get_tokenizer"]], "get_tokenizer() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.get_tokenizer"]], "logger (in module serve.gradio_rqa)": [[82, "serve.gradio_rqa.logger"]], "prepare_prompt_for_generation() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.prepare_prompt_for_generation"]], "prepare_prompt_for_generation() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.prepare_prompt_for_generation"]], "rephrase_question_for_retrieval() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.rephrase_question_for_retrieval"]], "rephrase_question_for_retrieval() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.rephrase_question_for_retrieval"]], "retrieve() (serve.gradio_rqa.gradiorqa method)": [[82, "serve.gradio_rqa.GradioRQA.retrieve"]], "retrieve() (serve.gradio_rqa.gradiosimplerqa method)": [[82, "serve.gradio_rqa.GradioSimpleRQA.retrieve"]], "serve.gradio_rqa": [[82, "module-serve.gradio_rqa"]], "ann_correct (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_CORRECT"]], "ann_harmful (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_HARMFUL"]], "ann_helpful (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_HELPFUL"]], "ann_incorrect (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_INCORRECT"]], "ann_not_harmful (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_NOT_HARMFUL"]], "ann_not_helpful (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.ANN_NOT_HELPFUL"]], "num_doc_to_retrieve (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.NUM_DOC_TO_RETRIEVE"]], "args (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.args"]], "block_css (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.block_css"]], "block_js (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.block_js"]], "build_demo() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.build_demo"]], "disable_btn (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.disable_btn"]], "document_view() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.document_view"]], "enable_btn (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.enable_btn"]], "get_conv_log_filename() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.get_conv_log_filename"]], "headers (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.headers"]], "learn_more_markdown (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.learn_more_markdown"]], "load_demo() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.load_demo"]], "logger (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.logger"]], "no_change_btn (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.no_change_btn"]], "parser (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.parser"]], "render_next_session() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.render_next_session"]], "render_prev_session() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.render_prev_session"]], "render_single_session() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.render_single_session"]], "save_annotations() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.save_annotations"]], "serve.gradio_static_server": [[83, "module-serve.gradio_static_server"]], "title_markdown (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.title_markdown"]], "tos_markdown (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.tos_markdown"]], "vote_correctness() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.vote_correctness"]], "vote_harmlessness() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.vote_harmlessness"]], "vote_helpfulness() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.vote_helpfulness"]], "vote_response() (in module serve.gradio_static_server)": [[83, "serve.gradio_static_server.vote_response"]], "num_doc_to_retrieve (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.NUM_DOC_TO_RETRIEVE"]], "add_text() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.add_text"]], "args (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.args"]], "block_css (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.block_css"]], "block_js (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.block_js"]], "build_demo() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.build_demo"]], "clear_history() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.clear_history"]], "disable_btn (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.disable_btn"]], "document_view() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.document_view"]], "downvote_last_response() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.downvote_last_response"]], "enable_btn (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.enable_btn"]], "flag_last_response() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.flag_last_response"]], "get_conv_log_filename() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.get_conv_log_filename"]], "get_model_list() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.get_model_list"]], "headers (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.headers"]], "http_generate() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.http_generate"]], "http_retrieve() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.http_retrieve"]], "learn_more_markdown (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.learn_more_markdown"]], "load_demo() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.load_demo"]], "load_demo_refresh_model_list() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.load_demo_refresh_model_list"]], "logger (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.logger"]], "no_change_btn (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.no_change_btn"]], "parser (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.parser"]], "regenerate() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.regenerate"]], "serve.gradio_web_server": [[84, "module-serve.gradio_web_server"]], "title_markdown (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.title_markdown"]], "tos_markdown (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.tos_markdown"]], "upvote_last_response() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.upvote_last_response"]], "violates_moderation() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.violates_moderation"]], "vote_last_response() (in module serve.gradio_web_server)": [[84, "serve.gradio_web_server.vote_last_response"]], "serve": [[85, "module-serve"]], "chatio (class in serve.inference)": [[86, "serve.inference.ChatIO"]], "chat_loop() (in module serve.inference)": [[86, "serve.inference.chat_loop"]], "generate_stream() (in module serve.inference)": [[86, "serve.inference.generate_stream"]], "prepare_logits_processor() (in module serve.inference)": [[86, "serve.inference.prepare_logits_processor"]], "print_output() (serve.inference.chatio method)": [[86, "serve.inference.ChatIO.print_output"]], "prompt_for_input() (serve.inference.chatio method)": [[86, "serve.inference.ChatIO.prompt_for_input"]], "prompt_for_output() (serve.inference.chatio method)": [[86, "serve.inference.ChatIO.prompt_for_output"]], "serve.inference": [[86, "module-serve.inference"]], "stream_output() (serve.inference.chatio method)": [[86, "serve.inference.ChatIO.stream_output"]], "modelworker (class in serve.model_worker)": [[87, "serve.model_worker.ModelWorker"]], "add_model_args() (in module serve.model_worker)": [[87, "serve.model_worker.add_model_args"]], "create_model_worker() (in module serve.model_worker)": [[87, "serve.model_worker.create_model_worker"]], "generate_gate() (serve.model_worker.modelworker method)": [[87, "serve.model_worker.ModelWorker.generate_gate"]], "generate_stream() (serve.model_worker.modelworker method)": [[87, "serve.model_worker.ModelWorker.generate_stream"]], "generate_stream_gate() (serve.model_worker.modelworker method)": [[87, "serve.model_worker.ModelWorker.generate_stream_gate"]], "load_model() (in module serve.model_worker)": [[87, "serve.model_worker.load_model"]], "logger (in module serve.model_worker)": [[87, "serve.model_worker.logger"]], "retrieve() (serve.model_worker.modelworker method)": [[87, "serve.model_worker.ModelWorker.retrieve"]], "serve.model_worker": [[87, "module-serve.model_worker"]], "worker_id (in module serve.model_worker)": [[87, "serve.model_worker.worker_id"]], "main() (in module serve.test_message)": [[88, "serve.test_message.main"]], "parser (in module serve.test_message)": [[88, "serve.test_message.parser"]], "serve.test_message": [[88, "module-serve.test_message"]], "supervisedfidtrainer (class in supervised_fid_trainer)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer"]], "_load_eval_data() (supervised_fid_trainer.supervisedfidtrainer method)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer._load_eval_data"]], "compute_loss() (supervised_fid_trainer.supervisedfidtrainer method)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer.compute_loss"]], "evaluation_loop() (supervised_fid_trainer.supervisedfidtrainer method)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer.evaluation_loop"]], "prediction_step() (supervised_fid_trainer.supervisedfidtrainer method)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer.prediction_step"]], "supervised_fid_trainer": [[89, "module-supervised_fid_trainer"]], "wrap_model_for_eval() (supervised_fid_trainer.supervisedfidtrainer method)": [[89, "supervised_fid_trainer.SupervisedFiDTrainer.wrap_model_for_eval"]], "supervisedtrainer (class in supervised_trainer)": [[90, "supervised_trainer.SupervisedTrainer"]], "_load_eval_data() (supervised_trainer.supervisedtrainer method)": [[90, "supervised_trainer.SupervisedTrainer._load_eval_data"]], "compute_loss() (supervised_trainer.supervisedtrainer method)": [[90, "supervised_trainer.SupervisedTrainer.compute_loss"]], "evaluation_loop() (supervised_trainer.supervisedtrainer method)": [[90, "supervised_trainer.SupervisedTrainer.evaluation_loop"]], "prediction_step() (supervised_trainer.supervisedtrainer method)": [[90, "supervised_trainer.SupervisedTrainer.prediction_step"]], "supervised_trainer": [[90, "module-supervised_trainer"]], "wrap_model_for_eval() (supervised_trainer.supervisedtrainer method)": [[90, "supervised_trainer.SupervisedTrainer.wrap_model_for_eval"]], "basetextloader (class in text_loaders.base)": [[91, "text_loaders.base.BaseTextLoader"]], "_convert_doc() (text_loaders.base.basetextloader method)": [[91, "text_loaders.base.BaseTextLoader._convert_doc"]], "load_data() (text_loaders.base.basetextloader method)": [[91, "text_loaders.base.BaseTextLoader.load_data"]], "save_texts() (text_loaders.base.basetextloader method)": [[91, "text_loaders.base.BaseTextLoader.save_texts"]], "text_loaders.base": [[91, "module-text_loaders.base"]], "text_loaders": [[92, "module-text_loaders"]], "langchaintextloader (class in text_loaders.langchain_text_loader)": [[93, "text_loaders.langchain_text_loader.LangChainTextLoader"]], "load_data() (text_loaders.langchain_text_loader.langchaintextloader method)": [[93, "text_loaders.langchain_text_loader.LangChainTextLoader.load_data"]], "loader_parameters (in module text_loaders.langchain_text_loader)": [[93, "text_loaders.langchain_text_loader.loader_parameters"]], "save_texts() (text_loaders.langchain_text_loader.langchaintextloader method)": [[93, "text_loaders.langchain_text_loader.LangChainTextLoader.save_texts"]], "text_loaders.langchain_text_loader": [[93, "module-text_loaders.langchain_text_loader"]], "llamaindextextloader (class in text_loaders.llamaindex_text_loader)": [[94, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader"]], "load_data() (text_loaders.llamaindex_text_loader.llamaindextextloader method)": [[94, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader.load_data"]], "loader_func (in module text_loaders.llamaindex_text_loader)": [[94, "text_loaders.llamaindex_text_loader.loader_func"]], "save_texts() (text_loaders.llamaindex_text_loader.llamaindextextloader method)": [[94, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader.save_texts"]], "text_loaders.llamaindex_text_loader": [[94, "module-text_loaders.llamaindex_text_loader"]], "create_dir_if_not_exists() (in module utils)": [[95, "utils.create_dir_if_not_exists"]], "init_logger() (in module utils)": [[95, "utils.init_logger"]], "logger (in module utils)": [[95, "utils.logger"]], "remove_optimizer_weights() (in module utils)": [[95, "utils.remove_optimizer_weights"]], "utils": [[95, "module-utils"]], "with_retriever_fid_trainer": [[96, "module-with_retriever_fid_trainer"]], "fixedretrievertrainer (class in with_retriever_trainer)": [[97, "with_retriever_trainer.FixedRetrieverTrainer"]], "_load_all_docs() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer._load_all_docs"]], "_load_eval_data() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer._load_eval_data"]], "batch_iterator() (in module with_retriever_trainer)": [[97, "with_retriever_trainer.batch_iterator"]], "compute_loss() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer.compute_loss"]], "evaluation_loop() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer.evaluation_loop"]], "prediction_step() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer.prediction_step"]], "with_retriever_trainer": [[97, "module-with_retriever_trainer"]], "wrap_model_for_eval() (with_retriever_trainer.fixedretrievertrainer method)": [[97, "with_retriever_trainer.FixedRetrieverTrainer.wrap_model_for_eval"]]}})