Search.setIndex({"docnames": ["_autosummary/local_rqa", "_autosummary/local_rqa.base", "_autosummary/local_rqa.constants", "_autosummary/local_rqa.evaluation", "_autosummary/local_rqa.evaluation.metrics", "_autosummary/local_rqa.evaluation.scores", "_autosummary/local_rqa.evaluation.utils", "_autosummary/local_rqa.guardrails", "_autosummary/local_rqa.guardrails.base", "_autosummary/local_rqa.pipelines", "_autosummary/local_rqa.pipelines.base", "_autosummary/local_rqa.pipelines.prompts", "_autosummary/local_rqa.qa_llms", "_autosummary/local_rqa.qa_llms.base", "_autosummary/local_rqa.qa_llms.fid", "_autosummary/local_rqa.qa_llms.huggingface", "_autosummary/local_rqa.qa_llms.openai", "_autosummary/local_rqa.qa_llms.prompts", "_autosummary/local_rqa.qa_llms.sglang", "_autosummary/local_rqa.qa_llms.tgi", "_autosummary/local_rqa.qa_llms.vllm", "_autosummary/local_rqa.retrievers", "_autosummary/local_rqa.retrievers.base", "_autosummary/local_rqa.schema", "_autosummary/local_rqa.schema.dialogue", "_autosummary/local_rqa.schema.document", "_autosummary/local_rqa.serve", "_autosummary/local_rqa.serve.base_model_worker", "_autosummary/local_rqa.serve.gradio_dialogue", "_autosummary/local_rqa.serve.test_message", "_autosummary/local_rqa.text_loaders", "_autosummary/local_rqa.text_loaders.base", "_autosummary/local_rqa.text_loaders.langchain_text_loader", "_autosummary/local_rqa.text_loaders.llamaindex_text_loader", "_autosummary/local_rqa.utils", "autoapi/arguments/index", "autoapi/base/index", "autoapi/constants/index", "autoapi/datasets/index", "autoapi/dist_utils/index", "autoapi/embeddings/index", "autoapi/evaluation/evaluator/index", "autoapi/evaluation/index", "autoapi/evaluation/metrics/index", "autoapi/evaluation/scores/index", "autoapi/evaluation/utils/index", "autoapi/guardrails/base/index", "autoapi/guardrails/index", "autoapi/index", "autoapi/pipelines/base/index", "autoapi/pipelines/index", "autoapi/pipelines/prompts/index", "autoapi/pipelines/retrieval_qa/index", "autoapi/qa_llms/base/index", "autoapi/qa_llms/fid/index", "autoapi/qa_llms/huggingface/index", "autoapi/qa_llms/index", "autoapi/qa_llms/openai/index", "autoapi/qa_llms/prompts/index", "autoapi/qa_llms/sglang/index", "autoapi/qa_llms/tgi/index", "autoapi/qa_llms/vllm/index", "autoapi/retriever_fid_trainer/index", "autoapi/retriever_replug_trainer/index", "autoapi/retriever_trainer/index", "autoapi/retrievers/base/index", "autoapi/retrievers/bm25_retriever/index", "autoapi/retrievers/faiss_retriever/index", "autoapi/retrievers/index", "autoapi/schema/dialogue/index", "autoapi/schema/document/index", "autoapi/schema/index", "autoapi/serve/base_model_worker/index", "autoapi/serve/controller/index", "autoapi/serve/gradio_dialogue/index", "autoapi/serve/gradio_rqa/index", "autoapi/serve/gradio_static_server/index", "autoapi/serve/gradio_web_server/index", "autoapi/serve/index", "autoapi/serve/model_worker/index", "autoapi/serve/test_message/index", "autoapi/supervised_fid_trainer/index", "autoapi/supervised_trainer/index", "autoapi/text_loaders/base/index", "autoapi/text_loaders/index", "autoapi/text_loaders/langchain_text_loader/index", "autoapi/text_loaders/llamaindex_text_loader/index", "autoapi/utils/index", "autoapi/with_retriever_fid_trainer/index", "autoapi/with_retriever_trainer/index", "generated/local_rqa", "index"], "filenames": ["_autosummary/local_rqa.rst", "_autosummary/local_rqa.base.rst", "_autosummary/local_rqa.constants.rst", "_autosummary/local_rqa.evaluation.rst", "_autosummary/local_rqa.evaluation.metrics.rst", "_autosummary/local_rqa.evaluation.scores.rst", "_autosummary/local_rqa.evaluation.utils.rst", "_autosummary/local_rqa.guardrails.rst", "_autosummary/local_rqa.guardrails.base.rst", "_autosummary/local_rqa.pipelines.rst", "_autosummary/local_rqa.pipelines.base.rst", "_autosummary/local_rqa.pipelines.prompts.rst", "_autosummary/local_rqa.qa_llms.rst", "_autosummary/local_rqa.qa_llms.base.rst", "_autosummary/local_rqa.qa_llms.fid.rst", "_autosummary/local_rqa.qa_llms.huggingface.rst", "_autosummary/local_rqa.qa_llms.openai.rst", "_autosummary/local_rqa.qa_llms.prompts.rst", "_autosummary/local_rqa.qa_llms.sglang.rst", "_autosummary/local_rqa.qa_llms.tgi.rst", "_autosummary/local_rqa.qa_llms.vllm.rst", "_autosummary/local_rqa.retrievers.rst", "_autosummary/local_rqa.retrievers.base.rst", "_autosummary/local_rqa.schema.rst", "_autosummary/local_rqa.schema.dialogue.rst", "_autosummary/local_rqa.schema.document.rst", "_autosummary/local_rqa.serve.rst", "_autosummary/local_rqa.serve.base_model_worker.rst", "_autosummary/local_rqa.serve.gradio_dialogue.rst", "_autosummary/local_rqa.serve.test_message.rst", "_autosummary/local_rqa.text_loaders.rst", "_autosummary/local_rqa.text_loaders.base.rst", "_autosummary/local_rqa.text_loaders.langchain_text_loader.rst", "_autosummary/local_rqa.text_loaders.llamaindex_text_loader.rst", "_autosummary/local_rqa.utils.rst", "autoapi/arguments/index.rst", "autoapi/base/index.rst", "autoapi/constants/index.rst", "autoapi/datasets/index.rst", "autoapi/dist_utils/index.rst", "autoapi/embeddings/index.rst", "autoapi/evaluation/evaluator/index.rst", "autoapi/evaluation/index.rst", "autoapi/evaluation/metrics/index.rst", "autoapi/evaluation/scores/index.rst", "autoapi/evaluation/utils/index.rst", "autoapi/guardrails/base/index.rst", "autoapi/guardrails/index.rst", "autoapi/index.rst", "autoapi/pipelines/base/index.rst", "autoapi/pipelines/index.rst", "autoapi/pipelines/prompts/index.rst", "autoapi/pipelines/retrieval_qa/index.rst", "autoapi/qa_llms/base/index.rst", "autoapi/qa_llms/fid/index.rst", "autoapi/qa_llms/huggingface/index.rst", "autoapi/qa_llms/index.rst", "autoapi/qa_llms/openai/index.rst", "autoapi/qa_llms/prompts/index.rst", "autoapi/qa_llms/sglang/index.rst", "autoapi/qa_llms/tgi/index.rst", "autoapi/qa_llms/vllm/index.rst", "autoapi/retriever_fid_trainer/index.rst", "autoapi/retriever_replug_trainer/index.rst", "autoapi/retriever_trainer/index.rst", "autoapi/retrievers/base/index.rst", "autoapi/retrievers/bm25_retriever/index.rst", "autoapi/retrievers/faiss_retriever/index.rst", "autoapi/retrievers/index.rst", "autoapi/schema/dialogue/index.rst", "autoapi/schema/document/index.rst", "autoapi/schema/index.rst", "autoapi/serve/base_model_worker/index.rst", "autoapi/serve/controller/index.rst", "autoapi/serve/gradio_dialogue/index.rst", "autoapi/serve/gradio_rqa/index.rst", "autoapi/serve/gradio_static_server/index.rst", "autoapi/serve/gradio_web_server/index.rst", "autoapi/serve/index.rst", "autoapi/serve/model_worker/index.rst", "autoapi/serve/test_message/index.rst", "autoapi/supervised_fid_trainer/index.rst", "autoapi/supervised_trainer/index.rst", "autoapi/text_loaders/base/index.rst", "autoapi/text_loaders/index.rst", "autoapi/text_loaders/langchain_text_loader/index.rst", "autoapi/text_loaders/llamaindex_text_loader/index.rst", "autoapi/utils/index.rst", "autoapi/with_retriever_fid_trainer/index.rst", "autoapi/with_retriever_trainer/index.rst", "generated/local_rqa.rst", "index.rst"], "titles": ["local_rqa", "local_rqa.base", "local_rqa.constants", "local_rqa.evaluation", "local_rqa.evaluation.metrics", "local_rqa.evaluation.scores", "local_rqa.evaluation.utils", "local_rqa.guardrails", "local_rqa.guardrails.base", "local_rqa.pipelines", "local_rqa.pipelines.base", "local_rqa.pipelines.prompts", "local_rqa.qa_llms", "local_rqa.qa_llms.base", "local_rqa.qa_llms.fid", "local_rqa.qa_llms.huggingface", "local_rqa.qa_llms.openai", "local_rqa.qa_llms.prompts", "local_rqa.qa_llms.sglang", "local_rqa.qa_llms.tgi", "local_rqa.qa_llms.vllm", "local_rqa.retrievers", "local_rqa.retrievers.base", "local_rqa.schema", "local_rqa.schema.dialogue", "local_rqa.schema.document", "local_rqa.serve", "local_rqa.serve.base_model_worker", "local_rqa.serve.gradio_dialogue", "local_rqa.serve.test_message", "local_rqa.text_loaders", "local_rqa.text_loaders.base", "local_rqa.text_loaders.langchain_text_loader", "local_rqa.text_loaders.llamaindex_text_loader", "local_rqa.utils", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">arguments</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">dist_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.metrics</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.scores</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">evaluation.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">guardrails.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">guardrails</span></code>", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.prompts</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">pipelines.retrieval_qa</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.fid</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.huggingface</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.openai</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.prompts</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.sglang</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.tgi</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">qa_llms.vllm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_replug_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retriever_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.bm25_retriever</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers.faiss_retriever</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">retrievers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema.dialogue</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema.document</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">schema</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.base_model_worker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.controller</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_dialogue</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_rqa</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_static_server</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.gradio_web_server</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.model_worker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">serve.test_message</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">supervised_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">supervised_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.langchain_text_loader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">text_loaders.llamaindex_text_loader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">with_retriever_fid_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">with_retriever_trainer</span></code>", "local_rqa", "Welcome to LocalRQA\u2019s documentation!"], "terms": {"modul": [0, 3, 7, 9, 12, 21, 23, 26, 30, 91], "class": [1, 2, 4, 8, 10, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 27, 28, 31, 32, 33], "function": [4, 5, 6, 14, 25, 27, 29, 34, 62, 63, 64], "loggerargu": 35, "pertain": 35, "us": [35, 41, 43, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 67, 69, 75, 76, 77, 81, 82, 83, 85, 86, 89], "wandb": 35, "log": [35, 37], "run_group": 35, "str": [35, 40, 41, 43, 44, 45, 46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79, 81, 82, 89], "run_project": 35, "run_ent": 35, "modelargu": 35, "model_name_or_path": [35, 54, 55], "fidtrainingarg": [35, 62], "reader_model_path": 35, "with_scor": 35, "bool": [35, 41, 52, 54, 59, 62, 63, 64, 73, 74, 79, 81, 82, 89], "text_maxlength": [35, 38], "int": [35, 41, 54, 61, 72, 73, 74, 76, 77, 79], "n_context": [35, 38], "apply_question_mask": 35, "apply_passage_mask": 35, "extract_cl": [35, 62], "project": 35, "reader_temperatur": 35, "float": [35, 40], "reader_batch_s": 35, "indexing_dimens": 35, "replugtrainingarg": [35, 63], "lm_model_path": 35, "lm_temperatur": 35, "retrieve_temperatur": 35, "num_doc": 35, "refresh_step": 35, "dataargu": [35, 62, 63, 64], "what": [35, 41], "data": [35, 38, 62, 63, 64, 76, 77, 81, 82, 85, 86, 89, 91], "we": [35, 55, 76, 77, 81, 82], "ar": [35, 54, 62, 63, 64, 75, 76, 77, 89], "go": 35, "input": [35, 37, 43, 54, 62, 63, 64, 81, 82, 89], "our": [35, 37, 67, 70, 76, 77], "model": [35, 40, 41, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 67, 75, 76, 77, 79, 81, 82, 89], "train": [35, 54, 62, 63, 64, 81, 82, 89, 91], "eval": [35, 41, 62, 63, 64, 81, 82, 89], "train_fil": 35, "eval_fil": 35, "test_fil": 35, "full_dataset_file_path": 35, "contrasitivetrainingarg": [35, 64], "hard_neg_ratio": 35, "contrastive_loss": 35, "temperatur": [35, 77], "retrievalqatrainingargu": [35, 62, 63, 64, 81, 82, 89], "base": [35, 37, 38, 40, 41, 43, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 73, 75, 79, 81, 82, 84, 85, 86, 89], "transform": [35, 52, 54, 55, 62, 63, 64, 81, 82, 89], "trainingargu": [35, 62, 63, 64, 89], "overrid": [35, 54, 62, 63, 64, 81, 82, 89], "some": [35, 54, 62, 63, 64, 89], "default": [35, 38, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 81, 82, 89], "output_dir": [35, 62, 63, 64, 89], "do_train": 35, "remove_unused_column": 35, "do_ev": 35, "learning_r": 35, "weight_decai": 35, "max_step": 35, "per_device_train_batch_s": 35, "per_device_eval_batch_s": 35, "warmup_ratio": 35, "gradient_checkpoint": 35, "lr_scheduler_typ": 35, "logging_step": 35, "eval_step": 35, "save_step": 35, "report_to": 35, "evaluation_strategi": 35, "metric_for_best_model": 35, "save_strategi": 35, "save_total_limit": 35, "seed": [35, 62, 63, 64, 79, 89], "write_predict": 35, "pooling_typ": [35, 40], "logger": [36, 40, 43, 49, 52, 59, 60, 61, 67, 72, 73, 75, 76, 77, 79, 87], "compon": [36, 46, 49, 52, 53, 65], "abc": [36, 41, 43, 65, 75, 83, 85, 86], "build": 36, "block": [36, 54], "pipelin": [36, 41, 48, 65, 75, 81, 82, 89], "which": [36, 38, 54, 69], "call": [36, 43, 54, 62, 63, 64, 89], "run": [36, 46, 49, 52, 53, 54, 62, 63, 64, 65, 89], "method": [36, 38, 46, 49, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 75, 89, 91], "iter": [36, 59, 61, 62, 63, 64, 89], "run_input_kei": [36, 46, 49, 53, 65], "abstract": [36, 38, 41, 43, 46, 49, 53, 54, 65, 72, 75, 83], "arg": [36, 43, 46, 49, 53, 62, 63, 64, 65, 75, 76, 77, 80, 83, 85, 86, 89], "kwarg": [36, 43, 46, 49, 53, 54, 63, 65, 67, 75, 79, 83, 85, 86], "main": [36, 46, 49, 53, 65, 76, 77, 80], "entrypoint": [36, 46, 49, 53, 65], "keyword": [36, 46, 49, 53, 65], "pass": [36, 46, 49, 53, 54, 62, 63, 64, 65, 89], "argument": [36, 46, 48, 49, 53, 54, 62, 63, 64, 65, 81, 82, 89], "thi": [36, 37, 38, 43, 46, 48, 49, 53, 54, 62, 63, 64, 65, 69, 73, 75, 76, 77, 89], "openai_model_nam": 37, "gpt": [37, 52], "4": [37, 54, 77], "1106": 37, "preview": [37, 76, 77], "3": [37, 52, 54], "5": [37, 52, 79], "turbo": [37, 52], "text": [37, 40, 52, 60, 65, 66, 67, 70, 77, 79, 83, 85, 86], "embed": [37, 48, 52, 62, 63, 64, 65, 67, 79, 81, 82], "ada": [37, 52, 67, 79], "002": [37, 52, 67, 79], "accelerationframework": 37, "enum": [37, 69, 73], "gener": [37, 48, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 73, 75, 76, 77, 89, 91], "enumer": [37, 73], "deriv": [37, 73], "from": [37, 38, 49, 54, 62, 63, 64, 65, 66, 67, 73, 89, 91], "defin": [37, 62, 63, 64, 73, 89], "new": [37, 62, 63, 64, 73, 89], "vllm": [37, 48, 52, 56], "tgi": [37, 48, 56], "sglang": [37, 48, 52, 56], "server_logdir": 37, "controller_heart_beat_expir": 37, "worker_heart_beat_interv": 37, "15": 37, "server_error_msg": 37, "network": 37, "error": [37, 54], "due": 37, "TO": 37, "high": 37, "traffic": 37, "pleas": [37, 54, 76, 77], "regener": [37, 77], "OR": 37, "refresh": 37, "page": [37, 48, 91], "qa_moderation_msg": 37, "your": [37, 54, 60, 62, 63, 64, 76, 77, 81, 82, 89], "violat": [37, 76, 77], "moder": [37, 76, 77], "guidelin": 37, "try": 37, "again": [37, 62, 63, 64, 89], "qa_error_msg": 37, "sorri": 37, "i": [37, 38, 54, 62, 63, 64, 65, 75, 76, 77, 81, 82, 89, 91], "encount": 37, "an": [37, 38, 41, 43, 49, 52, 54, 62, 63, 64, 65, 76, 77, 81, 82, 83, 85, 86, 89, 91], "later": [37, 69], "contact": [37, 76, 77], "support": [37, 38, 55], "errorcod": 37, "intenum": 37, "http": [37, 54, 76, 77], "platform": 37, "openai": [37, 48, 52, 56, 76, 77], "com": [37, 76, 77], "doc": [37, 40, 53, 54, 55, 57, 59, 60, 61, 63, 81, 82, 85, 86], "guid": [37, 54], "code": [37, 54, 76, 77], "api": [37, 54, 77], "validation_type_error": 37, "40001": 37, "invalid_auth_kei": 37, "40101": 37, "incorrect_auth_kei": 37, "40102": 37, "no_permiss": 37, "40103": 37, "invalid_model": 37, "40301": 37, "param_out_of_rang": 37, "40302": 37, "context_overflow": 37, "40303": 37, "rate_limit": 37, "42901": 37, "quota_exceed": 37, "42902": 37, "engine_overload": 37, "42903": 37, "internal_error": 37, "50001": 37, "cuda_out_of_memori": 37, "50002": 37, "gradio_request_error": 37, "50003": 37, "gradio_stream_unknown_error": 37, "50004": 37, "controller_no_work": 37, "50005": 37, "controller_worker_timeout": 37, "50006": 37, "noopdatacol": 38, "__call__": [38, 66], "featur": [38, 54, 62, 63, 64, 89, 91], "contrastiveretrievaldataset": 38, "raw_data": 38, "list": [38, 40, 41, 43, 46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75, 81, 82, 83, 85, 86, 89], "dict": [38, 41, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 69, 70, 73, 74, 75, 81, 82, 89], "start_data_idx": 38, "0": [38, 40, 43, 54], "end_data_idx": 38, "none": [38, 41, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 67, 72, 79, 81, 82, 87, 89], "document_fmt_str": 38, "titl": [38, 70], "shuffl": [38, 40], "fals": [38, 40, 43, 52, 53, 54, 59, 62, 63, 64, 74, 79, 81, 82, 87, 89], "torch": [38, 54, 62, 63, 64, 81, 82, 89], "util": [38, 42, 48, 54, 62, 63, 64, 70, 81, 82, 89], "repres": [38, 54, 69, 70], "all": [38, 49, 52, 54, 62, 63, 64, 74, 81, 82, 89], "map": 38, "kei": [38, 49, 62, 63, 64, 74, 75, 76, 81, 82, 89], "sampl": 38, "should": [38, 54, 62, 63, 64, 81, 82, 89], "subclass": [38, 62, 63, 64, 81, 82, 89], "overwrit": 38, "__getitem__": 38, "fetch": 38, "given": [38, 49, 52, 53, 57, 59, 61, 62, 63, 64, 65, 66, 67, 89], "could": 38, "also": 38, "option": [38, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 81, 82, 89], "__len__": 38, "expect": [38, 62, 63, 64, 81, 82, 89], "return": [38, 43, 46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 75, 81, 82, 85, 86, 89], "size": [38, 54, 62, 63, 64, 89], "mani": 38, "sampler": 38, "implement": [38, 75], "dataload": [38, 62, 63, 64, 81, 82, 89], "__getitems__": 38, "speedup": 38, "batch": [38, 40, 54, 62, 63, 64, 65, 66, 67, 89], "load": [38, 54, 74, 75, 85, 86], "accept": [38, 62, 63, 64, 81, 82, 89], "indic": [38, 54], "construct": 38, "index": [38, 52, 67, 79, 91], "yield": 38, "integr": 38, "To": 38, "make": [38, 49, 54, 62, 63, 64, 89], "work": [38, 54, 62, 63, 64, 81, 82, 89], "style": [38, 69], "non": [38, 76, 77], "custom": [38, 54, 62, 63, 64, 81, 82, 89], "must": [38, 54, 62, 63, 64, 76, 77, 85, 86, 89], "provid": [38, 41, 54, 62, 63, 64, 65, 76, 77, 83, 85, 86, 89, 91], "prepare_data": 38, "idx": [38, 74, 76, 77], "replugdataset": 38, "get_target": 38, "exampl": [38, 54, 62, 63, 64, 89], "fiddataset": 38, "score_kei": 38, "score": [38, 42, 43, 48, 54, 62], "question_prefix": 38, "question": [38, 43, 49, 52, 53, 54, 55, 57, 59, 60, 61, 63, 69, 75, 91], "title_prefix": 38, "passage_prefix": 38, "context": [38, 63], "sort_data": 38, "get_exampl": 38, "encode_passag": 38, "batch_text_passag": 38, "token": [38, 40, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 81, 82, 89], "max_length": [38, 54, 55], "fidcol": 38, "answer_maxlength": 38, "20": 38, "object": [38, 54, 62, 63, 64, 69, 70, 89], "load_fid_data": 38, "data_path": 38, "retrievercol": 38, "passage_maxlength": 38, "512": 38, "question_maxlength": 38, "barrier": 39, "get_rank": 39, "is_main": [39, 87], "batch_iter": [40, 89], "dset": [40, 89], "batch_siz": [40, 41, 54, 89], "drop_last": [40, 89], "mean_pool": 40, "token_embed": 40, "mask": [40, 54], "compute_embed": 40, "encoded_input": 40, "output": [40, 54, 62, 63, 64, 81, 82, 89], "embed_document_batch": 40, "8": 40, "devic": [40, 62, 63, 64, 76, 77, 79, 89], "cuda": [40, 79], "to_list": [40, 69], "localembed": 40, "mean": [40, 43, 62, 63, 64, 89], "langchain": [40, 67, 70, 85], "interfac": [40, 54], "embed_docu": 40, "emb": [40, 67], "search": [40, 54, 91], "embed_queri": 40, "queri": [40, 65, 66, 67], "evaluatorconfig": [41, 62, 63, 64, 81, 82, 89], "control": [41, 48, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 78, 89], "metric": [41, 42, 48, 62, 63, 64, 89], "comput": [41, 43, 54, 62, 63, 64, 76, 77, 81, 82, 89], "dure": [41, 81, 82], "well": 41, "other": [41, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 89, 91], "relat": 41, "config": [41, 54], "retr_document_accuraci": 41, "retr_document_recal": 41, "retr_lat": 41, "gen_f1": 41, "gen_precis": 41, "gen_roug": 41, "gen_bleu": 41, "gen_lat": 41, "gen_answer_stat": 41, "gen_gpt4ev": 41, "e2e_lat": 41, "assistant_prefix": [41, 52, 55, 57, 59, 60, 61, 69, 79], "user_prefix": [41, 52, 55, 57, 59, 60, 61, 69, 79], "sep_us": [41, 52, 55, 57, 59, 60, 61, 69], "sep_si": [41, 52, 55, 57, 59, 60, 61, 69], "test_data": 41, "document": [41, 43, 46, 48, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 76, 77, 81, 82, 83, 85, 86, 89], "helper": [41, 65, 83, 85, 86], "standard": [41, 65, 83, 85, 86], "wai": [41, 62, 63, 64, 65, 83, 85, 86, 89], "creat": [41, 48, 54, 65, 83, 85, 86], "inherit": [41, 54, 65, 83, 85, 86], "_get_data_iter": 41, "_flatten_perform": 41, "prefix": [41, 54], "metric_typ": 41, "wrapped_model": 41, "tupl": [41, 62, 63, 64, 81, 82, 89], "ani": [41, 54, 62, 63, 64, 70, 76, 77, 81, 82, 83, 85, 86, 89], "retrieverevalu": 41, "init_metr": 41, "reset_all_metr": 41, "compute_perform": 41, "e2eevalu": 41, "end": [41, 43, 81, 82], "perform": [41, 46, 62, 63, 64, 81, 82, 89], "qa": [41, 49, 52, 55, 91], "accuraci": 41, "retriev": [41, 48, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 72, 75, 79, 81, 82, 89, 91], "accurarci": 41, "paramet": [41, 43, 46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 75, 81, 82, 85, 86, 89], "_type_": [41, 43, 52, 55, 60, 65, 67, 69, 70, 75, 81, 82], "_description_": [41, 43, 46, 49, 52, 53, 55, 57, 59, 60, 61, 65, 66, 67, 69, 70, 75, 81, 82], "local_rqa": [41, 43, 46, 49, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 74, 75, 76, 77, 79, 81, 82, 83, 85, 86, 89], "retrieval_qa": [41, 48, 50, 75, 81, 82, 89], "rqapipelin": [41, 49, 52], "l": 43, "runningmet": 43, "each": [43, 54, 62, 63, 64, 81, 82, 89], "bach": 43, "updat": [43, 49, 69], "overal": 43, "veri": 43, "e": [43, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 70, 89], "g": [43, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 70, 89], "averag": [43, 54], "reset": [43, 54, 63], "monitoringmetr": 43, "start": [43, 62, 63, 64, 89], "record": 43, "someth": 43, "time": 43, "elaps": 43, "between": [43, 54, 63], "stop": [43, 54], "differ": [43, 62, 63, 64, 69, 89], "is_same_docu": 43, "retrieved_doc": [43, 75], "gold_doc": 43, "document_similar": 43, "src_doc": 43, "target_doc": 43, "is_almost_same_docu": 43, "threshold": 43, "7": 43, "documentaccuraci": 43, "name": [43, 62, 63, 64, 73, 89], "document_accuraci": 43, "batch_retrieved_doc": 43, "batch_gold_doc": 43, "documentrecal": 43, "document_recal": 43, "f1": [43, 44], "batch_quest": [43, 46, 49, 52, 53, 55, 57, 59, 60, 61, 65, 66, 67], "batch_gen_answ": 43, "batch_gold_answ": 43, "schema": [43, 46, 48, 49, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 74, 76, 77, 83, 85, 86, 89], "precis": [43, 44], "roug": [43, 44], "bleu": 43, "answerstat": 43, "answer_stat": 43, "gpt_eval_acc_prompt": 43, "gpt_eval_noans_acc_prompt": 43, "gpt4eval": 43, "use_gold_answ": 43, "_gener": [43, 59, 60, 61], "prompt": [43, 48, 50, 53, 54, 55, 56, 57, 59, 60, 61, 63], "judg": 43, "refer": 43, "answer": [43, 46, 49, 52, 53, 57, 59, 61, 63, 69, 76, 77, 91], "latenc": 43, "num_samples_seen": 43, "em": 44, "predict": [44, 62, 63, 64, 81, 82, 89], "ground_truth": 44, "normalize_fn": 44, "recal": 44, "rouge_wrapp": 44, "f1_score": 44, "callabl": [44, 54, 62, 63, 64, 81, 82, 89], "lambda": 44, "x": 44, "exact_match_scor": 44, "rouge_scor": 44, "normalize_answ": 45, "": [45, 52, 54, 55, 59, 60, 61, 62, 63, 64, 66, 69, 81, 82, 89], "baseanswerguardrail": [46, 52], "action": 46, "fact": 46, "check": [46, 54, 62, 63, 64, 77, 81, 82, 89], "safeti": [46, 76, 77], "filter": 46, "etc": [46, 62, 63, 64, 70, 89], "batch_source_docu": [46, 53, 55, 57, 59, 60, 61, 65, 69], "batch_dialogue_sess": [46, 49, 52, 53, 55, 57, 59, 60, 61, 69], "batch_answ": [46, 53, 69], "dialogu": [46, 48, 49, 52, 53, 55, 57, 59, 60, 61, 66, 67, 71, 74, 76, 77], "dialoguesess": [46, 49, 52, 53, 55, 57, 59, 60, 61, 69, 74], "rqaoutput": [46, 49, 52, 69], "post": 46, "process": [46, 54, 62, 63, 64, 89], "respons": [46, 54, 59, 61, 63], "befor": [46, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 81, 82, 89], "user": [46, 52, 54, 55, 57, 59, 60, 61, 63, 69, 76, 77, 79], "rais": [46, 53, 55, 57, 59, 60, 61, 75, 85, 86], "notimplementederror": [46, 53, 55, 57, 59, 60, 61, 75], "type": [46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 81, 82, 85, 86, 89], "noopanswerguardrail": 46, "dummi": 46, "through": [46, 49, 52, 54], "contain": [48, 49, 52, 62, 63, 64, 89], "auto": [48, 79], "1": [48, 54], "constant": 48, "guardrail": [48, 52], "dist_util": 48, "with_retriever_fid_train": 48, "supervised_train": 48, "supervised_fid_train": 48, "dataset": [48, 62, 63, 64, 81, 82, 89], "with_retriever_train": 48, "retriever_train": 48, "retriever_fid_train": 48, "retriever_replug_train": 48, "qa_llm": [48, 52, 81, 82, 89], "fid": [48, 55, 56], "huggingfac": [48, 52, 56], "text_load": 48, "langchain_text_load": [48, 84], "llamaindex_text_load": [48, 84], "evalu": [48, 62, 63, 64, 81, 82, 89], "bm25_retriev": [48, 68], "faiss_retriev": [48, 62, 63, 64, 68, 89], "serv": [48, 91], "base_model_work": [48, 78, 79], "gradio_dialogu": [48, 76, 77, 78], "gradio_rqa": [48, 78], "gradio_static_serv": [48, 78], "gradio_web_serv": [48, 78], "model_work": [48, 78], "test_messag": [48, 78], "sphinx": 48, "autoapi": 48, "histori": [49, 52, 53, 55, 57, 59, 60, 61, 66, 67, 69, 74, 75], "up": 49, "update_dialogue_sess": 49, "retrieval_qa_output": 49, "session": [49, 69, 76], "current": [49, 62, 63, 64, 89], "turn": [49, 69], "system": [49, 69, 91], "_prepare_input": 49, "data_dict": 49, "assum": [49, 52, 69, 81, 82], "you": [49, 52, 54, 62, 63, 64, 75, 76, 77, 89], "can": [49, 52, 54, 62, 63, 64, 89], "directli": [49, 52], "pipe": [49, 52], "dataclass": [49, 52], "sourc": [49, 52, 53, 55, 57, 59, 60, 61, 69, 91], "rephrase_question_prompt": 51, "baserqa": 52, "baseretriev": [52, 65, 66, 67, 81, 82], "baseqamodel": [52, 53, 55, 57, 59, 60, 61], "answer_guardrail": 52, "take": [52, 54, 62, 63, 64, 89], "exactli": 52, "three": 52, "them": [52, 54, 62, 63, 64, 89], "sequenc": [52, 54, 81, 82], "simplerqa": [52, 75, 81, 82, 89], "verbos": [52, 79], "_batch_gener": 52, "input_prompt": 52, "generate_kwarg": [52, 59, 60, 61], "rephrase_quest": 52, "rephras": [52, 53, 55, 57, 59, 60, 61, 65], "everi": 52, "standalon": 52, "_rephrase_quest": 52, "chat_history_str": [52, 53, 55, 57, 59, 60, 61], "static": [52, 54, 67, 69, 70], "from_huggingfac": 52, "qa_model": [52, 81, 82, 89], "automodelforcausallm": [52, 55], "qa_token": 52, "autotoken": [52, 54, 55], "qa_model_name_or_path": [52, 79], "qa_model_init_kwarg": 52, "assist": [52, 54, 55, 57, 59, 60, 61, 63, 69, 79], "initi": [52, 54, 67], "simpl": [52, 54, 62, 63, 64, 89], "rqa": [52, 65, 75, 91], "alreadi": [52, 54], "from_huggingface_fid": 52, "fusion": [52, 54, 55], "decod": [52, 54, 55], "from_openai": 52, "qa_model_nam": 52, "from_vllm": 52, "qa_model_url": 52, "intial": 52, "llama": [52, 76, 77], "2": [52, 54, 79], "from_tgi": 52, "host": [52, 60], "infer": [52, 54, 60], "from_sglang": 52, "classmethod": [52, 73, 75], "from_scratch": [52, 75], "database_path": [52, 67, 79], "document_path": [52, 62, 63, 64, 67, 79, 89], "index_path": [52, 62, 63, 64, 67, 79], "embedding_model_name_or_path": [52, 79], "lmsy": [52, 79], "vicuna": [52, 79], "7b": [52, 79], "v1": [52, 79], "qa_is_fid": [52, 79], "autorqa": 52, "generationoutput": [53, 55, 57, 59, 60, 61], "llm": [53, 57, 59, 61], "set": [53, 54, 57, 59, 61, 62, 63, 64, 89], "is_api_model": [53, 59, 60, 61], "r_gener": [53, 55, 57, 59, 60, 61], "tokenization_kwarg": [53, 55, 57, 59, 60, 61], "generation_kwarg": [53, 55, 57, 59, 60, 61], "augement": [53, 55, 57, 59, 60, 61], "batched_prompt": [53, 55, 57, 59, 60, 61], "potenti": [53, 55, 57, 59, 60, 61, 76, 77], "purpos": [53, 55, 57, 59, 60, 61, 76, 77], "_prepare_question_w_doc": [53, 55, 57, 59, 60, 61], "format": [53, 54, 55, 57, 59, 60, 61, 69], "chat": [53, 55, 57, 59, 60, 61, 63], "requir": [53, 55, 57, 59, 60, 61, 76, 77], "gradio": [53, 55, 57, 59, 60, 61, 75, 76, 77], "demo": [53, 55, 57, 59, 60, 61, 76, 77], "fidt5": [54, 55], "t5forconditionalgener": 54, "handl": [54, 65], "weight": 54, "download": 54, "pretrain": 54, "forward_": 54, "forward": [54, 62, 63, 64, 89], "input_id": 54, "attention_mask": 54, "label": [54, 62, 63, 64, 74, 81, 82, 89], "longtensor": 54, "shape": 54, "classif": 54, "regress": 54, "loss": [54, 62, 63, 64, 81, 82, 89], "100": 54, "vocab_s": 54, "ignor": [54, 62, 63, 64, 81, 82, 89], "onli": [54, 55, 62, 63, 64, 76, 77, 81, 82, 89], "python": 54, "import": [54, 62, 63, 64, 89], "from_pretrain": 54, "t5": [54, 55], "small": 54, "The": [54, 62, 63, 64, 76, 77, 81, 82, 89], "extra_id_0": 54, "walk": 54, "extra_id_1": 54, "park": 54, "return_tensor": 54, "pt": 54, "cute": 54, "dog": 54, "extra_id_2": 54, "logit": [54, 62, 63, 64, 81, 82, 89], "summar": 54, "studi": 54, "have": [54, 62, 63, 64, 89], "shown": 54, "own": [54, 62, 63, 64, 89], "good": 54, "print": 54, "skip_special_token": 54, "true": [54, 59, 60, 61, 87], "max_new_token": [54, 77], "id": 54, "languag": 54, "head": 54, "tip": [54, 62, 63, 64, 89], "warn": 54, "most": [54, 62, 63, 64, 81, 82, 89], "generation_config": 54, "configur": 54, "correspond": [54, 85, 86], "num_beam": 54, "do_sampl": 54, "For": [54, 55, 62, 63, 64, 76, 77, 89], "overview": 54, "strategi": 54, "out": 54, "follow": [54, 63, 76, 77], "generation_strategi": 54, "tensor": [54, 62, 63, 64, 81, 82, 89], "vari": 54, "depend": 54, "modal": 54, "encod": 54, "If": [54, 62, 63, 64, 89], "bos_token_id": 54, "input_valu": 54, "input_featur": 54, "pixel_valu": 54, "generationconfig": 54, "parametr": 54, "match": 54, "attribut": [54, 62, 64, 89], "had": 54, "prioriti": 54, "json": 54, "file": [54, 85, 86], "exist": [54, 91], "note": [54, 62, 63, 64, 69, 89], "unspecifi": 54, "valu": [54, 62, 63, 64, 76, 77, 89], "whose": 54, "parameter": 54, "logits_processor": 54, "logitsprocessorlist": 54, "processor": 54, "complement": 54, "built": 54, "thrown": 54, "intend": [54, 76, 77], "advanc": 54, "stopping_criteria": 54, "stoppingcriterialist": 54, "criteria": 54, "sure": 54, "return_dict_in_gener": 54, "output_scor": 54, "prefix_allowed_tokens_fn": 54, "constraint": 54, "beam": 54, "allow": 54, "step": [54, 62, 63, 64, 81, 82, 89], "appli": 54, "batch_id": 54, "It": [54, 73, 76, 77], "ha": [54, 62, 63, 64, 89], "next": 54, "condit": 54, "previous": 54, "inputs_id": 54, "constrain": 54, "describ": 54, "autoregress": 54, "entiti": 54, "arxiv": [54, 76, 77], "org": [54, 76, 77], "ab": [54, 76, 77], "2010": 54, "00904": 54, "synced_gpu": 54, "whether": [54, 62, 63, 64, 77, 81, 82, 89], "continu": 54, "while": [54, 62, 63, 64, 89], "loop": [54, 62, 63, 64, 81, 82, 89], "until": 54, "unless": 54, "overridden": [54, 62, 63, 64, 89], "flag": [54, 76, 77], "under": [54, 60, 62, 63, 64, 81, 82, 89], "deepspe": [54, 62, 63, 64, 89], "zero": [54, 62, 63, 64, 89], "stage": 54, "multipl": 54, "gpu": [54, 62, 63, 64, 89], "environ": 54, "avoid": 54, "hang": 54, "one": [54, 62, 63, 64, 89], "finish": 54, "otherwis": [54, 62, 63, 64, 75, 89], "ll": 54, "assistant_model": 54, "pretrainedmodel": [54, 62, 63, 64, 81, 82, 89], "acceler": [54, 75], "exact": 54, "same": [54, 62, 63, 64, 89], "achiev": 54, "when": [54, 62, 63, 64, 81, 82, 89], "forecast": 54, "candid": 54, "much": 54, "faster": 54, "than": 54, "re": 54, "As": 54, "smaller": 54, "streamer": 54, "basestream": 54, "stream": [54, 59], "put": 54, "token_id": 54, "further": 54, "negative_prompt_id": 54, "sequence_length": 54, "neg": 54, "need": 54, "cfg": 54, "experiment": 54, "subject": [54, 76, 77], "break": 54, "chang": 54, "futur": [54, 76, 77], "version": 54, "negative_prompt_attention_mask": 54, "ad": [54, 69], "hoc": 54, "generate_config": 54, "addit": 54, "specif": 54, "decoder_": 54, "A": [54, 62, 63, 64, 73, 74, 79, 81, 82, 89], "modeloutput": 54, "floattensor": 54, "is_encoder_decod": 54, "possibl": 54, "greedysearchdecoderonlyoutput": 54, "sampledecoderonlyoutput": 54, "beamsearchdecoderonlyoutput": 54, "beamsampledecoderonlyoutput": 54, "greedysearchencoderdecoderoutput": 54, "sampleencoderdecoderoutput": 54, "beamsearchencoderdecoderoutput": 54, "beamsampleencoderdecoderoutput": 54, "wrap_encod": 54, "use_checkpoint": 54, "wrap": [54, 62, 63, 64, 89], "obtain": 54, "unwrap_encod": 54, "unwrap": 54, "load_t5": 54, "state_dict": [54, 62, 63, 64], "set_checkpoint": 54, "enabl": [54, 91], "disabl": 54, "checkpoint": 54, "see": 54, "pytorch": [54, 62, 63, 64, 89], "stabl": 54, "html": 54, "reset_score_storag": 54, "storag": 54, "cross": 54, "attent": 54, "save": [54, 62, 63, 64, 85, 86, 89], "get_crossattention_scor": 54, "context_mask": 54, "aggreg": 54, "singl": [54, 62, 63, 64, 69, 89], "scalar": 54, "per": 54, "passag": 54, "seen": 54, "similar": 54, "first": [54, 62, 63, 64, 69, 81, 82, 89], "over": 54, "layer": [54, 62, 63, 64, 89], "more": [54, 62, 63, 64, 89], "detail": [54, 62, 63, 64, 76, 77, 89], "distil": 54, "knowledg": 54, "reader": 54, "2012": 54, "04584": 54, "overwrite_forward_crossattent": 54, "replac": 54, "from_t5": 54, "encoderwrapp": 54, "nn": [54, 62, 63, 64, 81, 82, 89], "wrapper": [54, 75], "checkpointwrapp": 54, "empti": 54, "hidden_st": 54, "position_bia": 54, "apply_checkpoint_wrapp": 54, "t5stack": 54, "cross_attention_forward": 54, "self": [54, 62, 63, 64, 89], "key_value_st": 54, "layer_head_mask": 54, "past_key_valu": 54, "use_cach": 54, "query_length": 54, "output_attent": 54, "huggingfaceqamodel": 55, "model_init_kwarg": 55, "simpli": 55, "_init": 55, "huggingfacefidqamodel": 55, "now": 55, "architectur": [55, 62, 63, 64, 89], "pack_fid_input": 55, "batched_fid_prompt": 55, "unpack_fid_input": 55, "encode_fid_input": 55, "batch_q_w_passag": 55, "openaiqamodel": 57, "model_nam": [57, 72, 73, 79], "rqa_prompt": 58, "rqa_prompt_train": 58, "sglangclient": 59, "url": [59, 60, 61, 70], "timeout": [59, 61], "60": [59, 61], "_post_http_request": [59, 61], "gen_arg": [59, 61], "request": [59, 61, 72, 73, 76, 77], "_get_streaming_respons": [59, 61], "_get_respons": [59, 61], "input_text": [59, 60, 61, 75], "generate_stream": [59, 61, 75, 79], "sglangqamodel": 59, "prepare_gen_kwarg": [59, 60, 61], "input_kwarg": [59, 60, 61], "_generate_stream": [59, 60, 61], "rqa_model": [59, 61], "tgiqamodel": 60, "hood": 60, "its": [60, 70, 76, 77], "vllmclient": 61, "offset": 61, "vllmqamodel": 61, "fidretrievertrain": 62, "modeling_util": [62, 63, 64, 81, 82, 89], "training_arg": [62, 63, 64], "trainer": [62, 63, 64, 81, 82, 89], "data_arg": [62, 63, 64], "fid_arg": 62, "eval_config": [62, 63, 64, 81, 82, 89], "data_col": [62, 63, 64, 81, 82, 89], "datacol": [62, 63, 64, 81, 82, 89], "train_dataset": [62, 63, 64, 81, 82, 89], "eval_dataset": [62, 63, 64, 81, 82, 89], "tokenization_utils_bas": [62, 63, 64, 81, 82, 89], "pretrainedtokenizerbas": [62, 63, 64, 81, 82, 89], "model_init": [62, 63, 64, 81, 82, 89], "compute_metr": [62, 63, 64, 81, 82, 89], "trainer_util": [62, 63, 64, 81, 82, 89], "evalpredict": [62, 63, 64, 81, 82, 89], "callback": [62, 63, 64, 81, 82, 89], "trainer_callback": [62, 63, 64, 81, 82, 89], "trainercallback": [62, 63, 64, 81, 82, 89], "optim": [62, 63, 64, 76, 77, 81, 82, 89], "lr_schedul": [62, 63, 64, 81, 82, 89], "lambdalr": [62, 63, 64, 81, 82, 89], "preprocess_logits_for_metr": [62, 63, 64, 81, 82, 89], "complet": [62, 63, 64, 89], "librari": [62, 63, 64, 89], "still": [62, 63, 64, 89], "long": [62, 63, 64, 89], "thei": [62, 63, 64, 89], "tweak": [62, 63, 64, 89], "Will": [62, 63, 64, 89], "basic": [62, 63, 64, 89], "instanc": [62, 63, 64, 89], "directori": [62, 63, 64, 89], "tmp_trainer": [62, 63, 64, 89], "form": [62, 63, 64, 89], "element": [62, 63, 64, 81, 82, 89], "default_data_col": [62, 63, 64, 89], "datacollatorwithpad": [62, 63, 64, 89], "iterabledataset": [62, 63, 64, 89], "column": [62, 63, 64, 89], "automat": [62, 63, 64, 89], "remov": [62, 63, 64, 89], "random": [62, 63, 64, 89], "distribut": [62, 63, 64, 73, 89], "fashion": [62, 63, 64, 89], "either": [62, 63, 64, 75, 89], "intern": [62, 63, 64, 89], "ident": [62, 63, 64, 89], "manual": [62, 63, 64, 89], "epoch": [62, 63, 64, 89], "set_epoch": [62, 63, 64, 89], "rng": [62, 63, 64, 89], "union": [62, 63, 64, 81, 82, 89], "dictionari": [62, 63, 64, 69, 70, 81, 82, 89], "prepend": [62, 63, 64, 89], "preprocess": [62, 63, 64, 89], "pad": [62, 63, 64, 89], "maximum": [62, 63, 64, 89], "length": [62, 63, 64, 89], "along": [62, 63, 64, 70, 89], "easier": [62, 63, 64, 89], "rerun": [62, 63, 64, 89], "interrupt": [62, 63, 64, 89], "reus": [62, 63, 64, 89], "fine": [62, 63, 64, 89], "tune": [62, 63, 64, 89], "instanti": [62, 63, 64, 89], "mai": [62, 63, 64, 69, 76, 77, 89], "optuna": [62, 63, 64, 89], "rai": [62, 63, 64, 89], "sigopt": [62, 63, 64, 89], "trial": [62, 63, 64, 89], "abl": [62, 63, 64, 89], "choos": [62, 63, 64, 89], "accord": [62, 63, 64, 89], "hyper": [62, 63, 64, 89], "count": [62, 63, 64, 89], "inner": [62, 63, 64, 89], "dropout": [62, 63, 64, 89], "probabl": [62, 63, 64, 89], "string": [62, 63, 64, 69, 70, 76, 77, 89], "add": [62, 63, 64, 69, 89], "those": [62, 63, 64, 76, 77, 89], "here": [62, 63, 64, 89], "want": [62, 63, 64, 89], "remove_callback": [62, 63, 64, 89], "schedul": [62, 63, 64, 89], "adamw": [62, 63, 64, 89], "get_linear_schedule_with_warmup": [62, 63, 64, 89], "right": [62, 63, 64, 89], "cach": [62, 63, 64, 89], "two": [62, 63, 64, 69, 89], "onc": [62, 63, 64, 89], "desir": [62, 63, 64, 89], "modif": [62, 63, 64, 89], "made": [62, 63, 64, 89], "reflect": [62, 63, 64, 89], "receiv": [62, 63, 64, 89], "second": [62, 63, 64, 89], "doe": [62, 63, 64, 89], "alwai": [62, 63, 64, 89], "point": [62, 63, 64, 89], "core": [62, 63, 64, 89], "model_wrap": [62, 63, 64, 89], "extern": [62, 63, 64, 89], "case": [62, 63, 64, 89], "origin": [62, 63, 64, 89], "distributeddataparallel": [62, 63, 64, 89], "hasn": [62, 63, 64, 89], "t": [62, 63, 64, 89], "been": [62, 63, 64, 89], "is_model_parallel": [62, 63, 64, 89], "switch": [62, 63, 64, 89], "parallel": [62, 63, 64, 89], "mode": [62, 63, 64, 89], "split": [62, 63, 64, 85, 86, 89], "place_model_on_devic": [62, 63, 64, 89], "place": [62, 63, 64, 89], "is_in_train": [62, 63, 64, 89], "embed_text": 62, "text_id": 62, "text_mask": 62, "apply_mask": 62, "kldivloss": [62, 63], "gold_scor": 62, "compute_loss": [62, 63, 64, 81, 82, 89], "return_output": [62, 63, 64, 81, 82, 89], "how": [62, 63, 64, 81, 82, 89], "By": [62, 63, 64, 76, 77, 81, 82, 89], "behavior": [62, 63, 64, 81, 82, 89], "prediction_step": [62, 63, 64, 81, 82, 89], "prediction_loss_onli": [62, 63, 64, 81, 82, 89], "ignore_kei": [62, 63, 64, 81, 82, 89], "inject": [62, 63, 64, 81, 82, 89], "target": [62, 63, 64, 81, 82, 89], "unpack": [62, 63, 64, 81, 82, 89], "being": [62, 63, 64, 81, 82, 89], "fed": [62, 63, 64, 81, 82, 89], "gather": [62, 63, 64, 81, 82, 89], "wrap_model_for_ev": [62, 63, 64, 81, 82, 89], "faissretriev": [62, 63, 64, 67, 89], "_load_all_doc": [62, 63, 64, 89], "_load_eval_data": [62, 63, 64, 81, 82, 89], "eval_data_path": [62, 63, 64, 81, 82, 89], "evaluation_loop": [62, 63, 64, 81, 82, 89], "descript": [62, 63, 64, 81, 82, 89], "metric_key_prefix": [62, 63, 64, 81, 82, 89], "evalloopoutput": [62, 63, 64, 81, 82, 89], "share": [62, 63, 64, 76, 77, 81, 82, 89], "both": [62, 63, 64, 81, 82, 89], "without": [62, 63, 64, 81, 82, 89], "_save": [62, 63, 64], "ignore_token_id": 63, "red": 63, "x1b": 63, "91m": 63, "green": 63, "92m": 63, "0m": 63, "multilin": [63, 76, 77], "show": [63, 76, 77], "curiou": 63, "artifici": 63, "intellig": 63, "give": 63, "help": [63, 76], "polit": 63, "do": 63, "mention": 63, "sinc": 63, "visibl": 63, "formatted_docu": 63, "formatted_chat": 63, "endoftext": 63, "replugretrievertrain": 63, "replug_arg": 63, "instruct": 63, "label_str": 63, "get_seq_prob": 63, "logit_scor": 63, "retrieve_scor": 63, "lm_score": 63, "pred": 63, "retrievertrain": 64, "contrastive_arg": 64, "_inbatch_contrastive_w_hardneg": 64, "retrievaloutput": [65, 66, 67, 75], "relev": [65, 66, 67, 69], "corpu": [65, 66, 67], "dummyretriev": 65, "mock": 65, "test": [65, 91], "normalize_str": 66, "bm25token": 66, "bm25retriev": 66, "openaiembed": 67, "prepare_docs_for_retriev": 67, "prepar": 67, "so": [67, 75], "faiss": 67, "would": 67, "recogn": 67, "fmt_content": [67, 70], "_init_retriev": 67, "retrieve_w_scor": 67, "from_disk": 67, "dialogueturn": 69, "store": 69, "source_docu": [69, 74], "speaker": 69, "messag": [69, 74], "to_str": 69, "convert": [69, 70], "represent": 69, "from_dict": [69, 70], "dialogue_turn_dict": 69, "to_dict": [69, 70, 74], "clone": [69, 70, 74], "separatorstyl": 69, "separ": 69, "speak": 69, "sep_styl": 69, "add_user_messag": [69, 74], "user_messag": 69, "add_system_messag": [69, 74], "system_messag": 69, "from_list": 69, "dialogue_list": 69, "default_document_formatt": 70, "metadata": [70, 74], "field": 70, "chunk": 70, "author": 70, "page_cont": 70, "__post_init__": 70, "document_dict": 70, "from_langchain_doc": 70, "to_langchain_doc": 70, "worker": [72, 73, 79], "app": [72, 73], "heart_beat_work": 72, "obj": 72, "basemodelwork": [72, 79], "controller_addr": [72, 79], "worker_addr": [72, 79], "worker_id": [72, 79], "model_path": 72, "limit_worker_concurr": [72, 79], "conv_templ": [72, 74, 79], "init_heart_beat": 72, "register_to_control": 72, "send_heart_beat": 72, "get_queue_length": 72, "get_statu": 72, "count_token": 72, "param": [72, 73, 79], "generate_stream_g": [72, 79], "generate_g": [72, 79], "release_worker_semaphor": 72, "acquire_worker_semaphor": 72, "create_background_task": 72, "async": [72, 73], "api_generate_stream": 72, "fastapi": [72, 73], "api_gener": 72, "api_retriev": 72, "api_get_statu": 72, "api_count_token": 72, "api_get_conv": 72, "api_model_detail": 72, "manag": 73, "send": 73, "address": 73, "client": 73, "dispatchmethod": 73, "lotteri": 73, "shortest_queu": 73, "from_str": 73, "workerinfo": 73, "speed": 73, "queue_length": 73, "check_heart_beat": 73, "last_heart_beat": 73, "heart_beat_control": 73, "dispatch_method": 73, "register_work": 73, "worker_nam": 73, "worker_statu": 73, "get_worker_statu": 73, "remove_work": 73, "refresh_all_work": 73, "list_model": 73, "get_worker_address": 73, "receive_heart_beat": 73, "remove_stale_workers_by_expir": 73, "handle_no_work": 73, "handle_worker_timeout": 73, "worker_address": 73, "worker_api_get_statu": 73, "worker_api_generate_stream": 73, "worker_api_retriev": 73, "create_control": 73, "gradiodialoguesess": [74, 76, 77], "keep": [74, 76, 77], "convers": 74, "_session": 74, "_tmp_data": 74, "skip_next": 74, "get_prompt": 74, "to_gradio_chatbot": 74, "conv_vicuna_v1": 74, "default_convers": 74, "annotationhistori": [74, 76], "data_file_path": 74, "empty_sess": 74, "annotation_kei": 74, "data_indic": 74, "parse_int_rang": 74, "_data_idx_filt": 74, "get_next_idx": 74, "get_prev_idx": 74, "get_current_idx": 74, "update_label": 74, "get_current_label": 74, "get_num_label": 74, "get_num_to_label": 74, "is_all_label": 74, "to_jsonl": 74, "gradiorqa": 75, "rephrase_question_for_retriev": 75, "get_model": 75, "get_token": 75, "generate_stream_from_api": 75, "NOT": 75, "framework": 75, "local": [75, 91], "just": 75, "prepare_prompt_for_gener": 75, "gradiosimplerqa": 75, "header": [76, 77], "argpars": [76, 77], "namespac": [76, 77], "no_change_btn": [76, 77], "enable_btn": [76, 77], "disable_btn": [76, 77], "num_doc_to_retriev": [76, 77], "ann_correct": 76, "correct": 76, "ann_incorrect": 76, "incorrect": 76, "ann_help": 76, "ann_not_help": 76, "ann_harm": 76, "harm": [76, 77], "ann_not_harm": 76, "harmless": 76, "get_conv_log_filenam": [76, 77], "document_view": [76, 77], "render_single_sess": 76, "render_next_sess": 76, "state": [76, 77], "submit_btn": 76, "render_prev_sess": 76, "vote_respons": 76, "radio_choic": 76, "vote_correct": 76, "vote_help": 76, "vote_harmless": 76, "load_demo": [76, 77], "dummy_st": 76, "url_param": [76, 77], "chatbot": 76, "save_annot": 76, "title_markdown": [76, 77], "localrqa": [76, 77], "github": [76, 77], "jasonyux": [76, 77], "xxxxx": [76, 77], "tos_markdown": [76, 77], "term": [76, 77], "servic": [76, 77], "agre": [76, 77], "research": [76, 77, 91], "commerci": [76, 77], "limit": [76, 77], "measur": [76, 77], "offens": [76, 77], "illeg": [76, 77], "violent": [76, 77], "racist": [76, 77], "sexual": [76, 77], "collect": [76, 77], "click": [76, 77], "button": [76, 77], "get": [76, 77], "inappropri": [76, 77], "improv": [76, 77], "experi": [76, 77], "desktop": [76, 77], "mobil": [76, 77], "compromis": [76, 77], "qualiti": [76, 77], "learn_more_markdown": [76, 77], "licens": [76, 77], "facebookresearch": [76, 77], "blob": [76, 77], "model_card": [76, 77], "md": [76, 77], "polici": [76, 77], "privaci": [76, 77], "practic": [76, 77], "chrome": [76, 77], "googl": [76, 77], "webstor": [76, 77], "sharegpt": [76, 77], "chatg": [76, 77], "daiacboceoaocpibfodeljbdfacokfjb": [76, 77], "u": [76, 77], "find": [76, 77], "block_css": [76, 77], "block_j": [76, 77], "build_demo": [76, 77], "embed_mod": [76, 77], "parser": [76, 77, 79, 80], "violates_moder": 77, "get_model_list": 77, "load_demo_refresh_model_list": 77, "vote_last_respons": 77, "vote_typ": 77, "upvote_last_respons": 77, "downvote_last_respons": 77, "flag_last_respons": 77, "clear_histori": 77, "add_text": 77, "http_retriev": 77, "http_gener": 77, "top_p": 77, "execut": 79, "load_model": 79, "load_8bit": 79, "load_4bit": 79, "device_map": 79, "add_model_arg": 79, "modelwork": 79, "no_regist": 79, "stream_interv": 79, "embed_in_trunc": 79, "debug": 79, "create_model_work": 79, "supervisedfidtrain": 81, "train_arg": [81, 82, 89], "eval_retriev": [81, 82], "equival": [81, 82], "fix": [81, 82], "includ": [81, 82], "gold": [81, 82], "choic": [81, 82], "supervisedtrain": 82, "basetextload": [83, 85, 86], "load_data": [83, 85, 86], "save_text": [83, 85, 86], "_convert_doc": 83, "langchaintextload": 85, "save_fold": [85, 86], "save_filenam": [85, 86], "parsed_doc": [85, 86], "loader_func": [85, 86], "directoryload": 85, "splitter_func": 85, "charactertextsplitt": 85, "text_splitt": 85, "specifi": [85, 86], "valueerror": [85, 86], "loader_param": [85, 86], "splitter_param": 85, "loader_funct": [85, 86], "splitter_funct": 85, "pickl": [85, 86], "loader_paramet": 85, "llamaindextextload": 86, "simpledirectoryread": 86, "init_logg": 87, "is_distribut": 87, "filenam": 87, "create_dir_if_not_exist": 87, "path": 87, "remove_optimizer_weight": 87, "save_dir": 87, "fixedretrievertrain": 89, "retriever_model": 89, "eval_wrapper_class": 89, "open": 91, "toolkit": 91, "quickli": 91, "augment": 91, "full": 91, "suit": 91, "tool": 91, "compar": 91, "wide": 91, "select": 91, "algorithm": 91, "curat": 91, "latest": 91}, "objects": {"": [[35, 0, 0, "-", "arguments"], [36, 0, 0, "-", "base"], [37, 0, 0, "-", "constants"], [38, 0, 0, "-", "datasets"], [39, 0, 0, "-", "dist_utils"], [40, 0, 0, "-", "embeddings"], [42, 0, 0, "-", "evaluation"], [47, 0, 0, "-", "guardrails"], [90, 0, 0, "-", "local_rqa"], [50, 0, 0, "-", "pipelines"], [56, 0, 0, "-", "qa_llms"], [62, 0, 0, "-", "retriever_fid_trainer"], [63, 0, 0, "-", "retriever_replug_trainer"], [64, 0, 0, "-", "retriever_trainer"], [68, 0, 0, "-", "retrievers"], [71, 0, 0, "-", "schema"], [78, 0, 0, "-", "serve"], [81, 0, 0, "-", "supervised_fid_trainer"], [82, 0, 0, "-", "supervised_trainer"], [84, 0, 0, "-", "text_loaders"], [87, 0, 0, "-", "utils"], [88, 0, 0, "-", "with_retriever_fid_trainer"], [89, 0, 0, "-", "with_retriever_trainer"]], "arguments": [[35, 1, 1, "", "ContrasitiveTrainingArgs"], [35, 1, 1, "", "DataArguments"], [35, 1, 1, "", "FidTrainingArgs"], [35, 1, 1, "", "LoggerArguments"], [35, 1, 1, "", "ModelArguments"], [35, 1, 1, "", "ReplugTrainingArgs"], [35, 1, 1, "", "RetrievalQATrainingArguments"]], "arguments.ContrasitiveTrainingArgs": [[35, 2, 1, "", "contrastive_loss"], [35, 2, 1, "", "hard_neg_ratio"], [35, 2, 1, "", "temperature"]], "arguments.DataArguments": [[35, 2, 1, "", "eval_file"], [35, 2, 1, "", "full_dataset_file_path"], [35, 2, 1, "", "test_file"], [35, 2, 1, "", "train_file"]], "arguments.FidTrainingArgs": [[35, 2, 1, "", "apply_passage_mask"], [35, 2, 1, "", "apply_question_mask"], [35, 2, 1, "", "extract_cls"], [35, 2, 1, "", "indexing_dimension"], [35, 2, 1, "", "n_context"], [35, 2, 1, "", "projection"], [35, 2, 1, "", "reader_batch_size"], [35, 2, 1, "", "reader_model_path"], [35, 2, 1, "", "reader_temperature"], [35, 2, 1, "", "text_maxlength"], [35, 2, 1, "", "with_score"]], "arguments.LoggerArguments": [[35, 2, 1, "", "run_entity"], [35, 2, 1, "", "run_group"], [35, 2, 1, "", "run_project"]], "arguments.ModelArguments": [[35, 2, 1, "", "model_name_or_path"]], "arguments.ReplugTrainingArgs": [[35, 2, 1, "", "lm_model_path"], [35, 2, 1, "", "lm_temperature"], [35, 2, 1, "", "num_docs"], [35, 2, 1, "", "refresh_step"], [35, 2, 1, "", "retrieve_temperature"], [35, 2, 1, "", "text_maxlength"]], "arguments.RetrievalQATrainingArguments": [[35, 2, 1, "", "do_eval"], [35, 2, 1, "", "do_train"], [35, 2, 1, "", "eval_steps"], [35, 2, 1, "", "evaluation_strategy"], [35, 2, 1, "", "gradient_checkpointing"], [35, 2, 1, "", "learning_rate"], [35, 2, 1, "", "logging_steps"], [35, 2, 1, "", "lr_scheduler_type"], [35, 2, 1, "", "max_steps"], [35, 2, 1, "", "metric_for_best_model"], [35, 2, 1, "", "output_dir"], [35, 2, 1, "", "per_device_eval_batch_size"], [35, 2, 1, "", "per_device_train_batch_size"], [35, 2, 1, "", "pooling_type"], [35, 2, 1, "", "remove_unused_columns"], [35, 2, 1, "", "report_to"], [35, 2, 1, "", "save_steps"], [35, 2, 1, "", "save_strategy"], [35, 2, 1, "", "save_total_limit"], [35, 2, 1, "", "seed"], [35, 2, 1, "", "warmup_ratio"], [35, 2, 1, "", "weight_decay"], [35, 2, 1, "", "write_predictions"]], "base": [[36, 1, 1, "", "Component"], [36, 4, 1, "", "logger"]], "base.Component": [[36, 3, 1, "", "run"], [36, 2, 1, "", "run_input_keys"]], "constants": [[37, 1, 1, "", "AccelerationFramework"], [37, 4, 1, "", "CONTROLLER_HEART_BEAT_EXPIRATION"], [37, 1, 1, "", "ErrorCode"], [37, 4, 1, "", "OPENAI_MODEL_NAMES"], [37, 4, 1, "", "QA_ERROR_MSG"], [37, 4, 1, "", "QA_MODERATION_MSG"], [37, 4, 1, "", "SERVER_ERROR_MSG"], [37, 4, 1, "", "SERVER_LOGDIR"], [37, 4, 1, "", "WORKER_HEART_BEAT_INTERVAL"]], "constants.AccelerationFramework": [[37, 2, 1, "", "SGLANG"], [37, 2, 1, "", "TGI"], [37, 2, 1, "", "VLLM"]], "constants.ErrorCode": [[37, 2, 1, "", "CONTEXT_OVERFLOW"], [37, 2, 1, "", "CONTROLLER_NO_WORKER"], [37, 2, 1, "", "CONTROLLER_WORKER_TIMEOUT"], [37, 2, 1, "", "CUDA_OUT_OF_MEMORY"], [37, 2, 1, "", "ENGINE_OVERLOADED"], [37, 2, 1, "", "GRADIO_REQUEST_ERROR"], [37, 2, 1, "", "GRADIO_STREAM_UNKNOWN_ERROR"], [37, 2, 1, "", "INCORRECT_AUTH_KEY"], [37, 2, 1, "", "INTERNAL_ERROR"], [37, 2, 1, "", "INVALID_AUTH_KEY"], [37, 2, 1, "", "INVALID_MODEL"], [37, 2, 1, "", "NO_PERMISSION"], [37, 2, 1, "", "PARAM_OUT_OF_RANGE"], [37, 2, 1, "", "QUOTA_EXCEEDED"], [37, 2, 1, "", "RATE_LIMIT"], [37, 2, 1, "", "VALIDATION_TYPE_ERROR"]], "datasets": [[38, 1, 1, "", "ContrastiveRetrievalDataset"], [38, 1, 1, "", "FidCollator"], [38, 1, 1, "", "FidDataset"], [38, 1, 1, "", "NoopDataCollator"], [38, 1, 1, "", "ReplugDataset"], [38, 1, 1, "", "RetrieverCollator"], [38, 5, 1, "", "encode_passages"], [38, 5, 1, "", "load_fid_data"]], "datasets.ContrastiveRetrievalDataset": [[38, 3, 1, "", "__getitem__"], [38, 3, 1, "", "__len__"], [38, 3, 1, "", "prepare_data"]], "datasets.FidCollator": [[38, 3, 1, "", "__call__"]], "datasets.FidDataset": [[38, 3, 1, "", "__getitem__"], [38, 3, 1, "", "__len__"], [38, 3, 1, "", "get_example"], [38, 3, 1, "", "get_target"], [38, 3, 1, "", "sort_data"]], "datasets.NoopDataCollator": [[38, 3, 1, "", "__call__"]], "datasets.ReplugDataset": [[38, 3, 1, "", "__getitem__"], [38, 3, 1, "", "__len__"], [38, 3, 1, "", "get_target"]], "datasets.RetrieverCollator": [[38, 3, 1, "", "__call__"]], "dist_utils": [[39, 5, 1, "", "barrier"], [39, 5, 1, "", "get_rank"], [39, 5, 1, "", "is_main"]], "embeddings": [[40, 1, 1, "", "LocalEmbeddings"], [40, 5, 1, "", "batch_iterator"], [40, 5, 1, "", "compute_embedding"], [40, 5, 1, "", "embed_document_batch"], [40, 4, 1, "", "logger"], [40, 5, 1, "", "mean_pooling"]], "embeddings.LocalEmbeddings": [[40, 3, 1, "", "embed_documents"], [40, 3, 1, "", "embed_query"]], "evaluation": [[41, 0, 0, "-", "evaluator"], [43, 0, 0, "-", "metrics"], [44, 0, 0, "-", "scores"], [45, 0, 0, "-", "utils"]], "evaluation.evaluator": [[41, 1, 1, "", "E2EEvaluator"], [41, 1, 1, "", "Evaluator"], [41, 1, 1, "", "EvaluatorConfig"], [41, 1, 1, "", "RetrieverEvaluator"]], "evaluation.evaluator.E2EEvaluator": [[41, 3, 1, "", "compute_performance"], [41, 3, 1, "", "evaluate"], [41, 3, 1, "", "init_metrics"], [41, 3, 1, "", "reset_all_metrics"]], "evaluation.evaluator.Evaluator": [[41, 3, 1, "", "_flatten_performance"], [41, 3, 1, "", "_get_data_iterator"], [41, 3, 1, "", "evaluate"]], "evaluation.evaluator.EvaluatorConfig": [[41, 2, 1, "", "assistant_prefix"], [41, 2, 1, "", "batch_size"], [41, 2, 1, "", "e2e_latency"], [41, 2, 1, "", "gen_answer_stats"], [41, 2, 1, "", "gen_bleu"], [41, 2, 1, "", "gen_f1"], [41, 2, 1, "", "gen_gpt4eval"], [41, 2, 1, "", "gen_latency"], [41, 2, 1, "", "gen_precision"], [41, 2, 1, "", "gen_rouge"], [41, 2, 1, "", "retr_document_accuracy"], [41, 2, 1, "", "retr_document_recall"], [41, 2, 1, "", "retr_latency"], [41, 2, 1, "", "sep_sys"], [41, 2, 1, "", "sep_user"], [41, 2, 1, "", "user_prefix"]], "evaluation.evaluator.RetrieverEvaluator": [[41, 3, 1, "", "compute_performance"], [41, 3, 1, "", "evaluate"], [41, 3, 1, "", "init_metrics"], [41, 3, 1, "", "reset_all_metrics"]], "evaluation.metrics": [[43, 1, 1, "", "AnswerStats"], [43, 1, 1, "", "BLEU"], [43, 1, 1, "", "DocumentAccuracy"], [43, 1, 1, "", "DocumentRecall"], [43, 1, 1, "", "F1"], [43, 1, 1, "", "GPT4Eval"], [43, 4, 1, "", "GPT_EVAL_ACC_PROMPT"], [43, 4, 1, "", "GPT_EVAL_NOANS_ACC_PROMPT"], [43, 1, 1, "", "Latency"], [43, 4, 1, "", "METRICS"], [43, 1, 1, "", "MonitoringMetric"], [43, 1, 1, "", "Precision"], [43, 1, 1, "", "ROUGE"], [43, 1, 1, "", "RunningMetic"], [43, 5, 1, "", "document_similarity"], [43, 5, 1, "", "is_almost_same_document"], [43, 5, 1, "", "is_same_document"], [43, 4, 1, "", "logger"], [43, 5, 1, "", "mean"]], "evaluation.metrics.AnswerStats": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.BLEU": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.DocumentAccuracy": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.DocumentRecall": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.F1": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.GPT4Eval": [[43, 3, 1, "", "_generate"], [43, 3, 1, "", "compute"], [43, 3, 1, "", "judge"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.Latency": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "start"], [43, 3, 1, "", "stop"]], "evaluation.metrics.MonitoringMetric": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "start"], [43, 3, 1, "", "stop"]], "evaluation.metrics.Precision": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.ROUGE": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.metrics.RunningMetic": [[43, 3, 1, "", "compute"], [43, 3, 1, "", "reset"], [43, 3, 1, "", "update"]], "evaluation.scores": [[44, 5, 1, "", "em"], [44, 5, 1, "", "exact_match_score"], [44, 5, 1, "", "f1"], [44, 5, 1, "", "f1_score"], [44, 5, 1, "", "precision"], [44, 5, 1, "", "recall"], [44, 4, 1, "", "rouge"], [44, 5, 1, "", "rouge_score"], [44, 5, 1, "", "rouge_wrapper"]], "evaluation.utils": [[45, 5, 1, "", "normalize_answer"]], "guardrails": [[46, 0, 0, "-", "base"]], "guardrails.base": [[46, 1, 1, "", "BaseAnswerGuardrail"], [46, 1, 1, "", "NoopAnswerGuardrail"]], "guardrails.base.BaseAnswerGuardrail": [[46, 3, 1, "", "guardrail"], [46, 3, 1, "", "run"], [46, 2, 1, "", "run_input_keys"]], "guardrails.base.NoopAnswerGuardrail": [[46, 3, 1, "", "guardrail"]], "local_rqa": [[1, 0, 0, "-", "base"], [2, 0, 0, "-", "constants"], [3, 0, 0, "-", "evaluation"], [7, 0, 0, "-", "guardrails"], [9, 0, 0, "-", "pipelines"], [12, 0, 0, "-", "qa_llms"], [21, 0, 0, "-", "retrievers"], [23, 0, 0, "-", "schema"], [26, 0, 0, "-", "serve"], [30, 0, 0, "-", "text_loaders"], [34, 0, 0, "-", "utils"]], "local_rqa.evaluation": [[4, 0, 0, "-", "metrics"], [5, 0, 0, "-", "scores"], [6, 0, 0, "-", "utils"]], "local_rqa.guardrails": [[8, 0, 0, "-", "base"]], "local_rqa.pipelines": [[10, 0, 0, "-", "base"], [11, 0, 0, "-", "prompts"]], "local_rqa.qa_llms": [[13, 0, 0, "-", "base"], [14, 0, 0, "-", "fid"], [15, 0, 0, "-", "huggingface"], [16, 0, 0, "-", "openai"], [17, 0, 0, "-", "prompts"], [18, 0, 0, "-", "sglang"], [19, 0, 0, "-", "tgi"], [20, 0, 0, "-", "vllm"]], "local_rqa.retrievers": [[22, 0, 0, "-", "base"]], "local_rqa.schema": [[24, 0, 0, "-", "dialogue"], [25, 0, 0, "-", "document"]], "local_rqa.serve": [[27, 0, 0, "-", "base_model_worker"], [28, 0, 0, "-", "gradio_dialogue"], [29, 0, 0, "-", "test_message"]], "local_rqa.text_loaders": [[31, 0, 0, "-", "base"], [32, 0, 0, "-", "langchain_text_loader"], [33, 0, 0, "-", "llamaindex_text_loader"]], "pipelines": [[49, 0, 0, "-", "base"], [51, 0, 0, "-", "prompts"], [52, 0, 0, "-", "retrieval_qa"]], "pipelines.base": [[49, 1, 1, "", "RQAPipeline"], [49, 4, 1, "", "logger"]], "pipelines.base.RQAPipeline": [[49, 3, 1, "", "_prepare_input"], [49, 3, 1, "", "components"], [49, 3, 1, "", "qa"], [49, 3, 1, "", "run"], [49, 2, 1, "", "run_input_keys"], [49, 3, 1, "", "update_dialogue_session"]], "pipelines.prompts": [[51, 4, 1, "", "REPHRASE_QUESTION_PROMPT"]], "pipelines.retrieval_qa": [[52, 1, 1, "", "AutoRQA"], [52, 1, 1, "", "BaseRQA"], [52, 1, 1, "", "SimpleRQA"], [52, 4, 1, "", "logger"]], "pipelines.retrieval_qa.SimpleRQA": [[52, 3, 1, "", "_batch_generate"], [52, 3, 1, "", "_rephrase_questions"], [52, 3, 1, "", "from_huggingface"], [52, 3, 1, "", "from_huggingface_fid"], [52, 3, 1, "", "from_openai"], [52, 3, 1, "", "from_scratch"], [52, 3, 1, "", "from_sglang"], [52, 3, 1, "", "from_tgi"], [52, 3, 1, "", "from_vllm"], [52, 3, 1, "", "qa"], [52, 3, 1, "", "rephrase_questions"]], "qa_llms": [[53, 0, 0, "-", "base"], [54, 0, 0, "-", "fid"], [55, 0, 0, "-", "huggingface"], [57, 0, 0, "-", "openai"], [58, 0, 0, "-", "prompts"], [59, 0, 0, "-", "sglang"], [60, 0, 0, "-", "tgi"], [61, 0, 0, "-", "vllm"]], "qa_llms.base": [[53, 1, 1, "", "BaseQAModel"], [53, 1, 1, "", "GenerationOutput"]], "qa_llms.base.BaseQAModel": [[53, 3, 1, "", "_prepare_question_w_docs"], [53, 3, 1, "", "generate"], [53, 2, 1, "", "is_api_model"], [53, 3, 1, "", "r_generate"], [53, 3, 1, "", "run"], [53, 2, 1, "", "run_input_keys"]], "qa_llms.base.GenerationOutput": [[53, 2, 1, "", "batch_answers"]], "qa_llms.fid": [[54, 1, 1, "", "CheckpointWrapper"], [54, 1, 1, "", "EncoderWrapper"], [54, 1, 1, "", "FiDT5"], [54, 5, 1, "", "apply_checkpoint_wrapper"], [54, 5, 1, "", "cross_attention_forward"]], "qa_llms.fid.CheckpointWrapper": [[54, 3, 1, "", "forward"]], "qa_llms.fid.EncoderWrapper": [[54, 3, 1, "", "forward"]], "qa_llms.fid.FiDT5": [[54, 3, 1, "", "forward"], [54, 3, 1, "", "forward_"], [54, 3, 1, "", "from_t5"], [54, 3, 1, "", "generate"], [54, 3, 1, "", "get_crossattention_scores"], [54, 3, 1, "", "load_t5"], [54, 3, 1, "", "overwrite_forward_crossattention"], [54, 3, 1, "", "reset_score_storage"], [54, 3, 1, "", "set_checkpoint"], [54, 3, 1, "", "unwrap_encoder"], [54, 3, 1, "", "wrap_encoder"]], "qa_llms.huggingface": [[55, 1, 1, "", "HuggingFaceFiDQAModel"], [55, 1, 1, "", "HuggingFaceQAModel"]], "qa_llms.huggingface.HuggingFaceFiDQAModel": [[55, 3, 1, "", "_init"], [55, 3, 1, "", "_prepare_question_w_docs"], [55, 3, 1, "", "encode_fid_inputs"], [55, 3, 1, "", "generate"], [55, 3, 1, "", "pack_fid_inputs"], [55, 3, 1, "", "r_generate"], [55, 3, 1, "", "unpack_fid_inputs"]], "qa_llms.huggingface.HuggingFaceQAModel": [[55, 3, 1, "", "_init"], [55, 3, 1, "", "_prepare_question_w_docs"], [55, 3, 1, "", "generate"], [55, 3, 1, "", "r_generate"]], "qa_llms.openai": [[57, 1, 1, "", "OpenAIQAModel"]], "qa_llms.openai.OpenAIQAModel": [[57, 3, 1, "", "_prepare_question_w_docs"], [57, 3, 1, "", "generate"], [57, 3, 1, "", "r_generate"]], "qa_llms.prompts": [[58, 4, 1, "", "RQA_PROMPT"], [58, 4, 1, "", "RQA_PROMPT_TRAIN"]], "qa_llms.sglang": [[59, 1, 1, "", "SGLangClient"], [59, 1, 1, "", "SGLangQAModel"], [59, 4, 1, "", "logger"], [59, 4, 1, "", "rqa_model"]], "qa_llms.sglang.SGLangClient": [[59, 3, 1, "", "_get_response"], [59, 3, 1, "", "_get_streaming_response"], [59, 3, 1, "", "_post_http_request"], [59, 3, 1, "", "generate"], [59, 3, 1, "", "generate_stream"]], "qa_llms.sglang.SGLangQAModel": [[59, 3, 1, "", "_generate"], [59, 3, 1, "", "_generate_stream"], [59, 3, 1, "", "_prepare_question_w_docs"], [59, 3, 1, "", "generate"], [59, 2, 1, "", "is_api_model"], [59, 3, 1, "", "prepare_gen_kwargs"], [59, 3, 1, "", "r_generate"]], "qa_llms.tgi": [[60, 1, 1, "", "TGIQAModel"], [60, 4, 1, "", "logger"]], "qa_llms.tgi.TGIQAModel": [[60, 3, 1, "", "_generate"], [60, 3, 1, "", "_generate_stream"], [60, 3, 1, "", "_prepare_question_w_docs"], [60, 3, 1, "", "generate"], [60, 2, 1, "", "is_api_model"], [60, 3, 1, "", "prepare_gen_kwargs"], [60, 3, 1, "", "r_generate"]], "qa_llms.vllm": [[61, 1, 1, "", "VLLMClient"], [61, 4, 1, "", "logger"], [61, 4, 1, "", "rqa_model"], [61, 1, 1, "", "vLLMQAModel"]], "qa_llms.vllm.VLLMClient": [[61, 3, 1, "", "_get_response"], [61, 3, 1, "", "_get_streaming_response"], [61, 3, 1, "", "_post_http_request"], [61, 3, 1, "", "generate"], [61, 3, 1, "", "generate_stream"]], "qa_llms.vllm.vLLMQAModel": [[61, 3, 1, "", "_generate"], [61, 3, 1, "", "_generate_stream"], [61, 3, 1, "", "_prepare_question_w_docs"], [61, 3, 1, "", "generate"], [61, 2, 1, "", "is_api_model"], [61, 3, 1, "", "prepare_gen_kwargs"], [61, 3, 1, "", "r_generate"]], "retriever_fid_trainer": [[62, 1, 1, "", "FidRetrieverTrainer"]], "retriever_fid_trainer.FidRetrieverTrainer": [[62, 3, 1, "", "_load_all_docs"], [62, 3, 1, "", "_load_eval_data"], [62, 3, 1, "", "_save"], [62, 3, 1, "", "compute_loss"], [62, 3, 1, "", "embed_text"], [62, 3, 1, "", "evaluation_loop"], [62, 3, 1, "", "kldivloss"], [62, 3, 1, "", "prediction_step"], [62, 3, 1, "", "wrap_model_for_eval"]], "retriever_replug_trainer": [[63, 4, 1, "", "GREEN"], [63, 4, 1, "", "IGNORE_TOKEN_ID"], [63, 4, 1, "", "PROMPT"], [63, 4, 1, "", "RED"], [63, 4, 1, "", "RESET"], [63, 1, 1, "", "ReplugRetrieverTrainer"]], "retriever_replug_trainer.ReplugRetrieverTrainer": [[63, 3, 1, "", "_load_all_docs"], [63, 3, 1, "", "_load_eval_data"], [63, 3, 1, "", "_save"], [63, 3, 1, "", "compute_loss"], [63, 3, 1, "", "evaluation_loop"], [63, 3, 1, "", "get_seq_prob"], [63, 3, 1, "", "instruct"], [63, 3, 1, "", "kldivloss"], [63, 3, 1, "", "prediction_step"], [63, 3, 1, "", "wrap_model_for_eval"]], "retriever_trainer": [[64, 1, 1, "", "RetrieverTrainer"]], "retriever_trainer.RetrieverTrainer": [[64, 3, 1, "", "_inbatch_contrastive_w_hardneg"], [64, 3, 1, "", "_load_all_docs"], [64, 3, 1, "", "_load_eval_data"], [64, 3, 1, "", "_save"], [64, 3, 1, "", "compute_loss"], [64, 3, 1, "", "evaluation_loop"], [64, 3, 1, "", "prediction_step"], [64, 3, 1, "", "wrap_model_for_eval"]], "retrievers": [[65, 0, 0, "-", "base"], [66, 0, 0, "-", "bm25_retriever"], [67, 0, 0, "-", "faiss_retriever"]], "retrievers.base": [[65, 1, 1, "", "BaseRetriever"], [65, 1, 1, "", "DummyRetriever"], [65, 1, 1, "", "RetrievalOutput"]], "retrievers.base.BaseRetriever": [[65, 3, 1, "", "retrieve"], [65, 3, 1, "", "run"], [65, 2, 1, "", "run_input_keys"]], "retrievers.base.DummyRetriever": [[65, 3, 1, "", "retrieve"]], "retrievers.base.RetrievalOutput": [[65, 2, 1, "", "batch_source_documents"]], "retrievers.bm25_retriever": [[66, 1, 1, "", "BM25Retriever"], [66, 1, 1, "", "BM25Tokenizer"], [66, 5, 1, "", "normalize_string"]], "retrievers.bm25_retriever.BM25Retriever": [[66, 3, 1, "", "retrieve"]], "retrievers.bm25_retriever.BM25Tokenizer": [[66, 3, 1, "", "__call__"]], "retrievers.faiss_retriever": [[67, 1, 1, "", "FaissRetriever"], [67, 4, 1, "", "logger"]], "retrievers.faiss_retriever.FaissRetriever": [[67, 3, 1, "", "_init_retriever"], [67, 3, 1, "", "from_disk"], [67, 3, 1, "", "prepare_docs_for_retrieval"], [67, 3, 1, "", "retrieve"], [67, 3, 1, "", "retrieve_w_score"]], "schema": [[69, 0, 0, "-", "dialogue"], [70, 0, 0, "-", "document"]], "schema.dialogue": [[69, 1, 1, "", "DialogueSession"], [69, 1, 1, "", "DialogueTurn"], [69, 1, 1, "", "RQAOutput"], [69, 1, 1, "", "SeparatorStyle"]], "schema.dialogue.DialogueSession": [[69, 3, 1, "", "add_system_message"], [69, 3, 1, "", "add_user_message"], [69, 2, 1, "", "assistant_prefix"], [69, 3, 1, "", "clone"], [69, 3, 1, "", "from_list"], [69, 2, 1, "", "history"], [69, 2, 1, "", "sep_style"], [69, 2, 1, "", "sep_sys"], [69, 2, 1, "", "sep_user"], [69, 3, 1, "", "to_list"], [69, 3, 1, "", "to_string"], [69, 2, 1, "", "user_prefix"]], "schema.dialogue.DialogueTurn": [[69, 3, 1, "", "clone"], [69, 3, 1, "", "from_dict"], [69, 2, 1, "", "message"], [69, 2, 1, "", "source_documents"], [69, 2, 1, "", "speaker"], [69, 3, 1, "", "to_dict"], [69, 3, 1, "", "to_string"]], "schema.dialogue.RQAOutput": [[69, 2, 1, "", "batch_answers"], [69, 2, 1, "", "batch_dialogue_session"], [69, 2, 1, "", "batch_source_documents"]], "schema.dialogue.SeparatorStyle": [[69, 2, 1, "", "SINGLE"], [69, 2, 1, "", "TWO"]], "schema.document": [[70, 1, 1, "", "Document"], [70, 5, 1, "", "default_document_formatter"]], "schema.document.Document": [[70, 3, 1, "", "__post_init__"], [70, 3, 1, "", "clone"], [70, 2, 1, "", "fmt_content"], [70, 3, 1, "", "from_dict"], [70, 3, 1, "", "from_langchain_doc"], [70, 2, 1, "", "metadata"], [70, 2, 1, "", "page_content"], [70, 3, 1, "", "to_dict"], [70, 3, 1, "", "to_langchain_doc"]], "serve": [[72, 0, 0, "-", "base_model_worker"], [73, 0, 0, "-", "controller"], [74, 0, 0, "-", "gradio_dialogue"], [75, 0, 0, "-", "gradio_rqa"], [76, 0, 0, "-", "gradio_static_server"], [77, 0, 0, "-", "gradio_web_server"], [79, 0, 0, "-", "model_worker"], [80, 0, 0, "-", "test_message"]], "serve.base_model_worker": [[72, 1, 1, "", "BaseModelWorker"], [72, 5, 1, "", "acquire_worker_semaphore"], [72, 5, 1, "", "api_count_token"], [72, 5, 1, "", "api_generate"], [72, 5, 1, "", "api_generate_stream"], [72, 5, 1, "", "api_get_conv"], [72, 5, 1, "", "api_get_status"], [72, 5, 1, "", "api_model_details"], [72, 5, 1, "", "api_retrieval"], [72, 4, 1, "", "app"], [72, 5, 1, "", "create_background_tasks"], [72, 5, 1, "", "heart_beat_worker"], [72, 4, 1, "", "logger"], [72, 5, 1, "", "release_worker_semaphore"], [72, 4, 1, "", "worker"]], "serve.base_model_worker.BaseModelWorker": [[72, 3, 1, "", "count_token"], [72, 3, 1, "", "generate_gate"], [72, 3, 1, "", "generate_stream_gate"], [72, 3, 1, "", "get_queue_length"], [72, 3, 1, "", "get_status"], [72, 3, 1, "", "init_heart_beat"], [72, 3, 1, "", "register_to_controller"], [72, 3, 1, "", "retrieve"], [72, 3, 1, "", "send_heart_beat"]], "serve.controller": [[73, 1, 1, "", "Controller"], [73, 1, 1, "", "DispatchMethod"], [73, 1, 1, "", "WorkerInfo"], [73, 4, 1, "", "app"], [73, 5, 1, "", "create_controller"], [73, 5, 1, "", "get_worker_address"], [73, 5, 1, "", "heart_beat_controller"], [73, 5, 1, "", "list_models"], [73, 4, 1, "", "logger"], [73, 5, 1, "", "receive_heart_beat"], [73, 5, 1, "", "refresh_all_workers"], [73, 5, 1, "", "register_worker"], [73, 5, 1, "", "worker_api_generate_stream"], [73, 5, 1, "id0", "worker_api_get_status"], [73, 5, 1, "", "worker_api_retrieval"]], "serve.controller.Controller": [[73, 3, 1, "", "get_worker_address"], [73, 3, 1, "", "get_worker_status"], [73, 3, 1, "", "handle_no_worker"], [73, 3, 1, "", "handle_worker_timeout"], [73, 3, 1, "", "list_models"], [73, 3, 1, "", "receive_heart_beat"], [73, 3, 1, "", "refresh_all_workers"], [73, 3, 1, "", "register_worker"], [73, 3, 1, "", "remove_stale_workers_by_expiration"], [73, 3, 1, "", "remove_worker"], [73, 3, 1, "", "worker_api_generate_stream"], [73, 3, 1, "", "worker_api_get_status"], [73, 3, 1, "", "worker_api_retrieval"]], "serve.controller.DispatchMethod": [[73, 2, 1, "", "LOTTERY"], [73, 2, 1, "", "SHORTEST_QUEUE"], [73, 3, 1, "", "from_str"]], "serve.controller.WorkerInfo": [[73, 2, 1, "", "check_heart_beat"], [73, 2, 1, "", "last_heart_beat"], [73, 2, 1, "", "model_names"], [73, 2, 1, "", "queue_length"], [73, 2, 1, "", "speed"]], "serve.gradio_dialogue": [[74, 1, 1, "", "AnnotationHistory"], [74, 1, 1, "", "GradioDialogueSession"], [74, 4, 1, "", "conv_templates"], [74, 4, 1, "", "conv_vicuna_v1"], [74, 4, 1, "", "default_conversation"]], "serve.gradio_dialogue.AnnotationHistory": [[74, 3, 1, "", "_data_idx_filter"], [74, 3, 1, "", "get_current_idx"], [74, 3, 1, "", "get_current_label"], [74, 3, 1, "", "get_next_idx"], [74, 3, 1, "", "get_num_labeled"], [74, 3, 1, "", "get_num_to_label"], [74, 3, 1, "", "get_prev_idx"], [74, 3, 1, "", "is_all_labeled"], [74, 3, 1, "", "load"], [74, 3, 1, "", "parse_int_range"], [74, 3, 1, "", "to_jsonl"], [74, 3, 1, "", "update_label"]], "serve.gradio_dialogue.GradioDialogueSession": [[74, 2, 1, "", "_session"], [74, 2, 1, "", "_tmp_data"], [74, 3, 1, "", "add_system_message"], [74, 3, 1, "", "add_user_message"], [74, 3, 1, "", "clone"], [74, 3, 1, "", "get_prompt"], [74, 2, 1, "", "skip_next"], [74, 3, 1, "", "to_dict"], [74, 3, 1, "", "to_gradio_chatbot"]], "serve.gradio_rqa": [[75, 1, 1, "", "GradioRQA"], [75, 1, 1, "", "GradioSimpleRQA"], [75, 4, 1, "", "logger"]], "serve.gradio_rqa.GradioRQA": [[75, 3, 1, "", "generate_stream_from_api"], [75, 3, 1, "", "get_model"], [75, 3, 1, "", "get_tokenizer"], [75, 3, 1, "", "prepare_prompt_for_generation"], [75, 3, 1, "", "rephrase_question_for_retrieval"], [75, 3, 1, "", "retrieve"]], "serve.gradio_rqa.GradioSimpleRQA": [[75, 3, 1, "", "from_scratch"], [75, 3, 1, "", "generate_stream_from_api"], [75, 3, 1, "", "get_model"], [75, 3, 1, "", "get_tokenizer"], [75, 3, 1, "", "prepare_prompt_for_generation"], [75, 3, 1, "", "rephrase_question_for_retrieval"], [75, 3, 1, "", "retrieve"]], "serve.gradio_static_server": [[76, 4, 1, "", "ANN_CORRECT"], [76, 4, 1, "", "ANN_HARMFUL"], [76, 4, 1, "", "ANN_HELPFUL"], [76, 4, 1, "", "ANN_INCORRECT"], [76, 4, 1, "", "ANN_NOT_HARMFUL"], [76, 4, 1, "", "ANN_NOT_HELPFUL"], [76, 4, 1, "", "NUM_DOC_TO_RETRIEVE"], [76, 4, 1, "", "args"], [76, 4, 1, "", "block_css"], [76, 4, 1, "", "block_js"], [76, 5, 1, "", "build_demo"], [76, 4, 1, "", "disable_btn"], [76, 5, 1, "", "document_view"], [76, 4, 1, "", "enable_btn"], [76, 5, 1, "", "get_conv_log_filename"], [76, 4, 1, "", "headers"], [76, 4, 1, "", "learn_more_markdown"], [76, 5, 1, "", "load_demo"], [76, 4, 1, "", "logger"], [76, 4, 1, "", "no_change_btn"], [76, 4, 1, "", "parser"], [76, 5, 1, "", "render_next_session"], [76, 5, 1, "", "render_prev_session"], [76, 5, 1, "", "render_single_session"], [76, 5, 1, "", "save_annotations"], [76, 4, 1, "", "title_markdown"], [76, 4, 1, "", "tos_markdown"], [76, 5, 1, "", "vote_correctness"], [76, 5, 1, "", "vote_harmlessness"], [76, 5, 1, "", "vote_helpfulness"], [76, 5, 1, "", "vote_response"]], "serve.gradio_web_server": [[77, 4, 1, "", "NUM_DOC_TO_RETRIEVE"], [77, 5, 1, "", "add_text"], [77, 4, 1, "", "args"], [77, 4, 1, "", "block_css"], [77, 4, 1, "", "block_js"], [77, 5, 1, "", "build_demo"], [77, 5, 1, "", "clear_history"], [77, 4, 1, "", "disable_btn"], [77, 5, 1, "", "document_view"], [77, 5, 1, "", "downvote_last_response"], [77, 4, 1, "", "enable_btn"], [77, 5, 1, "", "flag_last_response"], [77, 5, 1, "", "get_conv_log_filename"], [77, 5, 1, "", "get_model_list"], [77, 4, 1, "", "headers"], [77, 5, 1, "", "http_generate"], [77, 5, 1, "", "http_retrieve"], [77, 4, 1, "", "learn_more_markdown"], [77, 5, 1, "", "load_demo"], [77, 5, 1, "", "load_demo_refresh_model_list"], [77, 4, 1, "", "logger"], [77, 4, 1, "", "no_change_btn"], [77, 4, 1, "", "parser"], [77, 5, 1, "", "regenerate"], [77, 4, 1, "", "title_markdown"], [77, 4, 1, "", "tos_markdown"], [77, 5, 1, "", "upvote_last_response"], [77, 5, 1, "", "violates_moderation"], [77, 5, 1, "", "vote_last_response"]], "serve.model_worker": [[79, 1, 1, "", "ModelWorker"], [79, 5, 1, "", "add_model_args"], [79, 5, 1, "", "create_model_worker"], [79, 5, 1, "", "load_model"], [79, 4, 1, "", "logger"], [79, 4, 1, "", "worker_id"]], "serve.model_worker.ModelWorker": [[79, 3, 1, "", "generate_gate"], [79, 3, 1, "", "generate_stream"], [79, 3, 1, "", "generate_stream_gate"], [79, 3, 1, "", "retrieve"]], "serve.test_message": [[80, 5, 1, "", "main"], [80, 4, 1, "", "parser"]], "supervised_fid_trainer": [[81, 1, 1, "", "SupervisedFiDTrainer"]], "supervised_fid_trainer.SupervisedFiDTrainer": [[81, 3, 1, "", "_load_eval_data"], [81, 3, 1, "", "compute_loss"], [81, 3, 1, "", "evaluation_loop"], [81, 3, 1, "", "prediction_step"], [81, 3, 1, "", "wrap_model_for_eval"]], "supervised_trainer": [[82, 1, 1, "", "SupervisedTrainer"]], "supervised_trainer.SupervisedTrainer": [[82, 3, 1, "", "_load_eval_data"], [82, 3, 1, "", "compute_loss"], [82, 3, 1, "", "evaluation_loop"], [82, 3, 1, "", "prediction_step"], [82, 3, 1, "", "wrap_model_for_eval"]], "text_loaders": [[83, 0, 0, "-", "base"], [85, 0, 0, "-", "langchain_text_loader"], [86, 0, 0, "-", "llamaindex_text_loader"]], "text_loaders.base": [[83, 1, 1, "", "BaseTextLoader"]], "text_loaders.base.BaseTextLoader": [[83, 3, 1, "", "_convert_doc"], [83, 3, 1, "", "load_data"], [83, 3, 1, "", "save_texts"]], "text_loaders.langchain_text_loader": [[85, 1, 1, "", "LangChainTextLoader"], [85, 4, 1, "", "loader_parameters"]], "text_loaders.langchain_text_loader.LangChainTextLoader": [[85, 3, 1, "", "load_data"], [85, 3, 1, "", "save_texts"]], "text_loaders.llamaindex_text_loader": [[86, 1, 1, "", "LlamaIndexTextLoader"], [86, 4, 1, "", "loader_func"]], "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader": [[86, 3, 1, "", "load_data"], [86, 3, 1, "", "save_texts"]], "utils": [[87, 5, 1, "", "create_dir_if_not_exists"], [87, 5, 1, "", "init_logger"], [87, 4, 1, "", "logger"], [87, 5, 1, "", "remove_optimizer_weights"]], "with_retriever_trainer": [[89, 1, 1, "", "FixedRetrieverTrainer"], [89, 5, 1, "", "batch_iterator"]], "with_retriever_trainer.FixedRetrieverTrainer": [[89, 3, 1, "", "_load_all_docs"], [89, 3, 1, "", "_load_eval_data"], [89, 3, 1, "", "compute_loss"], [89, 3, 1, "", "evaluation_loop"], [89, 3, 1, "", "prediction_step"], [89, 3, 1, "", "wrap_model_for_eval"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:data", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "data", "Python data"], "5": ["py", "function", "Python function"]}, "titleterms": {"local_rqa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 90], "base": [1, 8, 10, 13, 22, 31, 36, 46, 49, 53, 65, 83], "constant": [2, 37], "evalu": [3, 4, 5, 6, 41, 42, 43, 44, 45], "metric": [4, 43], "score": [5, 44], "util": [6, 34, 45, 87], "guardrail": [7, 8, 46, 47], "pipelin": [9, 10, 11, 49, 50, 51, 52], "prompt": [11, 17, 51, 58], "qa_llm": [12, 13, 14, 15, 16, 17, 18, 19, 20, 53, 54, 55, 56, 57, 58, 59, 60, 61], "fid": [14, 54], "huggingfac": [15, 55], "openai": [16, 57], "sglang": [18, 59], "tgi": [19, 60], "vllm": [20, 61], "retriev": [21, 22, 65, 66, 67, 68], "schema": [23, 24, 25, 69, 70, 71], "dialogu": [24, 69], "document": [25, 70, 91], "serv": [26, 27, 28, 29, 72, 73, 74, 75, 76, 77, 78, 79, 80], "base_model_work": [27, 72], "gradio_dialogu": [28, 74], "test_messag": [29, 80], "text_load": [30, 31, 32, 33, 83, 84, 85, 86], "langchain_text_load": [32, 85], "llamaindex_text_load": [33, 86], "argument": 35, "modul": [35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 89], "content": [35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 87, 89], "class": [35, 36, 37, 38, 40, 41, 43, 46, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 79, 81, 82, 83, 85, 86, 89], "attribut": [36, 37, 40, 43, 44, 49, 52, 59, 60, 61, 63, 67, 72, 73, 74, 75, 76, 77, 79, 80, 85, 86, 87], "dataset": 38, "function": [38, 39, 40, 43, 44, 45, 54, 66, 70, 72, 73, 76, 77, 79, 80, 87, 89], "dist_util": 39, "embed": 40, "submodul": [42, 47, 50, 56, 68, 71, 78, 84], "api": 48, "refer": 48, "retrieval_qa": 52, "retriever_fid_train": 62, "retriever_replug_train": 63, "retriever_train": 64, "bm25_retriev": 66, "faiss_retriev": 67, "control": 73, "gradio_rqa": 75, "gradio_static_serv": 76, "gradio_web_serv": 77, "model_work": 79, "supervised_fid_train": 81, "supervised_train": 82, "with_retriever_fid_train": 88, "with_retriever_train": 89, "welcom": 91, "localrqa": 91, "": 91, "indic": 91, "tabl": 91}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"local_rqa": [[0, "module-local_rqa"], [90, "local-rqa"]], "local_rqa.base": [[1, "module-local_rqa.base"]], "local_rqa.constants": [[2, "module-local_rqa.constants"]], "local_rqa.evaluation": [[3, "module-local_rqa.evaluation"]], "local_rqa.evaluation.metrics": [[4, "module-local_rqa.evaluation.metrics"]], "local_rqa.evaluation.scores": [[5, "module-local_rqa.evaluation.scores"]], "local_rqa.evaluation.utils": [[6, "module-local_rqa.evaluation.utils"]], "local_rqa.guardrails": [[7, "module-local_rqa.guardrails"]], "local_rqa.guardrails.base": [[8, "module-local_rqa.guardrails.base"]], "local_rqa.pipelines": [[9, "module-local_rqa.pipelines"]], "local_rqa.pipelines.base": [[10, "module-local_rqa.pipelines.base"]], "local_rqa.pipelines.prompts": [[11, "module-local_rqa.pipelines.prompts"]], "local_rqa.qa_llms": [[12, "module-local_rqa.qa_llms"]], "local_rqa.qa_llms.base": [[13, "module-local_rqa.qa_llms.base"]], "local_rqa.qa_llms.fid": [[14, "module-local_rqa.qa_llms.fid"]], "local_rqa.qa_llms.huggingface": [[15, "module-local_rqa.qa_llms.huggingface"]], "local_rqa.qa_llms.openai": [[16, "module-local_rqa.qa_llms.openai"]], "local_rqa.qa_llms.prompts": [[17, "module-local_rqa.qa_llms.prompts"]], "local_rqa.qa_llms.sglang": [[18, "module-local_rqa.qa_llms.sglang"]], "local_rqa.qa_llms.tgi": [[19, "module-local_rqa.qa_llms.tgi"]], "local_rqa.qa_llms.vllm": [[20, "module-local_rqa.qa_llms.vllm"]], "local_rqa.retrievers": [[21, "module-local_rqa.retrievers"]], "local_rqa.retrievers.base": [[22, "module-local_rqa.retrievers.base"]], "local_rqa.schema": [[23, "module-local_rqa.schema"]], "local_rqa.schema.dialogue": [[24, "module-local_rqa.schema.dialogue"]], "local_rqa.schema.document": [[25, "module-local_rqa.schema.document"]], "local_rqa.serve": [[26, "module-local_rqa.serve"]], "local_rqa.serve.base_model_worker": [[27, "module-local_rqa.serve.base_model_worker"]], "local_rqa.serve.gradio_dialogue": [[28, "module-local_rqa.serve.gradio_dialogue"]], "local_rqa.serve.test_message": [[29, "module-local_rqa.serve.test_message"]], "local_rqa.text_loaders": [[30, "module-local_rqa.text_loaders"]], "local_rqa.text_loaders.base": [[31, "module-local_rqa.text_loaders.base"]], "local_rqa.text_loaders.langchain_text_loader": [[32, "module-local_rqa.text_loaders.langchain_text_loader"]], "local_rqa.text_loaders.llamaindex_text_loader": [[33, "module-local_rqa.text_loaders.llamaindex_text_loader"]], "local_rqa.utils": [[34, "module-local_rqa.utils"]], "arguments": [[35, "module-arguments"]], "Module Contents": [[35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [49, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [69, "module-contents"], [70, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [76, "module-contents"], [77, "module-contents"], [79, "module-contents"], [80, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [85, "module-contents"], [86, "module-contents"], [87, "module-contents"], [89, "module-contents"]], "Classes": [[35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [40, "classes"], [41, "classes"], [43, "classes"], [46, "classes"], [49, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [57, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [69, "classes"], [70, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [79, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [85, "classes"], [86, "classes"], [89, "classes"]], "base": [[36, "module-base"]], "Attributes": [[36, "attributes"], [37, "attributes"], [40, "attributes"], [43, "attributes"], [44, "attributes"], [49, "attributes"], [52, "attributes"], [59, "attributes"], [60, "attributes"], [61, "attributes"], [63, "attributes"], [67, "attributes"], [72, "attributes"], [73, "attributes"], [74, "attributes"], [75, "attributes"], [76, "attributes"], [77, "attributes"], [79, "attributes"], [80, "attributes"], [85, "attributes"], [86, "attributes"], [87, "attributes"]], "constants": [[37, "module-constants"]], "datasets": [[38, "module-datasets"]], "Functions": [[38, "functions"], [39, "functions"], [40, "functions"], [43, "functions"], [44, "functions"], [45, "functions"], [54, "functions"], [66, "functions"], [70, "functions"], [72, "functions"], [73, "functions"], [76, "functions"], [77, "functions"], [79, "functions"], [80, "functions"], [87, "functions"], [89, "functions"]], "dist_utils": [[39, "module-dist_utils"]], "embeddings": [[40, "module-embeddings"]], "evaluation.evaluator": [[41, "module-evaluation.evaluator"]], "evaluation": [[42, "module-evaluation"]], "Submodules": [[42, "submodules"], [47, "submodules"], [50, "submodules"], [56, "submodules"], [68, "submodules"], [71, "submodules"], [78, "submodules"], [84, "submodules"]], "evaluation.metrics": [[43, "module-evaluation.metrics"]], "evaluation.scores": [[44, "module-evaluation.scores"]], "evaluation.utils": [[45, "module-evaluation.utils"]], "guardrails.base": [[46, "module-guardrails.base"]], "guardrails": [[47, "module-guardrails"]], "API Reference": [[48, "api-reference"]], "pipelines.base": [[49, "module-pipelines.base"]], "pipelines": [[50, "module-pipelines"]], "pipelines.prompts": [[51, "module-pipelines.prompts"]], "pipelines.retrieval_qa": [[52, "module-pipelines.retrieval_qa"]], "qa_llms.base": [[53, "module-qa_llms.base"]], "qa_llms.fid": [[54, "module-qa_llms.fid"]], "qa_llms.huggingface": [[55, "module-qa_llms.huggingface"]], "qa_llms": [[56, "module-qa_llms"]], "qa_llms.openai": [[57, "module-qa_llms.openai"]], "qa_llms.prompts": [[58, "module-qa_llms.prompts"]], "qa_llms.sglang": [[59, "module-qa_llms.sglang"]], "qa_llms.tgi": [[60, "module-qa_llms.tgi"]], "qa_llms.vllm": [[61, "module-qa_llms.vllm"]], "retriever_fid_trainer": [[62, "module-retriever_fid_trainer"]], "retriever_replug_trainer": [[63, "module-retriever_replug_trainer"]], "retriever_trainer": [[64, "module-retriever_trainer"]], "retrievers.base": [[65, "module-retrievers.base"]], "retrievers.bm25_retriever": [[66, "module-retrievers.bm25_retriever"]], "retrievers.faiss_retriever": [[67, "module-retrievers.faiss_retriever"]], "retrievers": [[68, "module-retrievers"]], "schema.dialogue": [[69, "module-schema.dialogue"]], "schema.document": [[70, "module-schema.document"]], "schema": [[71, "module-schema"]], "serve.base_model_worker": [[72, "module-serve.base_model_worker"]], "serve.controller": [[73, "module-serve.controller"]], "serve.gradio_dialogue": [[74, "module-serve.gradio_dialogue"]], "serve.gradio_rqa": [[75, "module-serve.gradio_rqa"]], "serve.gradio_static_server": [[76, "module-serve.gradio_static_server"]], "serve.gradio_web_server": [[77, "module-serve.gradio_web_server"]], "serve": [[78, "module-serve"]], "serve.model_worker": [[79, "module-serve.model_worker"]], "serve.test_message": [[80, "module-serve.test_message"]], "supervised_fid_trainer": [[81, "module-supervised_fid_trainer"]], "supervised_trainer": [[82, "module-supervised_trainer"]], "text_loaders.base": [[83, "module-text_loaders.base"]], "text_loaders": [[84, "module-text_loaders"]], "text_loaders.langchain_text_loader": [[85, "module-text_loaders.langchain_text_loader"]], "text_loaders.llamaindex_text_loader": [[86, "module-text_loaders.llamaindex_text_loader"]], "utils": [[87, "module-utils"]], "with_retriever_fid_trainer": [[88, "module-with_retriever_fid_trainer"]], "with_retriever_trainer": [[89, "module-with_retriever_trainer"]], "Welcome to LocalRQA\u2019s documentation!": [[91, "welcome-to-localrqa-s-documentation"]], "Indices and tables": [[91, "indices-and-tables"]]}, "indexentries": {"contrasitivetrainingargs (class in arguments)": [[35, "arguments.ContrasitiveTrainingArgs"]], "dataarguments (class in arguments)": [[35, "arguments.DataArguments"]], "fidtrainingargs (class in arguments)": [[35, "arguments.FidTrainingArgs"]], "loggerarguments (class in arguments)": [[35, "arguments.LoggerArguments"]], "modelarguments (class in arguments)": [[35, "arguments.ModelArguments"]], "replugtrainingargs (class in arguments)": [[35, "arguments.ReplugTrainingArgs"]], "retrievalqatrainingarguments (class in arguments)": [[35, "arguments.RetrievalQATrainingArguments"]], "apply_passage_mask (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.apply_passage_mask"]], "apply_question_mask (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.apply_question_mask"]], "arguments": [[35, "module-arguments"]], "contrastive_loss (arguments.contrasitivetrainingargs attribute)": [[35, "arguments.ContrasitiveTrainingArgs.contrastive_loss"]], "do_eval (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.do_eval"]], "do_train (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.do_train"]], "eval_file (arguments.dataarguments attribute)": [[35, "arguments.DataArguments.eval_file"]], "eval_steps (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.eval_steps"]], "evaluation_strategy (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.evaluation_strategy"]], "extract_cls (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.extract_cls"]], "full_dataset_file_path (arguments.dataarguments attribute)": [[35, "arguments.DataArguments.full_dataset_file_path"]], "gradient_checkpointing (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.gradient_checkpointing"]], "hard_neg_ratio (arguments.contrasitivetrainingargs attribute)": [[35, "arguments.ContrasitiveTrainingArgs.hard_neg_ratio"]], "indexing_dimension (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.indexing_dimension"]], "learning_rate (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.learning_rate"]], "lm_model_path (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.lm_model_path"]], "lm_temperature (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.lm_temperature"]], "logging_steps (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.logging_steps"]], "lr_scheduler_type (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.lr_scheduler_type"]], "max_steps (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.max_steps"]], "metric_for_best_model (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.metric_for_best_model"]], "model_name_or_path (arguments.modelarguments attribute)": [[35, "arguments.ModelArguments.model_name_or_path"]], "module": [[35, "module-arguments"], [36, "module-base"], [37, "module-constants"], [38, "module-datasets"], [39, "module-dist_utils"], [40, "module-embeddings"], [41, "module-evaluation.evaluator"], [42, "module-evaluation"], [43, "module-evaluation.metrics"], [44, "module-evaluation.scores"], [45, "module-evaluation.utils"], [46, "module-guardrails.base"], [47, "module-guardrails"], [49, "module-pipelines.base"], [50, "module-pipelines"], [51, "module-pipelines.prompts"], [52, "module-pipelines.retrieval_qa"], [53, "module-qa_llms.base"], [54, "module-qa_llms.fid"], [55, "module-qa_llms.huggingface"], [56, "module-qa_llms"], [57, "module-qa_llms.openai"], [58, "module-qa_llms.prompts"], [59, "module-qa_llms.sglang"], [60, "module-qa_llms.tgi"], [61, "module-qa_llms.vllm"], [62, "module-retriever_fid_trainer"], [63, "module-retriever_replug_trainer"], [64, "module-retriever_trainer"], [65, "module-retrievers.base"], [66, "module-retrievers.bm25_retriever"], [67, "module-retrievers.faiss_retriever"], [68, "module-retrievers"], [69, "module-schema.dialogue"], [70, "module-schema.document"], [71, "module-schema"], [72, "module-serve.base_model_worker"], [73, "module-serve.controller"], [74, "module-serve.gradio_dialogue"], [75, "module-serve.gradio_rqa"], [76, "module-serve.gradio_static_server"], [77, "module-serve.gradio_web_server"], [78, "module-serve"], [79, "module-serve.model_worker"], [80, "module-serve.test_message"], [81, "module-supervised_fid_trainer"], [82, "module-supervised_trainer"], [83, "module-text_loaders.base"], [84, "module-text_loaders"], [85, "module-text_loaders.langchain_text_loader"], [86, "module-text_loaders.llamaindex_text_loader"], [87, "module-utils"], [88, "module-with_retriever_fid_trainer"], [89, "module-with_retriever_trainer"]], "n_context (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.n_context"]], "num_docs (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.num_docs"]], "output_dir (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.output_dir"]], "per_device_eval_batch_size (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.per_device_eval_batch_size"]], "per_device_train_batch_size (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.per_device_train_batch_size"]], "pooling_type (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.pooling_type"]], "projection (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.projection"]], "reader_batch_size (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.reader_batch_size"]], "reader_model_path (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.reader_model_path"]], "reader_temperature (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.reader_temperature"]], "refresh_step (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.refresh_step"]], "remove_unused_columns (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.remove_unused_columns"]], "report_to (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.report_to"]], "retrieve_temperature (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.retrieve_temperature"]], "run_entity (arguments.loggerarguments attribute)": [[35, "arguments.LoggerArguments.run_entity"]], "run_group (arguments.loggerarguments attribute)": [[35, "arguments.LoggerArguments.run_group"]], "run_project (arguments.loggerarguments attribute)": [[35, "arguments.LoggerArguments.run_project"]], "save_steps (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.save_steps"]], "save_strategy (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.save_strategy"]], "save_total_limit (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.save_total_limit"]], "seed (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.seed"]], "temperature (arguments.contrasitivetrainingargs attribute)": [[35, "arguments.ContrasitiveTrainingArgs.temperature"]], "test_file (arguments.dataarguments attribute)": [[35, "arguments.DataArguments.test_file"]], "text_maxlength (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.text_maxlength"]], "text_maxlength (arguments.replugtrainingargs attribute)": [[35, "arguments.ReplugTrainingArgs.text_maxlength"]], "train_file (arguments.dataarguments attribute)": [[35, "arguments.DataArguments.train_file"]], "warmup_ratio (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.warmup_ratio"]], "weight_decay (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.weight_decay"]], "with_score (arguments.fidtrainingargs attribute)": [[35, "arguments.FidTrainingArgs.with_score"]], "write_predictions (arguments.retrievalqatrainingarguments attribute)": [[35, "arguments.RetrievalQATrainingArguments.write_predictions"]], "component (class in base)": [[36, "base.Component"]], "base": [[36, "module-base"]], "logger (in module base)": [[36, "base.logger"]], "run() (base.component method)": [[36, "base.Component.run"]], "run_input_keys (base.component attribute)": [[36, "base.Component.run_input_keys"]], "accelerationframework (class in constants)": [[37, "constants.AccelerationFramework"]], "context_overflow (constants.errorcode attribute)": [[37, "constants.ErrorCode.CONTEXT_OVERFLOW"]], "controller_heart_beat_expiration (in module constants)": [[37, "constants.CONTROLLER_HEART_BEAT_EXPIRATION"]], "controller_no_worker (constants.errorcode attribute)": [[37, "constants.ErrorCode.CONTROLLER_NO_WORKER"]], "controller_worker_timeout (constants.errorcode attribute)": [[37, "constants.ErrorCode.CONTROLLER_WORKER_TIMEOUT"]], "cuda_out_of_memory (constants.errorcode attribute)": [[37, "constants.ErrorCode.CUDA_OUT_OF_MEMORY"]], "engine_overloaded (constants.errorcode attribute)": [[37, "constants.ErrorCode.ENGINE_OVERLOADED"]], "errorcode (class in constants)": [[37, "constants.ErrorCode"]], "gradio_request_error (constants.errorcode attribute)": [[37, "constants.ErrorCode.GRADIO_REQUEST_ERROR"]], "gradio_stream_unknown_error (constants.errorcode attribute)": [[37, "constants.ErrorCode.GRADIO_STREAM_UNKNOWN_ERROR"]], "incorrect_auth_key (constants.errorcode attribute)": [[37, "constants.ErrorCode.INCORRECT_AUTH_KEY"]], "internal_error (constants.errorcode attribute)": [[37, "constants.ErrorCode.INTERNAL_ERROR"]], "invalid_auth_key (constants.errorcode attribute)": [[37, "constants.ErrorCode.INVALID_AUTH_KEY"]], "invalid_model (constants.errorcode attribute)": [[37, "constants.ErrorCode.INVALID_MODEL"]], "no_permission (constants.errorcode attribute)": [[37, "constants.ErrorCode.NO_PERMISSION"]], "openai_model_names (in module constants)": [[37, "constants.OPENAI_MODEL_NAMES"]], "param_out_of_range (constants.errorcode attribute)": [[37, "constants.ErrorCode.PARAM_OUT_OF_RANGE"]], "qa_error_msg (in module constants)": [[37, "constants.QA_ERROR_MSG"]], "qa_moderation_msg (in module constants)": [[37, "constants.QA_MODERATION_MSG"]], "quota_exceeded (constants.errorcode attribute)": [[37, "constants.ErrorCode.QUOTA_EXCEEDED"]], "rate_limit (constants.errorcode attribute)": [[37, "constants.ErrorCode.RATE_LIMIT"]], "server_error_msg (in module constants)": [[37, "constants.SERVER_ERROR_MSG"]], "server_logdir (in module constants)": [[37, "constants.SERVER_LOGDIR"]], "sglang (constants.accelerationframework attribute)": [[37, "constants.AccelerationFramework.SGLANG"]], "tgi (constants.accelerationframework attribute)": [[37, "constants.AccelerationFramework.TGI"]], "validation_type_error (constants.errorcode attribute)": [[37, "constants.ErrorCode.VALIDATION_TYPE_ERROR"]], "vllm (constants.accelerationframework attribute)": [[37, "constants.AccelerationFramework.VLLM"]], "worker_heart_beat_interval (in module constants)": [[37, "constants.WORKER_HEART_BEAT_INTERVAL"]], "constants": [[37, "module-constants"]], "contrastiveretrievaldataset (class in datasets)": [[38, "datasets.ContrastiveRetrievalDataset"]], "fidcollator (class in datasets)": [[38, "datasets.FidCollator"]], "fiddataset (class in datasets)": [[38, "datasets.FidDataset"]], "noopdatacollator (class in datasets)": [[38, "datasets.NoopDataCollator"]], "replugdataset (class in datasets)": [[38, "datasets.ReplugDataset"]], "retrievercollator (class in datasets)": [[38, "datasets.RetrieverCollator"]], "__call__() (datasets.fidcollator method)": [[38, "datasets.FidCollator.__call__"]], "__call__() (datasets.noopdatacollator method)": [[38, "datasets.NoopDataCollator.__call__"]], "__call__() (datasets.retrievercollator method)": [[38, "datasets.RetrieverCollator.__call__"]], "__getitem__() (datasets.contrastiveretrievaldataset method)": [[38, "datasets.ContrastiveRetrievalDataset.__getitem__"]], "__getitem__() (datasets.fiddataset method)": [[38, "datasets.FidDataset.__getitem__"]], "__getitem__() (datasets.replugdataset method)": [[38, "datasets.ReplugDataset.__getitem__"]], "__len__() (datasets.contrastiveretrievaldataset method)": [[38, "datasets.ContrastiveRetrievalDataset.__len__"]], "__len__() (datasets.fiddataset method)": [[38, "datasets.FidDataset.__len__"]], "__len__() (datasets.replugdataset method)": [[38, "datasets.ReplugDataset.__len__"]], "datasets": [[38, "module-datasets"]], "encode_passages() (in module datasets)": [[38, "datasets.encode_passages"]], "get_example() (datasets.fiddataset method)": [[38, "datasets.FidDataset.get_example"]], "get_target() (datasets.fiddataset method)": [[38, "datasets.FidDataset.get_target"]], "get_target() (datasets.replugdataset method)": [[38, "datasets.ReplugDataset.get_target"]], "load_fid_data() (in module datasets)": [[38, "datasets.load_fid_data"]], "prepare_data() (datasets.contrastiveretrievaldataset method)": [[38, "datasets.ContrastiveRetrievalDataset.prepare_data"]], "sort_data() (datasets.fiddataset method)": [[38, "datasets.FidDataset.sort_data"]], "barrier() (in module dist_utils)": [[39, "dist_utils.barrier"]], "dist_utils": [[39, "module-dist_utils"]], "get_rank() (in module dist_utils)": [[39, "dist_utils.get_rank"]], "is_main() (in module dist_utils)": [[39, "dist_utils.is_main"]], "localembeddings (class in embeddings)": [[40, "embeddings.LocalEmbeddings"]], "batch_iterator() (in module embeddings)": [[40, "embeddings.batch_iterator"]], "compute_embedding() (in module embeddings)": [[40, "embeddings.compute_embedding"]], "embed_document_batch() (in module embeddings)": [[40, "embeddings.embed_document_batch"]], "embed_documents() (embeddings.localembeddings method)": [[40, "embeddings.LocalEmbeddings.embed_documents"]], "embed_query() (embeddings.localembeddings method)": [[40, "embeddings.LocalEmbeddings.embed_query"]], "embeddings": [[40, "module-embeddings"]], "logger (in module embeddings)": [[40, "embeddings.logger"]], "mean_pooling() (in module embeddings)": [[40, "embeddings.mean_pooling"]], "e2eevaluator (class in evaluation.evaluator)": [[41, "evaluation.evaluator.E2EEvaluator"]], "evaluator (class in evaluation.evaluator)": [[41, "evaluation.evaluator.Evaluator"]], "evaluatorconfig (class in evaluation.evaluator)": [[41, "evaluation.evaluator.EvaluatorConfig"]], "retrieverevaluator (class in evaluation.evaluator)": [[41, "evaluation.evaluator.RetrieverEvaluator"]], "_flatten_performance() (evaluation.evaluator.evaluator method)": [[41, "evaluation.evaluator.Evaluator._flatten_performance"]], "_get_data_iterator() (evaluation.evaluator.evaluator method)": [[41, "evaluation.evaluator.Evaluator._get_data_iterator"]], "assistant_prefix (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.assistant_prefix"]], "batch_size (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.batch_size"]], "compute_performance() (evaluation.evaluator.e2eevaluator method)": [[41, "evaluation.evaluator.E2EEvaluator.compute_performance"]], "compute_performance() (evaluation.evaluator.retrieverevaluator method)": [[41, "evaluation.evaluator.RetrieverEvaluator.compute_performance"]], "e2e_latency (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.e2e_latency"]], "evaluate() (evaluation.evaluator.e2eevaluator method)": [[41, "evaluation.evaluator.E2EEvaluator.evaluate"]], "evaluate() (evaluation.evaluator.evaluator method)": [[41, "evaluation.evaluator.Evaluator.evaluate"]], "evaluate() (evaluation.evaluator.retrieverevaluator method)": [[41, "evaluation.evaluator.RetrieverEvaluator.evaluate"]], "evaluation.evaluator": [[41, "module-evaluation.evaluator"]], "gen_answer_stats (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_answer_stats"]], "gen_bleu (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_bleu"]], "gen_f1 (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_f1"]], "gen_gpt4eval (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_gpt4eval"]], "gen_latency (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_latency"]], "gen_precision (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_precision"]], "gen_rouge (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.gen_rouge"]], "init_metrics() (evaluation.evaluator.e2eevaluator method)": [[41, "evaluation.evaluator.E2EEvaluator.init_metrics"]], "init_metrics() (evaluation.evaluator.retrieverevaluator method)": [[41, "evaluation.evaluator.RetrieverEvaluator.init_metrics"]], "reset_all_metrics() (evaluation.evaluator.e2eevaluator method)": [[41, "evaluation.evaluator.E2EEvaluator.reset_all_metrics"]], "reset_all_metrics() (evaluation.evaluator.retrieverevaluator method)": [[41, "evaluation.evaluator.RetrieverEvaluator.reset_all_metrics"]], "retr_document_accuracy (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.retr_document_accuracy"]], "retr_document_recall (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.retr_document_recall"]], "retr_latency (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.retr_latency"]], "sep_sys (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.sep_sys"]], "sep_user (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.sep_user"]], "user_prefix (evaluation.evaluator.evaluatorconfig attribute)": [[41, "evaluation.evaluator.EvaluatorConfig.user_prefix"]], "evaluation": [[42, "module-evaluation"]], "answerstats (class in evaluation.metrics)": [[43, "evaluation.metrics.AnswerStats"]], "bleu (class in evaluation.metrics)": [[43, "evaluation.metrics.BLEU"]], "documentaccuracy (class in evaluation.metrics)": [[43, "evaluation.metrics.DocumentAccuracy"]], "documentrecall (class in evaluation.metrics)": [[43, "evaluation.metrics.DocumentRecall"]], "f1 (class in evaluation.metrics)": [[43, "evaluation.metrics.F1"]], "gpt4eval (class in evaluation.metrics)": [[43, "evaluation.metrics.GPT4Eval"]], "gpt_eval_acc_prompt (in module evaluation.metrics)": [[43, "evaluation.metrics.GPT_EVAL_ACC_PROMPT"]], "gpt_eval_noans_acc_prompt (in module evaluation.metrics)": [[43, "evaluation.metrics.GPT_EVAL_NOANS_ACC_PROMPT"]], "latency (class in evaluation.metrics)": [[43, "evaluation.metrics.Latency"]], "metrics (in module evaluation.metrics)": [[43, "evaluation.metrics.METRICS"]], "monitoringmetric (class in evaluation.metrics)": [[43, "evaluation.metrics.MonitoringMetric"]], "precision (class in evaluation.metrics)": [[43, "evaluation.metrics.Precision"]], "rouge (class in evaluation.metrics)": [[43, "evaluation.metrics.ROUGE"]], "runningmetic (class in evaluation.metrics)": [[43, "evaluation.metrics.RunningMetic"]], "_generate() (evaluation.metrics.gpt4eval method)": [[43, "evaluation.metrics.GPT4Eval._generate"]], "compute() (evaluation.metrics.answerstats method)": [[43, "evaluation.metrics.AnswerStats.compute"]], "compute() (evaluation.metrics.bleu method)": [[43, "evaluation.metrics.BLEU.compute"]], "compute() (evaluation.metrics.documentaccuracy method)": [[43, "evaluation.metrics.DocumentAccuracy.compute"]], "compute() (evaluation.metrics.documentrecall method)": [[43, "evaluation.metrics.DocumentRecall.compute"]], "compute() (evaluation.metrics.f1 method)": [[43, "evaluation.metrics.F1.compute"]], "compute() (evaluation.metrics.gpt4eval method)": [[43, "evaluation.metrics.GPT4Eval.compute"]], "compute() (evaluation.metrics.latency method)": [[43, "evaluation.metrics.Latency.compute"]], "compute() (evaluation.metrics.monitoringmetric method)": [[43, "evaluation.metrics.MonitoringMetric.compute"]], "compute() (evaluation.metrics.precision method)": [[43, "evaluation.metrics.Precision.compute"]], "compute() (evaluation.metrics.rouge method)": [[43, "evaluation.metrics.ROUGE.compute"]], "compute() (evaluation.metrics.runningmetic method)": [[43, "evaluation.metrics.RunningMetic.compute"]], "document_similarity() (in module evaluation.metrics)": [[43, "evaluation.metrics.document_similarity"]], "evaluation.metrics": [[43, "module-evaluation.metrics"]], "is_almost_same_document() (in module evaluation.metrics)": [[43, "evaluation.metrics.is_almost_same_document"]], "is_same_document() (in module evaluation.metrics)": [[43, "evaluation.metrics.is_same_document"]], "judge() (evaluation.metrics.gpt4eval method)": [[43, "evaluation.metrics.GPT4Eval.judge"]], "logger (in module evaluation.metrics)": [[43, "evaluation.metrics.logger"]], "mean() (in module evaluation.metrics)": [[43, "evaluation.metrics.mean"]], "reset() (evaluation.metrics.answerstats method)": [[43, "evaluation.metrics.AnswerStats.reset"]], "reset() (evaluation.metrics.bleu method)": [[43, "evaluation.metrics.BLEU.reset"]], "reset() (evaluation.metrics.documentaccuracy method)": [[43, "evaluation.metrics.DocumentAccuracy.reset"]], "reset() (evaluation.metrics.documentrecall method)": [[43, "evaluation.metrics.DocumentRecall.reset"]], "reset() (evaluation.metrics.f1 method)": [[43, "evaluation.metrics.F1.reset"]], "reset() (evaluation.metrics.gpt4eval method)": [[43, "evaluation.metrics.GPT4Eval.reset"]], "reset() (evaluation.metrics.latency method)": [[43, "evaluation.metrics.Latency.reset"]], "reset() (evaluation.metrics.monitoringmetric method)": [[43, "evaluation.metrics.MonitoringMetric.reset"]], "reset() (evaluation.metrics.precision method)": [[43, "evaluation.metrics.Precision.reset"]], "reset() (evaluation.metrics.rouge method)": [[43, "evaluation.metrics.ROUGE.reset"]], "reset() (evaluation.metrics.runningmetic method)": [[43, "evaluation.metrics.RunningMetic.reset"]], "start() (evaluation.metrics.latency method)": [[43, "evaluation.metrics.Latency.start"]], "start() (evaluation.metrics.monitoringmetric method)": [[43, "evaluation.metrics.MonitoringMetric.start"]], "stop() (evaluation.metrics.latency method)": [[43, "evaluation.metrics.Latency.stop"]], "stop() (evaluation.metrics.monitoringmetric method)": [[43, "evaluation.metrics.MonitoringMetric.stop"]], "update() (evaluation.metrics.answerstats method)": [[43, "evaluation.metrics.AnswerStats.update"]], "update() (evaluation.metrics.bleu method)": [[43, "evaluation.metrics.BLEU.update"]], "update() (evaluation.metrics.documentaccuracy method)": [[43, "evaluation.metrics.DocumentAccuracy.update"]], "update() (evaluation.metrics.documentrecall method)": [[43, "evaluation.metrics.DocumentRecall.update"]], "update() (evaluation.metrics.f1 method)": [[43, "evaluation.metrics.F1.update"]], "update() (evaluation.metrics.gpt4eval method)": [[43, "evaluation.metrics.GPT4Eval.update"]], "update() (evaluation.metrics.precision method)": [[43, "evaluation.metrics.Precision.update"]], "update() (evaluation.metrics.rouge method)": [[43, "evaluation.metrics.ROUGE.update"]], "update() (evaluation.metrics.runningmetic method)": [[43, "evaluation.metrics.RunningMetic.update"]], "em() (in module evaluation.scores)": [[44, "evaluation.scores.em"]], "evaluation.scores": [[44, "module-evaluation.scores"]], "exact_match_score() (in module evaluation.scores)": [[44, "evaluation.scores.exact_match_score"]], "f1() (in module evaluation.scores)": [[44, "evaluation.scores.f1"]], "f1_score() (in module evaluation.scores)": [[44, "evaluation.scores.f1_score"]], "precision() (in module evaluation.scores)": [[44, "evaluation.scores.precision"]], "recall() (in module evaluation.scores)": [[44, "evaluation.scores.recall"]], "rouge (in module evaluation.scores)": [[44, "evaluation.scores.rouge"]], "rouge_score() (in module evaluation.scores)": [[44, "evaluation.scores.rouge_score"]], "rouge_wrapper() (in module evaluation.scores)": [[44, "evaluation.scores.rouge_wrapper"]], "evaluation.utils": [[45, "module-evaluation.utils"]], "normalize_answer() (in module evaluation.utils)": [[45, "evaluation.utils.normalize_answer"]], "baseanswerguardrail (class in guardrails.base)": [[46, "guardrails.base.BaseAnswerGuardrail"]], "noopanswerguardrail (class in guardrails.base)": [[46, "guardrails.base.NoopAnswerGuardrail"]], "guardrail() (guardrails.base.baseanswerguardrail method)": [[46, "guardrails.base.BaseAnswerGuardrail.guardrail"]], "guardrail() (guardrails.base.noopanswerguardrail method)": [[46, "guardrails.base.NoopAnswerGuardrail.guardrail"]], "guardrails.base": [[46, "module-guardrails.base"]], "run() (guardrails.base.baseanswerguardrail method)": [[46, "guardrails.base.BaseAnswerGuardrail.run"]], "run_input_keys (guardrails.base.baseanswerguardrail attribute)": [[46, "guardrails.base.BaseAnswerGuardrail.run_input_keys"]], "guardrails": [[47, "module-guardrails"]], "rqapipeline (class in pipelines.base)": [[49, "pipelines.base.RQAPipeline"]], "_prepare_input() (pipelines.base.rqapipeline method)": [[49, "pipelines.base.RQAPipeline._prepare_input"]], "components() (pipelines.base.rqapipeline method)": [[49, "pipelines.base.RQAPipeline.components"]], "logger (in module pipelines.base)": [[49, "pipelines.base.logger"]], "pipelines.base": [[49, "module-pipelines.base"]], "qa() (pipelines.base.rqapipeline method)": [[49, "pipelines.base.RQAPipeline.qa"]], "run() (pipelines.base.rqapipeline method)": [[49, "pipelines.base.RQAPipeline.run"]], "run_input_keys (pipelines.base.rqapipeline attribute)": [[49, "pipelines.base.RQAPipeline.run_input_keys"]], "update_dialogue_session() (pipelines.base.rqapipeline method)": [[49, "pipelines.base.RQAPipeline.update_dialogue_session"]], "pipelines": [[50, "module-pipelines"]], "rephrase_question_prompt (in module pipelines.prompts)": [[51, "pipelines.prompts.REPHRASE_QUESTION_PROMPT"]], "pipelines.prompts": [[51, "module-pipelines.prompts"]], "autorqa (class in pipelines.retrieval_qa)": [[52, "pipelines.retrieval_qa.AutoRQA"]], "baserqa (class in pipelines.retrieval_qa)": [[52, "pipelines.retrieval_qa.BaseRQA"]], "simplerqa (class in pipelines.retrieval_qa)": [[52, "pipelines.retrieval_qa.SimpleRQA"]], "_batch_generate() (pipelines.retrieval_qa.simplerqa method)": [[52, "pipelines.retrieval_qa.SimpleRQA._batch_generate"]], "_rephrase_questions() (pipelines.retrieval_qa.simplerqa method)": [[52, "pipelines.retrieval_qa.SimpleRQA._rephrase_questions"]], "from_huggingface() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_huggingface"]], "from_huggingface_fid() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_huggingface_fid"]], "from_openai() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_openai"]], "from_scratch() (pipelines.retrieval_qa.simplerqa class method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_scratch"]], "from_sglang() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_sglang"]], "from_tgi() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_tgi"]], "from_vllm() (pipelines.retrieval_qa.simplerqa static method)": [[52, "pipelines.retrieval_qa.SimpleRQA.from_vllm"]], "logger (in module pipelines.retrieval_qa)": [[52, "pipelines.retrieval_qa.logger"]], "pipelines.retrieval_qa": [[52, "module-pipelines.retrieval_qa"]], "qa() (pipelines.retrieval_qa.simplerqa method)": [[52, "pipelines.retrieval_qa.SimpleRQA.qa"]], "rephrase_questions() (pipelines.retrieval_qa.simplerqa method)": [[52, "pipelines.retrieval_qa.SimpleRQA.rephrase_questions"]], "baseqamodel (class in qa_llms.base)": [[53, "qa_llms.base.BaseQAModel"]], "generationoutput (class in qa_llms.base)": [[53, "qa_llms.base.GenerationOutput"]], "_prepare_question_w_docs() (qa_llms.base.baseqamodel method)": [[53, "qa_llms.base.BaseQAModel._prepare_question_w_docs"]], "batch_answers (qa_llms.base.generationoutput attribute)": [[53, "qa_llms.base.GenerationOutput.batch_answers"]], "generate() (qa_llms.base.baseqamodel method)": [[53, "qa_llms.base.BaseQAModel.generate"]], "is_api_model (qa_llms.base.baseqamodel attribute)": [[53, "qa_llms.base.BaseQAModel.is_api_model"]], "qa_llms.base": [[53, "module-qa_llms.base"]], "r_generate() (qa_llms.base.baseqamodel method)": [[53, "qa_llms.base.BaseQAModel.r_generate"]], "run() (qa_llms.base.baseqamodel method)": [[53, "qa_llms.base.BaseQAModel.run"]], "run_input_keys (qa_llms.base.baseqamodel attribute)": [[53, "qa_llms.base.BaseQAModel.run_input_keys"]], "checkpointwrapper (class in qa_llms.fid)": [[54, "qa_llms.fid.CheckpointWrapper"]], "encoderwrapper (class in qa_llms.fid)": [[54, "qa_llms.fid.EncoderWrapper"]], "fidt5 (class in qa_llms.fid)": [[54, "qa_llms.fid.FiDT5"]], "apply_checkpoint_wrapper() (in module qa_llms.fid)": [[54, "qa_llms.fid.apply_checkpoint_wrapper"]], "cross_attention_forward() (in module qa_llms.fid)": [[54, "qa_llms.fid.cross_attention_forward"]], "forward() (qa_llms.fid.checkpointwrapper method)": [[54, "qa_llms.fid.CheckpointWrapper.forward"]], "forward() (qa_llms.fid.encoderwrapper method)": [[54, "qa_llms.fid.EncoderWrapper.forward"]], "forward() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.forward"]], "forward_() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.forward_"]], "from_t5() (qa_llms.fid.fidt5 static method)": [[54, "qa_llms.fid.FiDT5.from_t5"]], "generate() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.generate"]], "get_crossattention_scores() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.get_crossattention_scores"]], "load_t5() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.load_t5"]], "overwrite_forward_crossattention() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.overwrite_forward_crossattention"]], "qa_llms.fid": [[54, "module-qa_llms.fid"]], "reset_score_storage() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.reset_score_storage"]], "set_checkpoint() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.set_checkpoint"]], "unwrap_encoder() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.unwrap_encoder"]], "wrap_encoder() (qa_llms.fid.fidt5 method)": [[54, "qa_llms.fid.FiDT5.wrap_encoder"]], "huggingfacefidqamodel (class in qa_llms.huggingface)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel"]], "huggingfaceqamodel (class in qa_llms.huggingface)": [[55, "qa_llms.huggingface.HuggingFaceQAModel"]], "_init() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel._init"]], "_init() (qa_llms.huggingface.huggingfaceqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceQAModel._init"]], "_prepare_question_w_docs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel._prepare_question_w_docs"]], "_prepare_question_w_docs() (qa_llms.huggingface.huggingfaceqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceQAModel._prepare_question_w_docs"]], "encode_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel.encode_fid_inputs"]], "generate() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel.generate"]], "generate() (qa_llms.huggingface.huggingfaceqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceQAModel.generate"]], "pack_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel.pack_fid_inputs"]], "qa_llms.huggingface": [[55, "module-qa_llms.huggingface"]], "r_generate() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel.r_generate"]], "r_generate() (qa_llms.huggingface.huggingfaceqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceQAModel.r_generate"]], "unpack_fid_inputs() (qa_llms.huggingface.huggingfacefidqamodel method)": [[55, "qa_llms.huggingface.HuggingFaceFiDQAModel.unpack_fid_inputs"]], "qa_llms": [[56, "module-qa_llms"]], "openaiqamodel (class in qa_llms.openai)": [[57, "qa_llms.openai.OpenAIQAModel"]], "_prepare_question_w_docs() (qa_llms.openai.openaiqamodel method)": [[57, "qa_llms.openai.OpenAIQAModel._prepare_question_w_docs"]], "generate() (qa_llms.openai.openaiqamodel method)": [[57, "qa_llms.openai.OpenAIQAModel.generate"]], "qa_llms.openai": [[57, "module-qa_llms.openai"]], "r_generate() (qa_llms.openai.openaiqamodel method)": [[57, "qa_llms.openai.OpenAIQAModel.r_generate"]], "rqa_prompt (in module qa_llms.prompts)": [[58, "qa_llms.prompts.RQA_PROMPT"]], "rqa_prompt_train (in module qa_llms.prompts)": [[58, "qa_llms.prompts.RQA_PROMPT_TRAIN"]], "qa_llms.prompts": [[58, "module-qa_llms.prompts"]], "sglangclient (class in qa_llms.sglang)": [[59, "qa_llms.sglang.SGLangClient"]], "sglangqamodel (class in qa_llms.sglang)": [[59, "qa_llms.sglang.SGLangQAModel"]], "_generate() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel._generate"]], "_generate_stream() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel._generate_stream"]], "_get_response() (qa_llms.sglang.sglangclient method)": [[59, "qa_llms.sglang.SGLangClient._get_response"]], "_get_streaming_response() (qa_llms.sglang.sglangclient method)": [[59, "qa_llms.sglang.SGLangClient._get_streaming_response"]], "_post_http_request() (qa_llms.sglang.sglangclient method)": [[59, "qa_llms.sglang.SGLangClient._post_http_request"]], "_prepare_question_w_docs() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel._prepare_question_w_docs"]], "generate() (qa_llms.sglang.sglangclient method)": [[59, "qa_llms.sglang.SGLangClient.generate"]], "generate() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel.generate"]], "generate_stream() (qa_llms.sglang.sglangclient method)": [[59, "qa_llms.sglang.SGLangClient.generate_stream"]], "is_api_model (qa_llms.sglang.sglangqamodel attribute)": [[59, "qa_llms.sglang.SGLangQAModel.is_api_model"]], "logger (in module qa_llms.sglang)": [[59, "qa_llms.sglang.logger"]], "prepare_gen_kwargs() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel.prepare_gen_kwargs"]], "qa_llms.sglang": [[59, "module-qa_llms.sglang"]], "r_generate() (qa_llms.sglang.sglangqamodel method)": [[59, "qa_llms.sglang.SGLangQAModel.r_generate"]], "rqa_model (in module qa_llms.sglang)": [[59, "qa_llms.sglang.rqa_model"]], "tgiqamodel (class in qa_llms.tgi)": [[60, "qa_llms.tgi.TGIQAModel"]], "_generate() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel._generate"]], "_generate_stream() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel._generate_stream"]], "_prepare_question_w_docs() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel._prepare_question_w_docs"]], "generate() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel.generate"]], "is_api_model (qa_llms.tgi.tgiqamodel attribute)": [[60, "qa_llms.tgi.TGIQAModel.is_api_model"]], "logger (in module qa_llms.tgi)": [[60, "qa_llms.tgi.logger"]], "prepare_gen_kwargs() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel.prepare_gen_kwargs"]], "qa_llms.tgi": [[60, "module-qa_llms.tgi"]], "r_generate() (qa_llms.tgi.tgiqamodel method)": [[60, "qa_llms.tgi.TGIQAModel.r_generate"]], "vllmclient (class in qa_llms.vllm)": [[61, "qa_llms.vllm.VLLMClient"]], "_generate() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel._generate"]], "_generate_stream() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel._generate_stream"]], "_get_response() (qa_llms.vllm.vllmclient method)": [[61, "qa_llms.vllm.VLLMClient._get_response"]], "_get_streaming_response() (qa_llms.vllm.vllmclient method)": [[61, "qa_llms.vllm.VLLMClient._get_streaming_response"]], "_post_http_request() (qa_llms.vllm.vllmclient method)": [[61, "qa_llms.vllm.VLLMClient._post_http_request"]], "_prepare_question_w_docs() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel._prepare_question_w_docs"]], "generate() (qa_llms.vllm.vllmclient method)": [[61, "qa_llms.vllm.VLLMClient.generate"]], "generate() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel.generate"]], "generate_stream() (qa_llms.vllm.vllmclient method)": [[61, "qa_llms.vllm.VLLMClient.generate_stream"]], "is_api_model (qa_llms.vllm.vllmqamodel attribute)": [[61, "qa_llms.vllm.vLLMQAModel.is_api_model"]], "logger (in module qa_llms.vllm)": [[61, "qa_llms.vllm.logger"]], "prepare_gen_kwargs() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel.prepare_gen_kwargs"]], "qa_llms.vllm": [[61, "module-qa_llms.vllm"]], "r_generate() (qa_llms.vllm.vllmqamodel method)": [[61, "qa_llms.vllm.vLLMQAModel.r_generate"]], "rqa_model (in module qa_llms.vllm)": [[61, "qa_llms.vllm.rqa_model"]], "vllmqamodel (class in qa_llms.vllm)": [[61, "qa_llms.vllm.vLLMQAModel"]], "fidretrievertrainer (class in retriever_fid_trainer)": [[62, "retriever_fid_trainer.FidRetrieverTrainer"]], "_load_all_docs() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer._load_eval_data"]], "_save() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer._save"]], "compute_loss() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.compute_loss"]], "embed_text() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.embed_text"]], "evaluation_loop() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.evaluation_loop"]], "kldivloss() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.kldivloss"]], "prediction_step() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.prediction_step"]], "retriever_fid_trainer": [[62, "module-retriever_fid_trainer"]], "wrap_model_for_eval() (retriever_fid_trainer.fidretrievertrainer method)": [[62, "retriever_fid_trainer.FidRetrieverTrainer.wrap_model_for_eval"]], "green (in module retriever_replug_trainer)": [[63, "retriever_replug_trainer.GREEN"]], "ignore_token_id (in module retriever_replug_trainer)": [[63, "retriever_replug_trainer.IGNORE_TOKEN_ID"]], "prompt (in module retriever_replug_trainer)": [[63, "retriever_replug_trainer.PROMPT"]], "red (in module retriever_replug_trainer)": [[63, "retriever_replug_trainer.RED"]], "reset (in module retriever_replug_trainer)": [[63, "retriever_replug_trainer.RESET"]], "replugretrievertrainer (class in retriever_replug_trainer)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer"]], "_load_all_docs() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer._load_eval_data"]], "_save() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer._save"]], "compute_loss() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.compute_loss"]], "evaluation_loop() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.evaluation_loop"]], "get_seq_prob() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.get_seq_prob"]], "instruct() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.instruct"]], "kldivloss() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.kldivloss"]], "prediction_step() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.prediction_step"]], "retriever_replug_trainer": [[63, "module-retriever_replug_trainer"]], "wrap_model_for_eval() (retriever_replug_trainer.replugretrievertrainer method)": [[63, "retriever_replug_trainer.ReplugRetrieverTrainer.wrap_model_for_eval"]], "retrievertrainer (class in retriever_trainer)": [[64, "retriever_trainer.RetrieverTrainer"]], "_inbatch_contrastive_w_hardneg() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer._inbatch_contrastive_w_hardneg"]], "_load_all_docs() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer._load_all_docs"]], "_load_eval_data() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer._load_eval_data"]], "_save() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer._save"]], "compute_loss() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer.compute_loss"]], "evaluation_loop() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer.evaluation_loop"]], "prediction_step() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer.prediction_step"]], "retriever_trainer": [[64, "module-retriever_trainer"]], "wrap_model_for_eval() (retriever_trainer.retrievertrainer method)": [[64, "retriever_trainer.RetrieverTrainer.wrap_model_for_eval"]], "baseretriever (class in retrievers.base)": [[65, "retrievers.base.BaseRetriever"]], "dummyretriever (class in retrievers.base)": [[65, "retrievers.base.DummyRetriever"]], "retrievaloutput (class in retrievers.base)": [[65, "retrievers.base.RetrievalOutput"]], "batch_source_documents (retrievers.base.retrievaloutput attribute)": [[65, "retrievers.base.RetrievalOutput.batch_source_documents"]], "retrieve() (retrievers.base.baseretriever method)": [[65, "retrievers.base.BaseRetriever.retrieve"]], "retrieve() (retrievers.base.dummyretriever method)": [[65, "retrievers.base.DummyRetriever.retrieve"]], "retrievers.base": [[65, "module-retrievers.base"]], "run() (retrievers.base.baseretriever method)": [[65, "retrievers.base.BaseRetriever.run"]], "run_input_keys (retrievers.base.baseretriever attribute)": [[65, "retrievers.base.BaseRetriever.run_input_keys"]], "bm25retriever (class in retrievers.bm25_retriever)": [[66, "retrievers.bm25_retriever.BM25Retriever"]], "bm25tokenizer (class in retrievers.bm25_retriever)": [[66, "retrievers.bm25_retriever.BM25Tokenizer"]], "__call__() (retrievers.bm25_retriever.bm25tokenizer method)": [[66, "retrievers.bm25_retriever.BM25Tokenizer.__call__"]], "normalize_string() (in module retrievers.bm25_retriever)": [[66, "retrievers.bm25_retriever.normalize_string"]], "retrieve() (retrievers.bm25_retriever.bm25retriever method)": [[66, "retrievers.bm25_retriever.BM25Retriever.retrieve"]], "retrievers.bm25_retriever": [[66, "module-retrievers.bm25_retriever"]], "faissretriever (class in retrievers.faiss_retriever)": [[67, "retrievers.faiss_retriever.FaissRetriever"]], "_init_retriever() (retrievers.faiss_retriever.faissretriever method)": [[67, "retrievers.faiss_retriever.FaissRetriever._init_retriever"]], "from_disk() (retrievers.faiss_retriever.faissretriever static method)": [[67, "retrievers.faiss_retriever.FaissRetriever.from_disk"]], "logger (in module retrievers.faiss_retriever)": [[67, "retrievers.faiss_retriever.logger"]], "prepare_docs_for_retrieval() (retrievers.faiss_retriever.faissretriever method)": [[67, "retrievers.faiss_retriever.FaissRetriever.prepare_docs_for_retrieval"]], "retrieve() (retrievers.faiss_retriever.faissretriever method)": [[67, "retrievers.faiss_retriever.FaissRetriever.retrieve"]], "retrieve_w_score() (retrievers.faiss_retriever.faissretriever method)": [[67, "retrievers.faiss_retriever.FaissRetriever.retrieve_w_score"]], "retrievers.faiss_retriever": [[67, "module-retrievers.faiss_retriever"]], "retrievers": [[68, "module-retrievers"]], "dialoguesession (class in schema.dialogue)": [[69, "schema.dialogue.DialogueSession"]], "dialogueturn (class in schema.dialogue)": [[69, "schema.dialogue.DialogueTurn"]], "rqaoutput (class in schema.dialogue)": [[69, "schema.dialogue.RQAOutput"]], "single (schema.dialogue.separatorstyle attribute)": [[69, "schema.dialogue.SeparatorStyle.SINGLE"]], "separatorstyle (class in schema.dialogue)": [[69, "schema.dialogue.SeparatorStyle"]], "two (schema.dialogue.separatorstyle attribute)": [[69, "schema.dialogue.SeparatorStyle.TWO"]], "add_system_message() (schema.dialogue.dialoguesession method)": [[69, "schema.dialogue.DialogueSession.add_system_message"]], "add_user_message() (schema.dialogue.dialoguesession method)": [[69, "schema.dialogue.DialogueSession.add_user_message"]], "assistant_prefix (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.assistant_prefix"]], "batch_answers (schema.dialogue.rqaoutput attribute)": [[69, "schema.dialogue.RQAOutput.batch_answers"]], "batch_dialogue_session (schema.dialogue.rqaoutput attribute)": [[69, "schema.dialogue.RQAOutput.batch_dialogue_session"]], "batch_source_documents (schema.dialogue.rqaoutput attribute)": [[69, "schema.dialogue.RQAOutput.batch_source_documents"]], "clone() (schema.dialogue.dialoguesession method)": [[69, "schema.dialogue.DialogueSession.clone"]], "clone() (schema.dialogue.dialogueturn method)": [[69, "schema.dialogue.DialogueTurn.clone"]], "from_dict() (schema.dialogue.dialogueturn static method)": [[69, "schema.dialogue.DialogueTurn.from_dict"]], "from_list() (schema.dialogue.dialoguesession static method)": [[69, "schema.dialogue.DialogueSession.from_list"]], "history (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.history"]], "message (schema.dialogue.dialogueturn attribute)": [[69, "schema.dialogue.DialogueTurn.message"]], "schema.dialogue": [[69, "module-schema.dialogue"]], "sep_style (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.sep_style"]], "sep_sys (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.sep_sys"]], "sep_user (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.sep_user"]], "source_documents (schema.dialogue.dialogueturn attribute)": [[69, "schema.dialogue.DialogueTurn.source_documents"]], "speaker (schema.dialogue.dialogueturn attribute)": [[69, "schema.dialogue.DialogueTurn.speaker"]], "to_dict() (schema.dialogue.dialogueturn method)": [[69, "schema.dialogue.DialogueTurn.to_dict"]], "to_list() (schema.dialogue.dialoguesession method)": [[69, "schema.dialogue.DialogueSession.to_list"]], "to_string() (schema.dialogue.dialoguesession method)": [[69, "schema.dialogue.DialogueSession.to_string"]], "to_string() (schema.dialogue.dialogueturn method)": [[69, "schema.dialogue.DialogueTurn.to_string"]], "user_prefix (schema.dialogue.dialoguesession attribute)": [[69, "schema.dialogue.DialogueSession.user_prefix"]], "document (class in schema.document)": [[70, "schema.document.Document"]], "__post_init__() (schema.document.document method)": [[70, "schema.document.Document.__post_init__"]], "clone() (schema.document.document method)": [[70, "schema.document.Document.clone"]], "default_document_formatter() (in module schema.document)": [[70, "schema.document.default_document_formatter"]], "fmt_content (schema.document.document attribute)": [[70, "schema.document.Document.fmt_content"]], "from_dict() (schema.document.document static method)": [[70, "schema.document.Document.from_dict"]], "from_langchain_doc() (schema.document.document static method)": [[70, "schema.document.Document.from_langchain_doc"]], "metadata (schema.document.document attribute)": [[70, "schema.document.Document.metadata"]], "page_content (schema.document.document attribute)": [[70, "schema.document.Document.page_content"]], "schema.document": [[70, "module-schema.document"]], "to_dict() (schema.document.document method)": [[70, "schema.document.Document.to_dict"]], "to_langchain_doc() (schema.document.document method)": [[70, "schema.document.Document.to_langchain_doc"]], "schema": [[71, "module-schema"]], "basemodelworker (class in serve.base_model_worker)": [[72, "serve.base_model_worker.BaseModelWorker"]], "acquire_worker_semaphore() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.acquire_worker_semaphore"]], "api_count_token() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_count_token"]], "api_generate() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_generate"]], "api_generate_stream() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_generate_stream"]], "api_get_conv() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_get_conv"]], "api_get_status() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_get_status"]], "api_model_details() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_model_details"]], "api_retrieval() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.api_retrieval"]], "app (in module serve.base_model_worker)": [[72, "serve.base_model_worker.app"]], "count_token() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.count_token"]], "create_background_tasks() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.create_background_tasks"]], "generate_gate() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.generate_gate"]], "generate_stream_gate() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.generate_stream_gate"]], "get_queue_length() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.get_queue_length"]], "get_status() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.get_status"]], "heart_beat_worker() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.heart_beat_worker"]], "init_heart_beat() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.init_heart_beat"]], "logger (in module serve.base_model_worker)": [[72, "serve.base_model_worker.logger"]], "register_to_controller() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.register_to_controller"]], "release_worker_semaphore() (in module serve.base_model_worker)": [[72, "serve.base_model_worker.release_worker_semaphore"]], "retrieve() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.retrieve"]], "send_heart_beat() (serve.base_model_worker.basemodelworker method)": [[72, "serve.base_model_worker.BaseModelWorker.send_heart_beat"]], "serve.base_model_worker": [[72, "module-serve.base_model_worker"]], "worker (in module serve.base_model_worker)": [[72, "serve.base_model_worker.worker"]], "controller (class in serve.controller)": [[73, "serve.controller.Controller"]], "dispatchmethod (class in serve.controller)": [[73, "serve.controller.DispatchMethod"]], "lottery (serve.controller.dispatchmethod attribute)": [[73, "serve.controller.DispatchMethod.LOTTERY"]], "shortest_queue (serve.controller.dispatchmethod attribute)": [[73, "serve.controller.DispatchMethod.SHORTEST_QUEUE"]], "workerinfo (class in serve.controller)": [[73, "serve.controller.WorkerInfo"]], "app (in module serve.controller)": [[73, "serve.controller.app"]], "check_heart_beat (serve.controller.workerinfo attribute)": [[73, "serve.controller.WorkerInfo.check_heart_beat"]], "create_controller() (in module serve.controller)": [[73, "serve.controller.create_controller"]], "from_str() (serve.controller.dispatchmethod class method)": [[73, "serve.controller.DispatchMethod.from_str"]], "get_worker_address() (in module serve.controller)": [[73, "serve.controller.get_worker_address"]], "get_worker_address() (serve.controller.controller method)": [[73, "serve.controller.Controller.get_worker_address"]], "get_worker_status() (serve.controller.controller method)": [[73, "serve.controller.Controller.get_worker_status"]], "handle_no_worker() (serve.controller.controller method)": [[73, "serve.controller.Controller.handle_no_worker"]], "handle_worker_timeout() (serve.controller.controller method)": [[73, "serve.controller.Controller.handle_worker_timeout"]], "heart_beat_controller() (in module serve.controller)": [[73, "serve.controller.heart_beat_controller"]], "last_heart_beat (serve.controller.workerinfo attribute)": [[73, "serve.controller.WorkerInfo.last_heart_beat"]], "list_models() (in module serve.controller)": [[73, "serve.controller.list_models"]], "list_models() (serve.controller.controller method)": [[73, "serve.controller.Controller.list_models"]], "logger (in module serve.controller)": [[73, "serve.controller.logger"]], "model_names (serve.controller.workerinfo attribute)": [[73, "serve.controller.WorkerInfo.model_names"]], "queue_length (serve.controller.workerinfo attribute)": [[73, "serve.controller.WorkerInfo.queue_length"]], "receive_heart_beat() (in module serve.controller)": [[73, "serve.controller.receive_heart_beat"]], "receive_heart_beat() (serve.controller.controller method)": [[73, "serve.controller.Controller.receive_heart_beat"]], "refresh_all_workers() (in module serve.controller)": [[73, "serve.controller.refresh_all_workers"]], "refresh_all_workers() (serve.controller.controller method)": [[73, "serve.controller.Controller.refresh_all_workers"]], "register_worker() (in module serve.controller)": [[73, "serve.controller.register_worker"]], "register_worker() (serve.controller.controller method)": [[73, "serve.controller.Controller.register_worker"]], "remove_stale_workers_by_expiration() (serve.controller.controller method)": [[73, "serve.controller.Controller.remove_stale_workers_by_expiration"]], "remove_worker() (serve.controller.controller method)": [[73, "serve.controller.Controller.remove_worker"]], "serve.controller": [[73, "module-serve.controller"]], "speed (serve.controller.workerinfo attribute)": [[73, "serve.controller.WorkerInfo.speed"]], "worker_api_generate_stream() (in module serve.controller)": [[73, "serve.controller.worker_api_generate_stream"]], "worker_api_generate_stream() (serve.controller.controller method)": [[73, "serve.controller.Controller.worker_api_generate_stream"]], "worker_api_get_status() (in module serve.controller)": [[73, "id0"], [73, "serve.controller.worker_api_get_status"]], "worker_api_get_status() (serve.controller.controller method)": [[73, "serve.controller.Controller.worker_api_get_status"]], "worker_api_retrieval() (in module serve.controller)": [[73, "serve.controller.worker_api_retrieval"]], "worker_api_retrieval() (serve.controller.controller method)": [[73, "serve.controller.Controller.worker_api_retrieval"]], "annotationhistory (class in serve.gradio_dialogue)": [[74, "serve.gradio_dialogue.AnnotationHistory"]], "gradiodialoguesession (class in serve.gradio_dialogue)": [[74, "serve.gradio_dialogue.GradioDialogueSession"]], "_data_idx_filter() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory._data_idx_filter"]], "_session (serve.gradio_dialogue.gradiodialoguesession attribute)": [[74, "serve.gradio_dialogue.GradioDialogueSession._session"]], "_tmp_data (serve.gradio_dialogue.gradiodialoguesession attribute)": [[74, "serve.gradio_dialogue.GradioDialogueSession._tmp_data"]], "add_system_message() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.add_system_message"]], "add_user_message() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.add_user_message"]], "clone() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.clone"]], "conv_templates (in module serve.gradio_dialogue)": [[74, "serve.gradio_dialogue.conv_templates"]], "conv_vicuna_v1 (in module serve.gradio_dialogue)": [[74, "serve.gradio_dialogue.conv_vicuna_v1"]], "default_conversation (in module serve.gradio_dialogue)": [[74, "serve.gradio_dialogue.default_conversation"]], "get_current_idx() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_current_idx"]], "get_current_label() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_current_label"]], "get_next_idx() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_next_idx"]], "get_num_labeled() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_num_labeled"]], "get_num_to_label() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_num_to_label"]], "get_prev_idx() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.get_prev_idx"]], "get_prompt() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.get_prompt"]], "is_all_labeled() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.is_all_labeled"]], "load() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.load"]], "parse_int_range() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.parse_int_range"]], "serve.gradio_dialogue": [[74, "module-serve.gradio_dialogue"]], "skip_next (serve.gradio_dialogue.gradiodialoguesession attribute)": [[74, "serve.gradio_dialogue.GradioDialogueSession.skip_next"]], "to_dict() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.to_dict"]], "to_gradio_chatbot() (serve.gradio_dialogue.gradiodialoguesession method)": [[74, "serve.gradio_dialogue.GradioDialogueSession.to_gradio_chatbot"]], "to_jsonl() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.to_jsonl"]], "update_label() (serve.gradio_dialogue.annotationhistory method)": [[74, "serve.gradio_dialogue.AnnotationHistory.update_label"]], "gradiorqa (class in serve.gradio_rqa)": [[75, "serve.gradio_rqa.GradioRQA"]], "gradiosimplerqa (class in serve.gradio_rqa)": [[75, "serve.gradio_rqa.GradioSimpleRQA"]], "from_scratch() (serve.gradio_rqa.gradiosimplerqa class method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.from_scratch"]], "generate_stream_from_api() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.generate_stream_from_api"]], "generate_stream_from_api() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.generate_stream_from_api"]], "get_model() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.get_model"]], "get_model() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.get_model"]], "get_tokenizer() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.get_tokenizer"]], "get_tokenizer() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.get_tokenizer"]], "logger (in module serve.gradio_rqa)": [[75, "serve.gradio_rqa.logger"]], "prepare_prompt_for_generation() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.prepare_prompt_for_generation"]], "prepare_prompt_for_generation() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.prepare_prompt_for_generation"]], "rephrase_question_for_retrieval() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.rephrase_question_for_retrieval"]], "rephrase_question_for_retrieval() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.rephrase_question_for_retrieval"]], "retrieve() (serve.gradio_rqa.gradiorqa method)": [[75, "serve.gradio_rqa.GradioRQA.retrieve"]], "retrieve() (serve.gradio_rqa.gradiosimplerqa method)": [[75, "serve.gradio_rqa.GradioSimpleRQA.retrieve"]], "serve.gradio_rqa": [[75, "module-serve.gradio_rqa"]], "ann_correct (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_CORRECT"]], "ann_harmful (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_HARMFUL"]], "ann_helpful (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_HELPFUL"]], "ann_incorrect (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_INCORRECT"]], "ann_not_harmful (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_NOT_HARMFUL"]], "ann_not_helpful (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.ANN_NOT_HELPFUL"]], "num_doc_to_retrieve (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.NUM_DOC_TO_RETRIEVE"]], "args (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.args"]], "block_css (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.block_css"]], "block_js (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.block_js"]], "build_demo() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.build_demo"]], "disable_btn (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.disable_btn"]], "document_view() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.document_view"]], "enable_btn (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.enable_btn"]], "get_conv_log_filename() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.get_conv_log_filename"]], "headers (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.headers"]], "learn_more_markdown (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.learn_more_markdown"]], "load_demo() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.load_demo"]], "logger (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.logger"]], "no_change_btn (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.no_change_btn"]], "parser (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.parser"]], "render_next_session() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.render_next_session"]], "render_prev_session() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.render_prev_session"]], "render_single_session() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.render_single_session"]], "save_annotations() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.save_annotations"]], "serve.gradio_static_server": [[76, "module-serve.gradio_static_server"]], "title_markdown (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.title_markdown"]], "tos_markdown (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.tos_markdown"]], "vote_correctness() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.vote_correctness"]], "vote_harmlessness() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.vote_harmlessness"]], "vote_helpfulness() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.vote_helpfulness"]], "vote_response() (in module serve.gradio_static_server)": [[76, "serve.gradio_static_server.vote_response"]], "num_doc_to_retrieve (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.NUM_DOC_TO_RETRIEVE"]], "add_text() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.add_text"]], "args (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.args"]], "block_css (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.block_css"]], "block_js (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.block_js"]], "build_demo() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.build_demo"]], "clear_history() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.clear_history"]], "disable_btn (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.disable_btn"]], "document_view() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.document_view"]], "downvote_last_response() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.downvote_last_response"]], "enable_btn (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.enable_btn"]], "flag_last_response() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.flag_last_response"]], "get_conv_log_filename() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.get_conv_log_filename"]], "get_model_list() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.get_model_list"]], "headers (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.headers"]], "http_generate() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.http_generate"]], "http_retrieve() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.http_retrieve"]], "learn_more_markdown (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.learn_more_markdown"]], "load_demo() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.load_demo"]], "load_demo_refresh_model_list() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.load_demo_refresh_model_list"]], "logger (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.logger"]], "no_change_btn (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.no_change_btn"]], "parser (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.parser"]], "regenerate() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.regenerate"]], "serve.gradio_web_server": [[77, "module-serve.gradio_web_server"]], "title_markdown (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.title_markdown"]], "tos_markdown (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.tos_markdown"]], "upvote_last_response() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.upvote_last_response"]], "violates_moderation() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.violates_moderation"]], "vote_last_response() (in module serve.gradio_web_server)": [[77, "serve.gradio_web_server.vote_last_response"]], "serve": [[78, "module-serve"]], "modelworker (class in serve.model_worker)": [[79, "serve.model_worker.ModelWorker"]], "add_model_args() (in module serve.model_worker)": [[79, "serve.model_worker.add_model_args"]], "create_model_worker() (in module serve.model_worker)": [[79, "serve.model_worker.create_model_worker"]], "generate_gate() (serve.model_worker.modelworker method)": [[79, "serve.model_worker.ModelWorker.generate_gate"]], "generate_stream() (serve.model_worker.modelworker method)": [[79, "serve.model_worker.ModelWorker.generate_stream"]], "generate_stream_gate() (serve.model_worker.modelworker method)": [[79, "serve.model_worker.ModelWorker.generate_stream_gate"]], "load_model() (in module serve.model_worker)": [[79, "serve.model_worker.load_model"]], "logger (in module serve.model_worker)": [[79, "serve.model_worker.logger"]], "retrieve() (serve.model_worker.modelworker method)": [[79, "serve.model_worker.ModelWorker.retrieve"]], "serve.model_worker": [[79, "module-serve.model_worker"]], "worker_id (in module serve.model_worker)": [[79, "serve.model_worker.worker_id"]], "main() (in module serve.test_message)": [[80, "serve.test_message.main"]], "parser (in module serve.test_message)": [[80, "serve.test_message.parser"]], "serve.test_message": [[80, "module-serve.test_message"]], "supervisedfidtrainer (class in supervised_fid_trainer)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer"]], "_load_eval_data() (supervised_fid_trainer.supervisedfidtrainer method)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer._load_eval_data"]], "compute_loss() (supervised_fid_trainer.supervisedfidtrainer method)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer.compute_loss"]], "evaluation_loop() (supervised_fid_trainer.supervisedfidtrainer method)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer.evaluation_loop"]], "prediction_step() (supervised_fid_trainer.supervisedfidtrainer method)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer.prediction_step"]], "supervised_fid_trainer": [[81, "module-supervised_fid_trainer"]], "wrap_model_for_eval() (supervised_fid_trainer.supervisedfidtrainer method)": [[81, "supervised_fid_trainer.SupervisedFiDTrainer.wrap_model_for_eval"]], "supervisedtrainer (class in supervised_trainer)": [[82, "supervised_trainer.SupervisedTrainer"]], "_load_eval_data() (supervised_trainer.supervisedtrainer method)": [[82, "supervised_trainer.SupervisedTrainer._load_eval_data"]], "compute_loss() (supervised_trainer.supervisedtrainer method)": [[82, "supervised_trainer.SupervisedTrainer.compute_loss"]], "evaluation_loop() (supervised_trainer.supervisedtrainer method)": [[82, "supervised_trainer.SupervisedTrainer.evaluation_loop"]], "prediction_step() (supervised_trainer.supervisedtrainer method)": [[82, "supervised_trainer.SupervisedTrainer.prediction_step"]], "supervised_trainer": [[82, "module-supervised_trainer"]], "wrap_model_for_eval() (supervised_trainer.supervisedtrainer method)": [[82, "supervised_trainer.SupervisedTrainer.wrap_model_for_eval"]], "basetextloader (class in text_loaders.base)": [[83, "text_loaders.base.BaseTextLoader"]], "_convert_doc() (text_loaders.base.basetextloader method)": [[83, "text_loaders.base.BaseTextLoader._convert_doc"]], "load_data() (text_loaders.base.basetextloader method)": [[83, "text_loaders.base.BaseTextLoader.load_data"]], "save_texts() (text_loaders.base.basetextloader method)": [[83, "text_loaders.base.BaseTextLoader.save_texts"]], "text_loaders.base": [[83, "module-text_loaders.base"]], "text_loaders": [[84, "module-text_loaders"]], "langchaintextloader (class in text_loaders.langchain_text_loader)": [[85, "text_loaders.langchain_text_loader.LangChainTextLoader"]], "load_data() (text_loaders.langchain_text_loader.langchaintextloader method)": [[85, "text_loaders.langchain_text_loader.LangChainTextLoader.load_data"]], "loader_parameters (in module text_loaders.langchain_text_loader)": [[85, "text_loaders.langchain_text_loader.loader_parameters"]], "save_texts() (text_loaders.langchain_text_loader.langchaintextloader method)": [[85, "text_loaders.langchain_text_loader.LangChainTextLoader.save_texts"]], "text_loaders.langchain_text_loader": [[85, "module-text_loaders.langchain_text_loader"]], "llamaindextextloader (class in text_loaders.llamaindex_text_loader)": [[86, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader"]], "load_data() (text_loaders.llamaindex_text_loader.llamaindextextloader method)": [[86, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader.load_data"]], "loader_func (in module text_loaders.llamaindex_text_loader)": [[86, "text_loaders.llamaindex_text_loader.loader_func"]], "save_texts() (text_loaders.llamaindex_text_loader.llamaindextextloader method)": [[86, "text_loaders.llamaindex_text_loader.LlamaIndexTextLoader.save_texts"]], "text_loaders.llamaindex_text_loader": [[86, "module-text_loaders.llamaindex_text_loader"]], "create_dir_if_not_exists() (in module utils)": [[87, "utils.create_dir_if_not_exists"]], "init_logger() (in module utils)": [[87, "utils.init_logger"]], "logger (in module utils)": [[87, "utils.logger"]], "remove_optimizer_weights() (in module utils)": [[87, "utils.remove_optimizer_weights"]], "utils": [[87, "module-utils"]], "with_retriever_fid_trainer": [[88, "module-with_retriever_fid_trainer"]], "fixedretrievertrainer (class in with_retriever_trainer)": [[89, "with_retriever_trainer.FixedRetrieverTrainer"]], "_load_all_docs() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer._load_all_docs"]], "_load_eval_data() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer._load_eval_data"]], "batch_iterator() (in module with_retriever_trainer)": [[89, "with_retriever_trainer.batch_iterator"]], "compute_loss() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer.compute_loss"]], "evaluation_loop() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer.evaluation_loop"]], "prediction_step() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer.prediction_step"]], "with_retriever_trainer": [[89, "module-with_retriever_trainer"]], "wrap_model_for_eval() (with_retriever_trainer.fixedretrievertrainer method)": [[89, "with_retriever_trainer.FixedRetrieverTrainer.wrap_model_for_eval"]]}})