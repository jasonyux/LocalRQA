Search.setIndex({"docnames": ["api_reference/index", "api_reference/local_rqa", "api_reference/local_rqa.evaluation", "api_reference/local_rqa.guardrails", "api_reference/local_rqa.pipelines", "api_reference/local_rqa.qa_llms", "api_reference/local_rqa.retrievers", "api_reference/local_rqa.schema", "api_reference/local_rqa.serve", "api_reference/local_rqa.text_loaders", "api_reference/local_rqa.trainers", "api_reference/local_rqa.trainers.qa_llm", "api_reference/local_rqa.trainers.retriever", "getting_started/installation", "getting_started/quickstart", "getting_started/scripts", "index", "modules/data", "modules/evaluation", "modules/evaluation/eval_e2e", "modules/evaluation/eval_retriever", "modules/serving", "modules/serving/acc_frameworks", "modules/serving/human_eval", "modules/serving/interactive", "modules/training", "modules/training/training_generator", "modules/training/training_retriever", "usecases/databricks", "usecases/faire"], "filenames": ["api_reference/index.rst", "api_reference/local_rqa.rst", "api_reference/local_rqa.evaluation.rst", "api_reference/local_rqa.guardrails.rst", "api_reference/local_rqa.pipelines.rst", "api_reference/local_rqa.qa_llms.rst", "api_reference/local_rqa.retrievers.rst", "api_reference/local_rqa.schema.rst", "api_reference/local_rqa.serve.rst", "api_reference/local_rqa.text_loaders.rst", "api_reference/local_rqa.trainers.rst", "api_reference/local_rqa.trainers.qa_llm.rst", "api_reference/local_rqa.trainers.retriever.rst", "getting_started/installation.rst", "getting_started/quickstart.rst", "getting_started/scripts.md", "index.rst", "modules/data.rst", "modules/evaluation.rst", "modules/evaluation/eval_e2e.rst", "modules/evaluation/eval_retriever.rst", "modules/serving.rst", "modules/serving/acc_frameworks.rst", "modules/serving/human_eval.rst", "modules/serving/interactive.rst", "modules/training.rst", "modules/training/training_generator.rst", "modules/training/training_retriever.rst", "usecases/databricks.rst", "usecases/faire.rst"], "titles": ["local_rqa", "local_rqa", "local_rqa.evaluation package", "local_rqa.guardrails package", "local_rqa.pipelines package", "local_rqa.qa_llms package", "local_rqa.retrievers package", "local_rqa.schema package", "local_rqa.serve package", "local_rqa.text_loaders package", "local_rqa.trainers namespace", "local_rqa.trainers.qa_llm namespace", "local_rqa.trainers.retriever namespace", "Installation", "Quickstart", "Some feature", "Welcome to LocalRQA\u2019s documentation!", "Data", "Evaluation", "End-to-End Evaluation", "Retriever Evaluation", "Serving", "Inference Acceleration Frameworks", "Static Human Evaluation", "Interactive Chat", "Training", "Generator", "Retriever", "Databricks", "Faire"], "terms": {"subpackag": 0, "evalu": [0, 1, 11, 12, 14, 21, 22, 26, 27, 28, 29], "packag": [0, 1], "submodul": 0, "modul": 0, "metric": [0, 1, 14, 20, 27, 28, 29], "score": [0, 1, 5, 6, 12, 20, 28, 29], "util": [0, 5, 7], "content": [0, 1, 12], "guardrail": [0, 1], "base": [0, 2, 7, 8, 11, 12, 14, 19, 22, 24, 26, 27, 28, 29], "pipelin": [0, 1, 6], "prompt": [0, 1, 24], "retrieval_qa": [0, 1], "qa_llm": [0, 1, 4, 10, 26, 28, 29], "fid": [0, 1, 11], "huggingfac": [0, 1, 4, 20, 21, 22, 24], "openai": [0, 1, 4, 8], "sglang": [0, 1, 4, 21, 22, 24], "tgi": [0, 1, 24], "vllm": [0, 1, 4, 21, 22, 24], "retriev": [0, 1, 2, 4, 5, 8, 10, 11, 16, 21, 22, 23], "bm25_retriev": [0, 1], "faiss_retriev": [0, 1], "schema": [0, 1, 6, 8, 23], "dialogu": [0, 1, 4, 8, 14], "document": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 15, 20, 22, 23, 24, 26, 27, 28, 29], "serv": [0, 1, 14, 16, 23, 24], "base_model_work": [0, 1], "control": [0, 1, 2, 5, 24], "gradio_dialogu": [0, 1], "gradio_rqa": [0, 1], "gradio_static_serv": [0, 1, 23], "gradio_web_serv": [0, 1, 24], "model_work": [0, 1, 22, 24], "test_messag": [0, 1, 24], "text_load": [0, 1, 14], "langchain_text_load": [0, 1, 14], "llamaindex_text_load": [0, 1], "trainer": [0, 1, 26, 27, 28, 29], "namespac": [0, 1, 8], "dist_util": [0, 1], "compon": [0, 1, 3, 4, 5, 6], "run": [0, 1, 3, 4, 5, 6, 14, 23, 24, 28, 29], "run_input_kei": [0, 1, 3, 4, 5, 6], "constant": 0, "accelerationframework": [0, 1], "errorcod": [0, 1], "context_overflow": [0, 1], "controller_no_work": [0, 1], "controller_worker_timeout": [0, 1], "cuda_out_of_memori": [0, 1], "engine_overload": [0, 1], "gradio_request_error": [0, 1], "gradio_stream_unknown_error": [0, 1], "incorrect_auth_kei": [0, 1], "internal_error": [0, 1], "invalid_auth_kei": [0, 1], "invalid_model": [0, 1], "no_permiss": [0, 1], "param_out_of_rang": [0, 1], "quota_exceed": [0, 1], "rate_limit": [0, 1], "validation_type_error": [0, 1], "init_logg": [0, 1, 10], "pretty_print_semaphor": [0, 1], "em": [1, 2], "exact_match_scor": [1, 2], "f1": [1, 2], "f1_score": [1, 2], "precis": [1, 2], "recal": [1, 2, 20, 26, 27, 28, 29], "rouge_scor": [1, 2], "rouge_wrapp": [1, 2], "normalize_answ": [1, 2], "baseanswerguardrail": [1, 3, 4], "noopanswerguardrail": [1, 3], "rqapipelin": [1, 2, 4], "qa": [1, 2, 4, 5, 14, 16], "update_dialogue_sess": [1, 4], "autorqa": [1, 4], "baserqa": [1, 4], "simplerqa": [1, 4, 8, 11, 14], "from_huggingfac": [1, 4], "from_huggingface_fid": [1, 4], "from_openai": [1, 4], "from_scratch": [1, 4, 8, 14], "from_sglang": [1, 4], "from_tgi": [1, 4], "from_vllm": [1, 4], "rephrase_quest": [1, 4], "baseqamodel": [1, 4, 5], "gener": [1, 4, 5, 8, 14, 16, 20, 21, 22, 23, 24, 27], "is_api_model": [1, 5], "r_gener": [1, 5], "generationoutput": [1, 5], "batch_answ": [1, 3, 5, 7, 14], "checkpointwrapp": [1, 5], "forward": [1, 5], "encoderwrapp": [1, 5], "fidt5": [1, 5], "forward_": [1, 5], "from_t5": [1, 5], "get_crossattention_scor": [1, 5], "load_t5": [1, 5], "overwrite_forward_crossattent": [1, 5], "reset_score_storag": [1, 5], "set_checkpoint": [1, 5], "unwrap_encod": [1, 5], "wrap_encod": [1, 5], "apply_checkpoint_wrapp": [1, 5], "cross_attention_forward": [1, 5], "huggingfacefidqamodel": [1, 5], "encode_fid_input": [1, 5, 10, 11], "pack_fid_input": [1, 5], "unpack_fid_input": [1, 5], "huggingfaceqamodel": [1, 5], "openaiqamodel": [1, 5], "sglangclient": [1, 5], "generate_stream": [1, 5, 8], "sglangqamodel": [1, 5], "prepare_gen_kwarg": [1, 5], "tgiqamodel": [1, 5], "vllmclient": [1, 5], "vllmqamodel": [1, 5], "baseretriev": [1, 4, 6, 11], "dummyretriev": [1, 6], "retrievaloutput": [1, 6, 8], "batch_source_docu": [1, 3, 5, 6, 7, 14], "faissretriev": [1, 6, 11, 12], "from_disk": [1, 6], "prepare_docs_for_retriev": [1, 6], "retrieve_w_scor": [1, 6], "dialoguesess": [1, 3, 4, 5, 7, 8, 14], "add_system_messag": [1, 7, 8], "add_user_messag": [1, 7, 8], "assistant_prefix": [1, 2, 4, 5, 7, 8, 11, 26, 28, 29], "clone": [1, 7, 8, 13], "from_list": [1, 7], "histori": [1, 4, 7, 8, 14, 26], "sep_styl": [1, 7], "sep_si": [1, 2, 4, 5, 7, 11, 26, 28, 29], "sep_us": [1, 2, 4, 5, 7, 11, 26, 28, 29], "to_list": [1, 7, 12], "to_str": [1, 7], "user_prefix": [1, 2, 4, 5, 7, 8, 11, 26, 28, 29], "dialogueturn": [1, 7], "from_dict": [1, 7], "messag": [1, 7, 8], "source_docu": [1, 7, 8], "speaker": [1, 7], "to_dict": [1, 7, 8], "rqaoutput": [1, 3, 4, 7, 14], "batch_dialogue_sess": [1, 3, 4, 5, 7, 14], "separatorstyl": [1, 7], "singl": [1, 5, 7], "two": [1, 7, 21, 22], "fmt_content": [1, 6, 7, 23, 27], "from_langchain_doc": [1, 7], "metadata": [1, 6, 7, 8, 27], "page_cont": [1, 7, 27], "to_langchain_doc": [1, 7], "default_document_formatt": [1, 7], "basemodelwork": [1, 8], "count_token": [1, 8], "generate_g": [1, 8], "generate_stream_g": [1, 8], "get_queue_length": [1, 8], "get_statu": [1, 8], "init_heart_beat": [1, 8], "register_to_control": [1, 8], "send_heart_beat": [1, 8], "acquire_worker_semaphor": [1, 8], "api_count_token": [1, 8], "api_gener": [1, 8], "api_generate_stream": [1, 8], "api_get_conv": [1, 8], "api_get_statu": [1, 8], "api_model_detail": [1, 8], "api_retriev": [1, 8], "create_background_task": [1, 8], "heart_beat_work": [1, 8], "release_worker_semaphor": [1, 8], "annotationhistori": [1, 8], "get_current_idx": [1, 8], "get_current_label": [1, 8], "get_next_idx": [1, 8], "get_num_label": [1, 8], "get_num_to_label": [1, 8], "get_prev_idx": [1, 8], "is_all_label": [1, 8], "load": [1, 5, 6, 8, 9, 14, 20, 24], "parse_int_rang": [1, 8], "to_jsonl": [1, 8], "update_label": [1, 8], "gradiodialoguesess": [1, 8], "get_prompt": [1, 8], "skip_next": [1, 8], "to_gradio_chatbot": [1, 8], "gradiorqa": [1, 8], "generate_stream_from_api": [1, 8], "get_model": [1, 8], "get_token": [1, 8], "prepare_prompt_for_gener": [1, 8], "rephrase_question_for_retriev": [1, 8], "gradiosimplerqa": [1, 8], "main": [1, 3, 4, 5, 6, 8], "basetextload": [1, 9], "load_data": [1, 9, 14], "save_text": [1, 9], "langchaintextload": [1, 9, 14], "llamaindextextload": [1, 9], "argument": [1, 3, 4, 5, 6, 10, 22, 24], "dataset": [1, 10, 27], "supervised_fid_train": [1, 10], "supervised_train": [1, 10], "with_retriever_fid_train": [1, 10], "with_retriever_train": [1, 10], "embed": [1, 4, 5, 6, 8, 10, 11, 14, 20, 24], "retriever_fid_train": [1, 10], "retriever_replug_train": [1, 10], "retriever_train": [1, 10], "barrier": [1, 10], "get_rank": [1, 10], "is_main": [1, 10], "create_dir_if_not_exist": [1, 10], "remove_optimizer_weight": [1, 10], "class": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 22, 24], "abc": [1, 2, 6, 8, 9], "build": 1, "block": [1, 5], "which": [1, 5, 7, 14, 20, 23, 24, 27], "call": [1, 2, 5], "method": [1, 3, 4, 5, 6, 8, 16, 20, 21, 27], "iter": 1, "abstract": [1, 2, 3, 5, 6, 8, 9], "arg": [1, 2, 3, 4, 5, 6, 8, 9], "kwarg": [1, 2, 3, 4, 5, 6, 8, 9, 12, 14], "entrypoint": [1, 3, 4, 5, 6, 22, 24], "keyword": [1, 3, 4, 5, 6], "pass": [1, 3, 4, 5, 6], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 14, 21, 22, 23, 24, 26, 27], "valu": [1, 5, 7, 8], "enum": [1, 7, 8], "an": [1, 2, 4, 5, 8, 11, 12, 16, 21, 22, 23, 24, 26, 28, 29], "enumer": [1, 8], "intenum": 1, "http": [1, 5, 22, 24], "platform": 1, "com": 1, "doc": [1, 5, 9, 11, 12, 14], "guid": [1, 5, 29], "error": [1, 5], "code": [1, 5, 14], "api": [1, 5, 8], "40303": 1, "50005": 1, "50006": 1, "50002": 1, "42903": 1, "50003": 1, "50004": 1, "40102": 1, "50001": 1, "40101": 1, "40301": 1, "40103": 1, "40302": 1, "42902": 1, "42901": 1, "40001": 1, "true": [1, 2, 5, 10, 11, 12, 26, 27, 28, 29], "is_distribut": [1, 10], "fals": [1, 2, 4, 5, 8, 10, 11, 12, 27], "filenam": [1, 10, 14, 19, 22], "none": [1, 2, 4, 5, 6, 8, 10, 11, 12], "semaphor": 1, "predict": [2, 5, 11, 12, 23], "ground_truth": 2, "normalize_fn": 2, "type": [2, 3, 4, 5, 6, 7, 9, 11, 12], "callabl": [2, 5, 11, 12], "str": [2, 3, 4, 5, 6, 7, 8, 11, 12, 14], "function": [2, 5], "lambda": 2, "": [2, 4, 5, 7, 11, 12, 14, 15, 21, 23, 24], "perform": [2, 3, 5, 11, 12, 14, 22, 23, 24, 27], "action": 3, "fact": 3, "check": [3, 5, 8, 11, 12], "safeti": 3, "filter": 3, "etc": [3, 7, 14], "batch_quest": [2, 3, 4, 5, 6, 14], "list": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 27], "post": [3, 5], "process": [3, 5, 22, 26, 29], "respons": [3, 5, 14, 21, 22, 23, 24], "befor": [3, 5, 11, 12], "return": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12], "user": [2, 3, 4, 5, 7, 8, 11, 14, 21, 23, 24, 26, 27, 28, 29], "paramet": [2, 3, 4, 5, 6, 7, 8, 9, 11, 12], "_description_": [2, 3, 4, 5, 7, 8, 11], "rais": [3, 5, 6, 8, 9], "notimplementederror": [3, 5, 8, 9], "dummi": 3, "answer": [2, 3, 4, 5, 7, 14, 16, 21, 26, 28, 29], "through": [3, 4, 5], "given": [4, 5, 6, 14, 24, 26, 27], "question": [2, 4, 5, 6, 7, 8, 12, 14, 16, 23, 27, 28, 29], "model": [2, 4, 5, 6, 8, 11, 12, 14, 20, 21, 23, 24, 26, 28, 29], "make": [4, 5, 15, 24], "up": [4, 5, 21, 22], "assum": [4, 7, 11], "you": [4, 5, 8, 13, 14, 22, 23, 24], "can": [4, 5, 13, 14, 20, 21, 22, 23, 24], "directli": [4, 5, 14, 21], "pipe": 4, "all": [4, 5, 8, 11, 12, 23, 24, 26, 28, 29], "dataclass": 4, "contain": [4, 5, 23], "sourc": [4, 5, 7, 14, 16], "retrieval_qa_output": 4, "updat": [1, 2, 4, 7, 14], "session": [4, 7, 8], "from": [4, 5, 6, 14, 16, 20, 21, 24, 28, 29], "current": [4, 21], "turn": [4, 7, 24], "system": [4, 7, 16, 21, 22], "answer_guardrail": 4, "take": [4, 5, 28, 29], "exactli": 4, "three": 4, "them": [4, 5, 14, 21], "sequenc": [4, 5, 11], "verbos": [4, 8], "static": [4, 5, 6, 7, 21], "qa_model": [4, 11], "automodelforcausallm": [4, 5], "qa_token": 4, "autotoken": [4, 5, 11], "qa_model_name_or_path": [4, 8, 14, 19, 22, 24, 28, 29], "qa_model_init_kwarg": 4, "dict": [2, 4, 5, 7, 8, 11, 12, 23], "assist": [2, 4, 5, 7, 8, 11, 26, 28, 29], "bool": [2, 4, 5, 8, 11, 12], "initi": [4, 5, 27], "simpl": [4, 14, 21], "rqa": [4, 6, 8, 16, 21, 22], "alreadi": [4, 5], "option": [4, 5, 6, 11, 12, 23, 24, 26, 27], "default": [4, 5, 6, 11, 12, 20, 22, 23, 24], "_type_": [2, 4, 5, 6, 7, 8, 11], "fusion": [4, 5], "decod": [4, 5], "qa_model_nam": 4, "e": [2, 4, 5, 7, 21, 23, 29], "g": [2, 4, 5, 7, 21, 23, 29], "gpt": [4, 26, 28, 29], "3": [4, 5, 11, 12, 14, 15, 24, 26, 27, 28, 29], "5": [4, 8, 14, 19, 22, 24, 26, 27, 28, 29], "turbo": [4, 28, 29], "classmethod": [4, 8], "database_path": [4, 6, 8], "document_path": [4, 6, 8, 14, 19, 20, 22, 24, 28, 29], "index_path": [4, 6, 8, 12, 14, 19, 20, 22, 24, 28, 29], "index": [4, 6, 8, 12, 14, 16, 19, 20, 22, 24, 26], "embedding_model_name_or_path": [4, 8, 14, 19, 20, 22, 24, 28, 29], "text": [4, 5, 6, 7, 8, 9, 12, 14, 16, 21, 22, 27, 29], "ada": [4, 8], "002": [4, 8], "lmsy": [4, 8, 14, 19, 22, 24], "vicuna": [4, 8, 14, 19, 22, 24], "7b": [4, 8, 14, 19, 22, 24, 26, 28, 29], "v1": [4, 8, 14, 19, 22, 24, 29], "qa_is_fid": [4, 8], "qa_model_url": 4, "host": [4, 5, 22, 24], "infer": [4, 5, 21, 24], "intial": 4, "llama": 4, "2": [4, 5, 7, 8, 14, 15, 20, 21, 24, 26, 27, 28, 29], "rephras": [4, 5, 6], "everi": [4, 5], "standalon": 4, "us": [2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 20, 21, 22, 23, 24, 26, 27, 28, 29], "llm": 5, "set": [5, 21, 23, 24], "batched_prompt": 5, "tokenization_kwarg": 5, "generation_kwarg": 5, "potenti": 5, "other": [2, 5, 16, 23], "purpos": 5, "augement": 5, "token": [5, 11, 12, 28, 29], "object": [2, 5, 7, 8, 11, 12, 14], "use_checkpoint": 5, "wrapper": [5, 8], "replac": [5, 24], "output": [5, 11, 12, 20], "empti": [5, 14, 15, 24], "tensor": [5, 11, 12], "allow": [5, 23, 24], "checkpoint": [5, 26, 28, 29], "hidden_st": 5, "attention_mask": 5, "position_bia": 5, "defin": [5, 20, 27], "comput": [1, 2, 5, 11, 12, 21], "should": [5, 11, 12, 22, 24], "overridden": 5, "subclass": [5, 11, 12], "although": 5, "recip": 5, "need": [5, 22, 23, 24], "within": 5, "one": [5, 24], "instanc": [5, 22], "afterward": 5, "instead": 5, "sinc": [5, 22], "former": 5, "care": 5, "regist": [5, 24], "hook": 5, "while": [5, 24], "latter": 5, "silent": 5, "ignor": [5, 11, 12], "encod": [5, 26], "t5": [5, 12, 26, 27], "obtain": [5, 23, 24, 28, 29], "input_id": 5, "config": [2, 5, 20], "t5forconditionalgener": 5, "The": [5, 6, 11, 12, 20, 22, 23, 26, 27], "overrid": [5, 11, 12], "__call__": 5, "special": 5, "tip": 5, "pre": [5, 21, 23], "step": [5, 11, 12, 22, 24, 28, 29], "torch": [5, 11, 12], "longtensor": 5, "shape": 5, "batch_siz": [1, 2, 5, 11, 12], "sequence_length": 5, "indic": [5, 27], "input": [2, 5, 11, 12, 23, 24, 26], "vocabulari": 5, "i": [5, 6, 8, 11, 12, 14, 16, 22, 23, 24, 27], "rel": 5, "posit": 5, "so": [5, 6, 8], "abl": 5, "pad": 5, "both": [5, 6, 11, 12], "right": 5, "left": 5, "see": [5, 14, 21, 23, 24], "pretrainedtoken": 5, "detail": [5, 21, 23, 24], "what": [2, 5, 12, 14, 23, 24], "ar": [5, 8, 12, 20, 22, 23, 24, 27], "id": [5, 24, 27], "glossari": 5, "To": [5, 22, 24], "know": 5, "more": [5, 21, 23, 24], "how": [5, 11, 12, 14, 21, 23, 24], "prepar": [5, 6, 23, 24, 28, 29], "pretrain": 5, "look": 5, "train": [5, 11, 12, 14, 16, 26, 27], "floattensor": 5, "mask": [5, 12], "avoid": 5, "attent": 5, "select": [5, 16, 27], "0": [2, 5, 11, 12, 14, 22, 24, 27, 28, 29], "1": [5, 7, 8, 11, 12, 14, 15, 20, 21, 23, 24, 26, 27, 28, 29], "decoder_input_id": 5, "target_sequence_length": 5, "pad_token_id": 5, "start": [1, 2, 5, 24], "If": [5, 22], "past_key_valu": 5, "onli": [5, 11, 12, 23, 29], "last": [5, 11, 12], "have": [5, 20], "decoder_attention_mask": 5, "booltensor": 5, "behavior": [5, 11, 12], "causal": 5, "also": [5, 21, 22, 24], "head_mask": 5, "num_head": 5, "num_lay": 5, "nullifi": 5, "head": 5, "self": 5, "decoder_head_mask": 5, "cross_attn_head_mask": 5, "cross": 5, "encoder_output": 5, "tupl": [2, 5, 11, 12], "consist": 5, "last_hidden_st": 5, "hidden_s": 5, "hidden": 5, "state": [5, 8], "layer": 5, "length": [5, 11, 12, 28, 29], "n_layer": 5, "each": [2, 5, 11, 12, 21, 22, 27, 28, 29], "4": [2, 5, 12, 20, 26, 27, 28, 29], "embed_size_per_head": 5, "precomput": 5, "kei": [5, 8, 11, 12], "speed": [1, 5, 8, 21, 22, 24], "those": 5, "don": 5, "t": 5, "past": 5, "inputs_emb": 5, "choos": 5, "represent": [5, 7], "want": 5, "over": 5, "convert": [5, 7], "associ": 5, "vector": 5, "than": [5, 24], "intern": 5, "lookup": 5, "matrix": 5, "decoder_inputs_emb": 5, "unset": 5, "use_cach": 5, "output_attent": 5, "whether": [5, 8, 11, 12], "under": [5, 11, 12, 23, 24, 28, 29], "output_hidden_st": 5, "return_dict": 5, "modeloutput": 5, "plain": 5, "label": [5, 8, 11, 12], "classif": 5, "regress": 5, "loss": [5, 11, 12], "100": [5, 11, 12, 26, 29], "vocab_s": 5, "transform": [5, 11, 12], "modeling_output": 5, "seq2seqlmoutput": 5, "A": [5, 8, 11, 12, 23], "when": [5, 11, 12, 22, 24], "compris": 5, "variou": [5, 14], "element": [5, 11, 12], "depend": 5, "configur": [5, 14], "t5config": 5, "provid": [5, 16, 21, 22, 23, 24, 28], "languag": [5, 24], "logit": [5, 11, 12], "softmax": 5, "addit": 5, "encoder_sequence_length": 5, "sequenti": 5, "decoder_hidden_st": 5, "ha": 5, "plu": 5, "decoder_attent": 5, "weight": 5, "after": [5, 20, 28, 29], "averag": [2, 5], "cross_attent": 5, "encoder_last_hidden_st": 5, "encoder_hidden_st": 5, "encoder_attent": 5, "exampl": [5, 12, 14, 19, 22, 23, 24, 27, 28, 29], "python": [5, 19, 20, 22, 23, 24, 26, 27, 28, 29], "import": [5, 14], "from_pretrain": 5, "summar": 5, "studi": 5, "shown": [5, 24], "own": [5, 14], "dog": 5, "good": 5, "return_tensor": 5, "pt": 5, "batch": [5, 6, 12], "size": 5, "print": [5, 14], "model_name_or_path": [5, 10, 12, 26, 27, 28, 29], "max_new_token": [5, 8], "warn": [5, 11, 12], "most": [5, 11, 12, 24, 27], "generation_config": 5, "ani": [2, 5, 7, 9, 11, 12, 20, 22], "correspond": [5, 9], "num_beam": 5, "do_sampl": 5, "For": [5, 14, 21, 22, 23, 24], "overview": 5, "strategi": 5, "out": 5, "follow": [5, 20, 27], "generation_strategi": 5, "vari": 5, "modal": 5, "bos_token_id": 5, "format": [5, 7, 14, 27], "repres": [5, 7], "input_valu": 5, "input_featur": 5, "pixel_valu": 5, "generationconfig": 5, "parametr": 5, "match": 5, "attribut": 5, "had": 5, "prioriti": 5, "json": [5, 14, 26, 27, 28, 29], "file": [5, 6, 9, 13, 20, 23], "exist": [5, 16, 24], "pleas": [5, 24], "note": [5, 7, 23, 24], "unspecifi": 5, "inherit": 5, "whose": 5, "parameter": 5, "logits_processor": 5, "logitsprocessorlist": 5, "custom": [5, 11, 12], "processor": 5, "complement": 5, "built": 5, "creat": [5, 13, 14], "thrown": 5, "featur": [5, 16], "intend": 5, "advanc": 5, "stopping_criteria": 5, "stoppingcriterialist": 5, "stop": [1, 2, 5], "criteria": 5, "your": [5, 11, 12, 14, 21, 22, 23, 24], "sure": [5, 24], "return_dict_in_gener": 5, "output_scor": 5, "prefix_allowed_tokens_fn": 5, "int": [2, 5, 8, 11, 12], "constraint": 5, "beam": 5, "search": [5, 12, 14, 16], "appli": [5, 28, 29], "batch_id": 5, "It": [5, 8, 28, 29], "next": 5, "condit": [5, 26], "previous": 5, "inputs_id": 5, "constrain": 5, "prefix": [2, 5], "describ": 5, "autoregress": 5, "entiti": 5, "arxiv": 5, "org": 5, "ab": 5, "2010": 5, "00904": 5, "synced_gpu": 5, "continu": 5, "loop": [5, 11, 12], "until": 5, "max_length": [5, 11, 12], "unless": 5, "flag": 5, "deepspe": [5, 11, 12, 26, 28, 29], "zero": 5, "stage": 5, "multipl": [5, 22], "gpu": [5, 24], "environ": [5, 13], "hang": 5, "finish": 5, "otherwis": [5, 8, 20, 24], "ll": [5, 14], "assistant_model": 5, "pretrainedmodel": [5, 11, 12], "acceler": [5, 8, 24], "must": [5, 6, 9], "exact": 5, "same": [5, 24], "achiev": 5, "forecast": 5, "candid": 5, "much": 5, "faster": 5, "re": 5, "As": [5, 14], "smaller": 5, "streamer": 5, "basestream": 5, "stream": [5, 27], "put": 5, "token_id": 5, "further": [5, 21, 24, 28, 29], "negative_prompt_id": 5, "neg": [5, 27], "some": [5, 11, 12, 16], "cfg": 5, "experiment": 5, "subject": 5, "break": 5, "chang": [5, 22, 24], "futur": 5, "version": [5, 23], "negative_prompt_attention_mask": 5, "ad": [5, 7], "hoc": 5, "generate_config": 5, "specif": 5, "decoder_": 5, "is_encoder_decod": 5, "possibl": 5, "greedysearchdecoderonlyoutput": 5, "sampledecoderonlyoutput": 5, "beamsearchdecoderonlyoutput": 5, "beamsampledecoderonlyoutput": 5, "greedysearchencoderdecoderoutput": 5, "sampleencoderdecoderoutput": 5, "beamsearchencoderdecoderoutput": 5, "beamsampleencoderdecoderoutput": 5, "context_mask": 5, "aggreg": 5, "scalar": 5, "per": 5, "passag": [5, 26, 27, 28, 29], "seen": 5, "similar": [5, 6, 22], "between": [2, 5], "first": [5, 7, 11, 12, 23, 24, 28], "distil": 5, "knowledg": 5, "reader": [5, 27], "2012": 5, "04584": 5, "state_dict": 5, "save": [5, 9, 14, 19, 20, 22, 23, 24, 26, 27, 28, 29], "reset": [1, 2, 5], "storag": 5, "enabl": [5, 16], "disabl": 5, "pytorch": 5, "stabl": 5, "html": [5, 14], "unwrap": 5, "wrap": 5, "t5stack": 5, "key_value_st": 5, "layer_head_mask": 5, "query_length": 5, "work": [5, 11, 12, 24, 28], "model_init_kwarg": 5, "now": [5, 14], "we": [5, 11, 12, 14, 21, 22, 28, 29], "support": [5, 21, 22, 28], "architectur": 5, "batch_q_w_passag": 5, "batched_fid_prompt": 5, "simpli": [5, 23, 24], "model_nam": [1, 5, 8], "url": [5, 7, 14, 22, 24], "timeout": 5, "60": 5, "input_text": [5, 8], "generate_kwarg": 5, "input_kwarg": 5, "hood": 5, "its": [5, 7], "relev": [6, 7, 14, 27], "corpu": 6, "queri": [6, 12, 26, 27], "handl": [6, 24], "mock": 6, "test": [6, 16, 19, 20, 21, 22, 23, 24, 28, 29], "disk": 6, "folder": [6, 24, 28, 29], "path": [6, 10, 14, 19, 20, 22, 23, 24, 26, 27], "valueerror": [6, 9], "cannot": 6, "faiss": [6, 21, 22], "langchain": [6, 7, 9, 14], "would": [6, 20], "recogn": [6, 24], "emb": [6, 12], "our": [6, 7, 12, 22, 23, 28, 29], "langchaindocu": 6, "_summary_": 6, "search_typ": 6, "factori": [7, 8, 11, 12], "speak": 7, "system_messag": 7, "add": 7, "user_messag": 7, "dialogue_list": 7, "dictionari": [7, 11, 12], "string": 7, "store": [7, 14], "mai": [7, 22], "later": 7, "dialogue_turn_dict": 7, "differ": [2, 7, 21], "separ": [7, 14], "style": 7, "chunk": [7, 9, 14], "along": 7, "titl": [7, 12, 27], "author": 7, "document_dict": 7, "field": 7, "controller_addr": 8, "worker_addr": 8, "worker_id": 8, "model_path": [8, 28], "limit_worker_concurr": 8, "conv_templ": 8, "param": 8, "async": 8, "request": [8, 24], "obj": 8, "data_file_path": 8, "empty_sess": 8, "annotation_kei": 8, "data_indic": 8, "_session": 8, "_tmp_data": 8, "keep": [8, 29], "convers": 8, "gradio": 8, "either": 8, "NOT": 8, "framework": [8, 14, 24], "local": [8, 16], "just": 8, "implement": [8, 14, 26, 27], "retrieved_doc": [2, 8, 23], "pickl": 9, "save_fold": [9, 14], "data": [9, 12, 14, 16, 23], "save_filenam": [9, 14], "parsed_doc": 9, "loader_func": [9, 14], "document_load": [9, 14], "directori": [9, 23, 24], "directoryload": 9, "splitter_func": [9, 14], "text_splitt": [9, 14], "charactertextsplitt": [9, 14], "specifi": [9, 14], "loader_param": [9, 14], "splitter_param": [9, 14], "loader_funct": 9, "splitter_funct": 9, "split": 9, "simpledirectoryread": 9, "e2eqatrainingargu": [10, 11], "do_ev": [10, 11, 12, 28, 29], "do_train": [10, 11, 12, 28, 29], "eval_step": [10, 11, 12, 26, 28, 29], "evaluation_strategi": [10, 11, 12], "learning_r": [10, 11, 12, 26, 27, 28, 29], "load_best_model_at_end": [10, 11, 12], "logging_step": [10, 11, 12, 26, 28, 29], "lr_scheduler_typ": [10, 11, 12], "metric_for_best_model": [10, 11, 12, 27, 28, 29], "num_train_epoch": [10, 11, 12, 26, 28, 29], "per_device_eval_batch_s": [10, 11, 12, 26, 27, 28, 29], "remove_unused_column": [10, 11, 12], "report_to": [10, 11, 12], "save_step": [10, 11, 12, 26, 28, 29], "save_strategi": [10, 11, 12], "save_total_limit": [10, 11, 12], "seed": [8, 10, 11, 12], "warmup_ratio": [10, 11, 12], "weight_decai": [10, 11, 12], "retrievalqatrainingargu": [10, 11, 12], "documents_path": [10, 11], "eval_data_path": [10, 11, 19, 20, 22, 28, 29], "write_predict": [10, 11, 12], "noopdatacol": [10, 11, 12], "supervisedfidrqawretrieverdataset": [10, 11], "encode_data": [10, 11], "pre_retrieve_all_doc": [10, 11], "prepare_data": [10, 11, 12], "supervisedrqadataset": [10, 11], "supervisedrqawretrieverdataset": [10, 11], "batch_iter": [10, 11, 12], "retriever_init": [10, 11], "contrasitivetrainingarg": [10, 12], "contrastive_loss": [10, 12, 27, 28, 29], "hard_neg_ratio": [10, 12, 27, 28, 29], "temperatur": [8, 10, 12, 28, 29], "dataargu": [10, 12], "eval_fil": [10, 12, 26, 27, 28, 29], "full_dataset_file_path": [10, 12, 26, 27, 28, 29], "test_fil": [10, 12, 26, 28, 29], "train_fil": [10, 12, 26, 27, 28, 29], "fidtrainingarg": [10, 12], "apply_passage_mask": [10, 12], "apply_question_mask": [10, 12], "extract_cl": [10, 12], "indexing_dimens": [10, 12], "n_context": [10, 12, 27], "project": [10, 12, 23, 24, 27], "reader_batch_s": [10, 12, 27], "reader_model_path": [10, 12, 27], "reader_temperatur": [10, 12, 27], "text_maxlength": [10, 12, 27], "with_scor": [10, 12, 27], "loggerargu": [10, 12], "run_ent": [10, 12], "run_group": [10, 12, 26, 28, 29], "run_project": [10, 12], "modelargu": [10, 12], "replugtrainingarg": [10, 12], "lm_model_path": [10, 12, 27], "lm_temperatur": [10, 12, 27], "num_doc": [10, 12, 27], "refresh_step": [10, 12, 27], "retrieve_temperatur": [10, 12, 27], "gradient_checkpoint": [10, 11, 12], "max_step": [10, 11, 12, 28, 29], "output_dir": [10, 11, 12, 19, 20, 22, 26, 27, 28, 29], "per_device_train_batch_s": [10, 11, 12, 26, 27, 28, 29], "pooling_typ": [10, 12, 27, 28, 29], "contrastiveretrievaldataset": [10, 12], "fidcol": [10, 12], "fiddataset": [10, 12], "get_exampl": [10, 12], "get_target": [10, 12], "sort_data": [10, 12], "replugdataset": [10, 12], "retrievercol": [10, 12], "encode_passag": [10, 12], "load_fid_data": [10, 12], "localembed": [10, 12], "embed_docu": [10, 12], "embed_queri": [10, 12], "compute_embed": [10, 12], "embed_document_batch": [10, 12], "mean_pool": [10, 12], "save_dir": [10, 28, 29], "overwrite_output_dir": [11, 12], "do_predict": [11, 12], "prediction_loss_onli": [11, 12], "8": [11, 12], "per_gpu_train_batch_s": [11, 12], "per_gpu_eval_batch_s": [11, 12], "gradient_accumulation_step": [11, 12, 26, 28, 29], "eval_accumulation_step": [11, 12], "eval_delai": [11, 12], "float": [11, 12, 27], "1e": [11, 12, 26, 27, 28, 29], "05": [11, 12, 27, 28, 29], "01": [11, 12], "adam_beta1": [11, 12], "9": [11, 12], "adam_beta2": [11, 12], "999": [11, 12], "adam_epsilon": [11, 12], "08": [11, 12], "max_grad_norm": [11, 12], "7": [2, 11, 26], "cosin": [11, 12], "lr_scheduler_kwarg": [10, 11, 12], "warmup_step": [11, 12], "log_level": [11, 12], "passiv": [11, 12], "log_level_replica": [11, 12], "log_on_each_nod": [11, 12], "logging_dir": [11, 12], "logging_strategi": [11, 12], "trainer_util": [11, 12], "intervalstrategi": [11, 12], "logging_first_step": [11, 12], "10": [11, 12, 26, 27, 28, 29], "logging_nan_inf_filt": [11, 12], "save_safetensor": [11, 12], "save_on_each_nod": [11, 12], "save_only_model": [11, 12], "no_cuda": [11, 12], "use_cpu": [11, 12], "use_mps_devic": [11, 12], "42": [11, 12], "data_se": [11, 12], "jit_mode_ev": [11, 12], "use_ipex": [11, 12], "bf16": [11, 12, 26, 28, 29], "fp16": [11, 12], "fp16_opt_level": [11, 12], "o1": [11, 12], "half_precision_backend": [11, 12], "auto": [8, 11, 12], "bf16_full_ev": [11, 12], "fp16_full_ev": [11, 12], "tf32": [11, 12], "local_rank": [11, 12], "ddp_backend": [11, 12], "tpu_num_cor": [11, 12], "tpu_metrics_debug": [11, 12], "debug": [8, 11, 12], "debug_util": [11, 12], "debugopt": [11, 12], "dataloader_drop_last": [11, 12], "dataloader_num_work": [11, 12], "past_index": [11, 12], "run_nam": [11, 12], "disable_tqdm": [11, 12], "label_nam": [11, 12], "eval_loss": [11, 12], "greater_is_bett": [11, 12], "ignore_data_skip": [11, 12], "fsdp": [11, 12], "fsdpoption": [11, 12], "fsdp_min_num_param": [11, 12], "fsdp_config": [11, 12], "fsdp_transformer_layer_cls_to_wrap": [11, 12], "label_smoothing_factor": [11, 12], "optim": [11, 12], "training_arg": [11, 12], "optimizernam": [11, 12], "adamw_torch": [11, 12], "optim_arg": [11, 12], "adafactor": [11, 12], "group_by_length": [11, 12], "length_column_nam": [11, 12], "wandb": [11, 12], "ddp_find_unused_paramet": [11, 12], "ddp_bucket_cap_mb": [11, 12], "ddp_broadcast_buff": [11, 12], "dataloader_pin_memori": [11, 12], "dataloader_persistent_work": [11, 12], "skip_memory_metr": [11, 12], "use_legacy_prediction_loop": [11, 12], "push_to_hub": [11, 12], "resume_from_checkpoint": [11, 12], "hub_model_id": [11, 12], "hub_strategi": [11, 12], "hubstrategi": [11, 12], "every_sav": [11, 12], "hub_token": [11, 12], "hub_private_repo": [11, 12], "hub_always_push": [11, 12], "gradient_checkpointing_kwarg": [11, 12], "include_inputs_for_metr": [11, 12], "fp16_backend": [11, 12], "push_to_hub_model_id": [11, 12], "push_to_hub_organ": [11, 12], "push_to_hub_token": [11, 12], "mp_paramet": [11, 12], "auto_find_batch_s": [11, 12], "full_determin": [11, 12], "torchdynamo": [11, 12], "ray_scop": [11, 12], "ddp_timeout": [11, 12], "1800": [11, 12], "torch_compil": [11, 12], "torch_compile_backend": [11, 12], "torch_compile_mod": [11, 12], "dispatch_batch": [11, 12], "split_batch": [11, 12], "include_tokens_per_second": [11, 12], "include_num_input_tokens_seen": [11, 12], "neftune_noise_alpha": [11, 12], "trainingargu": [11, 12], "union": [11, 12], "5e": [11, 26], "schedulertyp": 11, "linear": 11, "500": 11, "nonetyp": 11, "qa_w_doc_data": 11, "embedding_model": [11, 20, 26, 28, 29], "huggingfaceembed": 11, "openaiembed": 11, "retriever_init_fn": 11, "max_num_to_retriev": 11, "encoder_max_length": 11, "512": [11, 12, 27], "decoder_max_length": 11, "256": [11, 12, 27, 28, 29], "start_data_idx": [11, 12], "end_data_idx": [11, 12, 28, 29], "shuffl": [11, 12], "fix": [11, 28, 29], "encoder_text_data": 11, "decoder_text_data": 11, "q_w_passag": 11, "all_quest": 11, "650": 11, "text_data": 11, "2048": 11, "dset": [11, 12], "drop_last": [11, 12], "embeddings_model": 11, "train_index_path": 11, "inbatch_contrast": [12, 27, 28, 29], "databricks_new": [12, 28], "train_w_qa": [12, 26, 27, 28, 29], "jsonl": [12, 19, 20, 22, 23, 26, 27, 28, 29], "eval_w_qa": [12, 26, 27, 28, 29], "test_w_qa": [12, 19, 22, 26, 28, 29], "databas": [12, 14, 24, 28, 29], "databrick": 12, "databricks_400": [12, 28], "pkl": [12, 19, 20, 22, 26, 27, 28, 29], "pertain": 12, "go": [12, 24], "eval": [2, 11, 12, 26], "googl": [12, 14, 26, 27], "flan": [12, 26, 27], "xl": [12, 26, 27], "50": [12, 14, 23, 26, 27, 28, 29], "768": 12, "localrqa": [12, 14, 21, 26, 27], "log": [12, 23, 24], "facebook": [12, 27], "contriev": [12, 27], "msmarco": [12, 27], "stabilityai": [12, 27], "stablelm": [12, 27], "zephyr": [12, 27], "3b": [12, 27], "20": [12, 24, 27], "result": [12, 19, 22, 23, 28, 29], "model_checkpoint": [12, 28, 29], "contriever_contrastive_ft": 12, "200": 12, "mean": [1, 2, 12, 20, 23, 27, 28, 29], "raw_data": 12, "document_fmt_str": 12, "answer_maxlength": 12, "score_kei": 12, "question_prefix": 12, "title_prefix": 12, "passage_prefix": 12, "context": [12, 22, 23], "passage_maxlength": 12, "question_maxlength": 12, "batch_text_passag": 12, "data_path": 12, "devic": [8, 12], "cuda": [8, 12], "encoded_input": 12, "token_embed": 12, "repo": 13, "setup": 13, "docker": 13, "virtual": 13, "requir": [13, 15], "txt": 13, "pip": 13, "r": 13, "In": [14, 23, 24], "show": 14, "get": [], "could": [14, 28, 29], "demo": 14, "py": [14, 19, 20, 22, 23, 24, 26, 27, 28, 29], "script": [14, 19, 20, 22, 23, 26, 27, 28, 29], "integr": [14, 21], "llamaindex": 14, "easili": [14, 22], "ingest": 14, "drive": 14, "websit": 14, "langchain_commun": 14, "seleniumurlload": 14, "local_rqa": [14, 22, 23, 24], "split_func": 14, "loader_paramet": 14, "website_url": 14, "splitter_paramet": 14, "chunk_siz": 14, "400": [14, 28, 29], "chunk_overlap": 14, "n": 14, "dir": [14, 19, 20, 22, 26, 27], "By": [11, 12, 22, 28, 29], "previou": [28, 29], "readi": [], "intfloat": [14, 19, 22, 24, 27, 28], "e5": [14, 19, 22, 24, 27, 28], "v2": [14, 19, 22, 24, 27, 28], "dbf": [14, 24], "final_answ": [], "where": [14, 27], "construct": [], "excit": 15, "here": [15, 16], "let": 15, "surround": 15, "line": 15, "item": 15, "nest": [15, 26, 28, 29], "open": [16, 24], "toolkit": 16, "research": [14, 16], "quickli": [14, 16], "augment": [16, 23], "full": [14, 16], "suit": 16, "tool": 16, "compar": 16, "wide": 16, "algorithm": [14, 16], "curat": 16, "latest": [14, 16], "page": [16, 23, 24], "offer": [], "wai": 21, "public": 21, "collect": [14, 21, 24, 27], "human": [21, 24], "feedback": [21, 24], "improv": 21, "effici": [], "experi": [], "dure": [2, 11, 22], "interact": [14, 21, 22], "chat": [21, 22, 26], "interfac": [], "design": [], "gather": [11, 12], "server": [23, 24], "command": [26, 27], "below": [], "open_rqa": 23, "launch": [21, 23, 24], "model_id": [22, 24], "simple_rqa": [22, 24], "do": [23, 24], "quick": 24, "abov": [14, 21, 22, 24], "try": [], "invalid_array_index": 24, "procedur": 22, "veri": [2, 22], "m": [22, 24], "api_serv": [22, 24], "localhost": [22, 24], "8000": [22, 24], "Then": [23, 24, 28, 29], "section": [], "includ": [11, 20, 22, 26, 27], "done": [], "paper": [], "file_path": 23, "test_e2": [19, 22, 28, 29], "include_idx": 23, "fine": 26, "grain": [], "12": [], "14": [], "25": [], "63": [], "ask": [], "idx": 8, "6": 26, "26": [], "annot": [23, 24], "yy": 23, "mm": 23, "dd": 23, "hh": 23, "k": [20, 26, 27, 28, 29], "produc": [23, 26], "tune": 26, "concaten": 26, "parallel": 26, "q": [26, 27], "p": [26, 27], "pair": [26, 27], "automat": [14, 23, 26, 28, 29], "measur": 26, "bleu": [1, 2, 26], "roug": [1, 2, 26, 28, 29], "runtim": [20, 26, 27], "sampl": [26, 27], "berkelei": [26, 28, 29], "starl": [26, 28, 29], "lm": [26, 28, 29], "alpha": [26, 28, 29], "retirev": 26, "train_w_fixed_retriev": [26, 28, 29], "use_flash_attent": [26, 28, 29], "ds_config": [26, 28, 29], "gpt4": [26, 28, 29], "correct": [21, 26, 28, 29], "end_of_turn": [26, 28, 29], "embedding_max_num_to_retriev": [26, 28, 29], "wandb_run_group": 26, "full_dataset_index_path": [26, 28, 29], "manner": 26, "train_w_gt_fid": 26, "down": 27, "hard": 27, "ndcg": [20, 27], "evaluatorconfig": [1, 2, 11, 12, 20, 27], "train_fid_retriev": 27, "train_w_q_fid": 27, "eval_w_q_fid": 27, "eval_retr": [27, 28, 29], "document_recal": [2, 27, 28, 29], "ctx": 27, "gold_doc": [2, 23, 27], "calcul": 27, "train_replug_retriev": 27, "train_ctl_retriev": [27, 28, 29], "train_w_q": [27, 28, 29], "eval_w_q": [27, 28], "128": [27, 28, 29], "technic": 28, "team": 28, "11": 28, "136": 28, "maximum": [28, 29], "doc_to_q_databrick": 28, "mode": [28, 29], "prompt_model": [28, 29], "num_hard_negs_per_doc": [28, 29], "num_train_data": [28, 29], "1200": 28, "small": 28, "number": 28, "num_eval_test_data": [28, 29], "150": [28, 29], "doc_q_to_a_databrick": 28, "1106": [28, 29], "preview": [28, 29], "dataset_w_q": [28, 29], "save_nam": [28, 29], "train_w_a": [28, 29], "eval_w_a": [28, 29], "test_w_a": [28, 29], "ctl": [28, 29], "finetun": [20, 28, 29], "e5_databricks_1e4_inbatch256_temp1_hard0": 28, "highest": [28, 29], "e5_databricks_1e4_inbatch256_chunk400_fulldoc_temp1_hard0": 28, "torchrun": [28, 29], "nproc_per_nod": [28, 29], "master_port": [28, 29], "20001": [28, 29], "retriever_model": [11, 28, 29], "05_retriever_train": 28, "120": 28, "databricks_starling7b": 28, "5e6": 28, "train7_e5": 28, "ft": [28, 29], "databricks_vicuna": 28, "databricks_400_e51e4_inbatch256_chunk400hard0": 28, "05_checkpoint120": 28, "final": [20, 24, 28, 29], "l": [2, 28, 29], "acc": [28, 29], "1e5": [28, 29], "train2_e5": 28, "databricks_e2e_test": 28, "crawl": 29, "faq": 29, "_": [], "raw": 29, "remov": 29, "imag": 29, "hyperlink": 29, "758": 29, "faire_400": 29, "doc_to_q": 29, "600": 29, "faire_new": 29, "doc_q_to_a": 29, "refer": [2, 14, 23, 24], "found": 14, "root": [14, 23, 24], "repositori": 14, "pars": 14, "doe": 23, "plugin": 14, "beyond": 14, "deploi": [14, 21], "real": [14, 23, 24], "quickstart": [22, 24], "_static": [], "human_eval_ui": [], "pdf": [], "anoth": [], "figur": [], "caption": [], "paragraph": [], "se": [], "_serv": [], "discuss": [], "backend": 21, "ui": 21, "free": 21, "showcas": 21, "techniqu": 21, "rlhf": 21, "qualiti": [21, 23, 24], "rate": 21, "help": 21, "sever": 21, "johnson": [21, 22], "et": [21, 22], "al": [21, 22], "2019": [21, 22], "2023": [21, 22], "kwon": [21, 22], "zheng": [21, 22], "2023b": [], "mention": 21, "bullet": [], "second": [], "analysi": 23, "On": [], "high": [22, 23, 24], "level": [23, 24], "web": [23, 24], "At": [23, 24], "perpar": 23, "test_retriev": 20, "notic": 20, "even": 20, "though": 20, "better": 20, "sentencetransform": 20, "becaus": [20, 24], "pool": 20, "test_w_q": [20, 29], "test_bsz": 20, "recall4": [27, 28, 29], "bge": 29, "bge_1e5_mean_faire_inbatch256_temp1": 29, "2_hard0": 29, "baai": 29, "en": 29, "56": 29, "faire_starling7b": 29, "train2_bg": 29, "faire_vicuna": 29, "faire_400_bge1e5_inbatch256_chunk400hard0": 29, "05_checkpoint56": 29, "faire_e2e_test": 29, "gen_answ": 23, "respect": 23, "capit": [], "franc": [], "pari": [], "germani": [], "berlin": [], "get_worker_address": [1, 8], "get_worker_statu": [1, 8], "handle_no_work": [1, 8], "handle_worker_timeout": [1, 8], "list_model": [1, 8], "receive_heart_beat": [1, 8], "refresh_all_work": [1, 8], "register_work": [1, 8], "remove_stale_workers_by_expir": [1, 8], "remove_work": [1, 8], "worker_api_generate_stream": [1, 8], "worker_api_get_statu": [1, 8], "worker_api_retriev": [1, 8], "dispatchmethod": [1, 8], "lotteri": [1, 8], "shortest_queu": [1, 8], "from_str": [1, 8], "workerinfo": [1, 8], "check_heart_beat": [1, 8], "last_heart_beat": [1, 8], "queue_length": [1, 8], "create_control": [1, 8], "heart_beat_control": [1, 8], "add_text": [1, 8], "build_demo": [1, 8], "clear_histori": [1, 8], "document_view": [1, 8], "downvote_last_respons": [1, 8], "flag_last_respons": [1, 8], "get_conv_log_filenam": [1, 8], "get_model_list": [1, 8], "http_gener": [1, 8], "http_retriev": [1, 8], "load_demo": [1, 8], "load_demo_refresh_model_list": [1, 8], "regener": [1, 8], "upvote_last_respons": [1, 8], "violates_moder": [1, 8], "vote_last_respons": [1, 8], "modelwork": [1, 8], "add_model_arg": [1, 8], "create_model_work": [1, 8], "load_model": [1, 8], "manag": [8, 24], "distribut": 8, "worker": [8, 24], "send": [8, 24], "address": [8, 22], "client": 8, "dispatch_method": 8, "worker_nam": 8, "worker_address": 8, "worker_statu": 8, "name": [2, 8, 22, 24], "embed_mod": 8, "top_p": 8, "url_param": 8, "violat": 8, "moder": 8, "vote_typ": 8, "execut": 8, "no_regist": 8, "load_8bit": 8, "load_4bit": 8, "stream_interv": 8, "embed_in_trunc": 8, "parser": 8, "device_map": 8, "bash": [], "vicuna13b": [], "ft_e5": [], "access": [], "tabl": [], "explor": [], "xxx": 23, "generated_answ": 23, "come": [], "manual": 23, "subset": [], "read": [23, 24], "displai": 23, "7861": 23, "port": [22, 23, 24], "onc": 23, "complet": 23, "click": 23, "submit": 23, "multi": 24, "bot": [], "natur": 24, "export": [22, 24], "cuda_visible_devic": [22, 24], "databricks_400_e5": [], "choic": [11, 22, 24], "simp": [], "asyn": [], "asynchron": 24, "actual": 24, "listen": 24, "5000": [], "21001": 24, "ref": [], "conver": [], "case": 24, "point": 24, "tell": 24, "me": 24, "joke": 24, "word": 24, "fron": [], "front": 24, "end": [2, 11, 24], "28888": 24, "thei": 24, "webpag": 24, "automodel": 24, "reduc": 22, "latenc": [1, 2, 22], "time": [2, 22], "larg": 22, "accept": [11, 12, 22], "These": [], "tto": [], "stack": [], "overflow": [], "home": [], "github": [], "sgl": [], "facebookresearch": [], "howev": 22, "switch": [], "endpoint": [], "drop": 22, "rest": 24, "mani": 22, "e2eevalu": [1, 2], "compute_perform": [1, 2], "init_metr": [1, 2], "reset_all_metr": [1, 2], "e2e_lat": [1, 2], "gen_answer_stat": [1, 2], "gen_bleu": [1, 2], "gen_f1": [1, 2], "gen_gpt4ev": [1, 2], "gen_lat": [1, 2], "gen_precis": [1, 2], "gen_roug": [1, 2], "retr_document_accuraci": [1, 2], "retr_document_recal": [1, 2], "retr_lat": [1, 2], "retr_ndcg": [1, 2], "retrieverevalu": [1, 2], "answerstat": [1, 2], "documentaccuraci": [1, 2], "documentndcg": [1, 2], "documentrecal": [1, 2], "calculate_recal": [1, 2], "gpt4eval": [1, 2], "judg": [1, 2], "monitoringmetr": [1, 2], "runningmet": [1, 2], "document_similar": [1, 2], "is_almost_same_docu": [1, 2], "is_same_docu": [1, 2], "render_next_sess": [1, 8], "render_prev_sess": [1, 8], "render_single_sess": [1, 8], "save_annot": [1, 8], "vote_correct": [1, 8], "vote_harmless": [1, 8], "vote_help": [1, 8], "vote_respons": [1, 8], "test_data": 2, "accuraci": 2, "accurarci": 2, "wrapped_model": 2, "metric_typ": 2, "well": 2, "relat": 2, "answer_stat": 2, "batch_gen_answ": 2, "batch_gold_answ": 2, "batch_retrieved_doc": 2, "batch_gold_doc": 2, "document_accuraci": 2, "document_ndcg": 2, "num": 2, "use_gold_answ": 2, "num_samples_seen": 2, "record": 2, "someth": 2, "elaps": 2, "overal": 2, "bach": 2, "src_doc": 2, "target_doc": 2, "threshold": 2, "dummy_st": 8, "chatbot": 8, "submit_btn": 8, "radio_choic": 8, "supervisedfidtrain": [10, 11], "compute_loss": [10, 11, 12], "evaluation_loop": [10, 11, 12], "prediction_step": [10, 11, 12], "wrap_model_for_ev": [10, 11, 12], "supervisedtrain": [10, 11], "fixedretrievertrain": [10, 11], "fidretrievertrain": [10, 12], "embed_text": [10, 12], "kldivloss": [10, 12], "replugretrievertrain": [10, 12], "get_seq_prob": [10, 12], "instruct": [10, 12], "retrievertrain": [10, 12], "train_arg": 11, "eval_config": [11, 12], "eval_retriev": 11, "data_col": [11, 12], "datacol": [11, 12], "train_dataset": [11, 12], "eval_dataset": [11, 12], "pretrainedtokenizerbas": [11, 12], "model_init": [11, 12], "compute_metr": [11, 12], "evalpredict": [11, 12], "callback": [11, 12], "trainercallback": [11, 12], "lambdalr": [11, 12], "preprocess_logits_for_metr": [11, 12], "equival": 11, "gold": 11, "return_output": [11, 12], "dataload": [11, 12], "descript": [11, 12], "ignore_kei": [11, 12], "metric_key_prefix": [11, 12], "evalloopoutput": [11, 12], "share": [11, 12], "without": [11, 12], "inject": [11, 12], "nn": [11, 12], "target": [11, 12], "unpack": [11, 12], "being": [11, 12], "fed": [11, 12], "expect": [11, 12], "eval_wrapper_class": 11, "data_arg": 12, "fid_arg": 12, "text_id": 12, "text_mask": 12, "apply_mask": 12, "gold_scor": 12, "replug_arg": 12, "pred": 12, "logit_scor": 12, "label_str": 12, "retrieve_scor": 12, "lm_score": 12, "contrastive_arg": 12, "launch_serv": 22, "meta": [], "hf": [], "30000": 22, "f": [], "debug_test": [], "databricks_vincuna": [], "vicuna7b": [], "eval_result": [], "3000": 22}, "objects": {"": [[1, 0, 0, "-", "local_rqa"]], "local_rqa": [[1, 0, 0, "-", "base"], [1, 0, 0, "-", "constants"], [2, 0, 0, "-", "evaluation"], [3, 0, 0, "-", "guardrails"], [4, 0, 0, "-", "pipelines"], [5, 0, 0, "-", "qa_llms"], [6, 0, 0, "-", "retrievers"], [7, 0, 0, "-", "schema"], [8, 0, 0, "-", "serve"], [9, 0, 0, "-", "text_loaders"], [10, 0, 0, "-", "trainers"], [1, 0, 0, "-", "utils"]], "local_rqa.base": [[1, 1, 1, "", "Component"]], "local_rqa.base.Component": [[1, 2, 1, "", "run"], [1, 3, 1, "", "run_input_keys"]], "local_rqa.constants": [[1, 1, 1, "", "AccelerationFramework"], [1, 1, 1, "", "ErrorCode"]], "local_rqa.constants.AccelerationFramework": [[1, 3, 1, "", "SGLANG"], [1, 3, 1, "", "TGI"], [1, 3, 1, "", "VLLM"]], "local_rqa.constants.ErrorCode": [[1, 3, 1, "", "CONTEXT_OVERFLOW"], [1, 3, 1, "", "CONTROLLER_NO_WORKER"], [1, 3, 1, "", "CONTROLLER_WORKER_TIMEOUT"], [1, 3, 1, "", "CUDA_OUT_OF_MEMORY"], [1, 3, 1, "", "ENGINE_OVERLOADED"], [1, 3, 1, "", "GRADIO_REQUEST_ERROR"], [1, 3, 1, "", "GRADIO_STREAM_UNKNOWN_ERROR"], [1, 3, 1, "", "INCORRECT_AUTH_KEY"], [1, 3, 1, "", "INTERNAL_ERROR"], [1, 3, 1, "", "INVALID_AUTH_KEY"], [1, 3, 1, "", "INVALID_MODEL"], [1, 3, 1, "", "NO_PERMISSION"], [1, 3, 1, "", "PARAM_OUT_OF_RANGE"], [1, 3, 1, "", "QUOTA_EXCEEDED"], [1, 3, 1, "", "RATE_LIMIT"], [1, 3, 1, "", "VALIDATION_TYPE_ERROR"]], "local_rqa.evaluation": [[2, 0, 0, "-", "evaluator"], [2, 0, 0, "-", "metrics"], [2, 0, 0, "-", "scores"], [2, 0, 0, "-", "utils"]], "local_rqa.evaluation.evaluator": [[2, 1, 1, "", "E2EEvaluator"], [2, 1, 1, "", "Evaluator"], [2, 1, 1, "", "EvaluatorConfig"], [2, 1, 1, "", "RetrieverEvaluator"]], "local_rqa.evaluation.evaluator.E2EEvaluator": [[2, 2, 1, "", "compute_performance"], [2, 2, 1, "", "evaluate"], [2, 2, 1, "", "init_metrics"], [2, 2, 1, "", "reset_all_metrics"]], "local_rqa.evaluation.evaluator.Evaluator": [[2, 2, 1, "", "evaluate"]], "local_rqa.evaluation.evaluator.EvaluatorConfig": [[2, 3, 1, "", "assistant_prefix"], [2, 3, 1, "", "batch_size"], [2, 3, 1, "", "e2e_latency"], [2, 3, 1, "", "gen_answer_stats"], [2, 3, 1, "", "gen_bleu"], [2, 3, 1, "", "gen_f1"], [2, 3, 1, "", "gen_gpt4eval"], [2, 3, 1, "", "gen_latency"], [2, 3, 1, "", "gen_precision"], [2, 3, 1, "", "gen_rouge"], [2, 3, 1, "", "retr_document_accuracy"], [2, 3, 1, "", "retr_document_recall"], [2, 3, 1, "", "retr_latency"], [2, 3, 1, "", "retr_ndcg"], [2, 3, 1, "", "sep_sys"], [2, 3, 1, "", "sep_user"], [2, 3, 1, "", "user_prefix"]], "local_rqa.evaluation.evaluator.RetrieverEvaluator": [[2, 2, 1, "", "compute_performance"], [2, 2, 1, "", "evaluate"], [2, 2, 1, "", "init_metrics"], [2, 2, 1, "", "reset_all_metrics"]], "local_rqa.evaluation.metrics": [[2, 1, 1, "", "AnswerStats"], [2, 1, 1, "", "BLEU"], [2, 1, 1, "", "DocumentAccuracy"], [2, 1, 1, "", "DocumentNDCG"], [2, 1, 1, "", "DocumentRecall"], [2, 1, 1, "", "F1"], [2, 1, 1, "", "GPT4Eval"], [2, 1, 1, "", "Latency"], [2, 1, 1, "", "MonitoringMetric"], [2, 1, 1, "", "Precision"], [2, 1, 1, "", "ROUGE"], [2, 1, 1, "", "RunningMetic"], [2, 4, 1, "", "document_similarity"], [2, 4, 1, "", "is_almost_same_document"], [2, 4, 1, "", "is_same_document"], [2, 4, 1, "", "mean"]], "local_rqa.evaluation.metrics.AnswerStats": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.BLEU": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.DocumentAccuracy": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.DocumentNDCG": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.DocumentRecall": [[2, 2, 1, "", "calculate_recall"], [2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.F1": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.GPT4Eval": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "judge"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.Latency": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "start"], [2, 2, 1, "", "stop"]], "local_rqa.evaluation.metrics.MonitoringMetric": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "start"], [2, 2, 1, "", "stop"]], "local_rqa.evaluation.metrics.Precision": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.ROUGE": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.metrics.RunningMetic": [[2, 2, 1, "", "compute"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update"]], "local_rqa.evaluation.scores": [[2, 4, 1, "", "em"], [2, 4, 1, "", "exact_match_score"], [2, 4, 1, "", "f1"], [2, 4, 1, "", "f1_score"], [2, 4, 1, "", "precision"], [2, 4, 1, "", "recall"], [2, 4, 1, "", "rouge_score"], [2, 4, 1, "", "rouge_wrapper"]], "local_rqa.evaluation.utils": [[2, 4, 1, "", "normalize_answer"]], "local_rqa.guardrails": [[3, 0, 0, "-", "base"]], "local_rqa.guardrails.base": [[3, 1, 1, "", "BaseAnswerGuardrail"], [3, 1, 1, "", "NoopAnswerGuardrail"]], "local_rqa.guardrails.base.BaseAnswerGuardrail": [[3, 2, 1, "", "guardrail"], [3, 2, 1, "", "run"], [3, 3, 1, "", "run_input_keys"]], "local_rqa.guardrails.base.NoopAnswerGuardrail": [[3, 2, 1, "", "guardrail"]], "local_rqa.pipelines": [[4, 0, 0, "-", "base"], [4, 0, 0, "-", "prompts"], [4, 0, 0, "-", "retrieval_qa"]], "local_rqa.pipelines.base": [[4, 1, 1, "", "RQAPipeline"]], "local_rqa.pipelines.base.RQAPipeline": [[4, 2, 1, "", "components"], [4, 2, 1, "", "qa"], [4, 2, 1, "", "run"], [4, 3, 1, "", "run_input_keys"], [4, 2, 1, "", "update_dialogue_session"]], "local_rqa.pipelines.retrieval_qa": [[4, 1, 1, "", "AutoRQA"], [4, 1, 1, "", "BaseRQA"], [4, 1, 1, "", "SimpleRQA"]], "local_rqa.pipelines.retrieval_qa.SimpleRQA": [[4, 2, 1, "", "from_huggingface"], [4, 2, 1, "", "from_huggingface_fid"], [4, 2, 1, "", "from_openai"], [4, 2, 1, "", "from_scratch"], [4, 2, 1, "", "from_sglang"], [4, 2, 1, "", "from_tgi"], [4, 2, 1, "", "from_vllm"], [4, 2, 1, "", "qa"], [4, 2, 1, "", "rephrase_questions"]], "local_rqa.qa_llms": [[5, 0, 0, "-", "base"], [5, 0, 0, "-", "fid"], [5, 0, 0, "-", "huggingface"], [5, 0, 0, "-", "openai"], [5, 0, 0, "-", "prompts"], [5, 0, 0, "-", "sglang"], [5, 0, 0, "-", "tgi"], [5, 0, 0, "-", "vllm"]], "local_rqa.qa_llms.base": [[5, 1, 1, "", "BaseQAModel"], [5, 1, 1, "", "GenerationOutput"]], "local_rqa.qa_llms.base.BaseQAModel": [[5, 2, 1, "", "generate"], [5, 3, 1, "", "is_api_model"], [5, 2, 1, "", "r_generate"], [5, 2, 1, "", "run"], [5, 3, 1, "", "run_input_keys"]], "local_rqa.qa_llms.base.GenerationOutput": [[5, 3, 1, "", "batch_answers"]], "local_rqa.qa_llms.fid": [[5, 1, 1, "", "CheckpointWrapper"], [5, 1, 1, "", "EncoderWrapper"], [5, 1, 1, "", "FiDT5"], [5, 4, 1, "", "apply_checkpoint_wrapper"], [5, 4, 1, "", "cross_attention_forward"]], "local_rqa.qa_llms.fid.CheckpointWrapper": [[5, 2, 1, "", "forward"]], "local_rqa.qa_llms.fid.EncoderWrapper": [[5, 2, 1, "", "forward"]], "local_rqa.qa_llms.fid.FiDT5": [[5, 2, 1, "", "forward"], [5, 2, 1, "", "forward_"], [5, 2, 1, "", "from_t5"], [5, 2, 1, "", "generate"], [5, 2, 1, "", "get_crossattention_scores"], [5, 2, 1, "", "load_t5"], [5, 2, 1, "", "overwrite_forward_crossattention"], [5, 2, 1, "", "reset_score_storage"], [5, 2, 1, "", "set_checkpoint"], [5, 2, 1, "", "unwrap_encoder"], [5, 2, 1, "", "wrap_encoder"]], "local_rqa.qa_llms.huggingface": [[5, 1, 1, "", "HuggingFaceFiDQAModel"], [5, 1, 1, "", "HuggingFaceQAModel"]], "local_rqa.qa_llms.huggingface.HuggingFaceFiDQAModel": [[5, 2, 1, "", "encode_fid_inputs"], [5, 2, 1, "", "generate"], [5, 2, 1, "", "pack_fid_inputs"], [5, 2, 1, "", "r_generate"], [5, 2, 1, "", "unpack_fid_inputs"]], "local_rqa.qa_llms.huggingface.HuggingFaceQAModel": [[5, 2, 1, "", "generate"], [5, 2, 1, "", "r_generate"]], "local_rqa.qa_llms.openai": [[5, 1, 1, "", "OpenAIQAModel"]], "local_rqa.qa_llms.openai.OpenAIQAModel": [[5, 2, 1, "", "generate"], [5, 2, 1, "", "r_generate"]], "local_rqa.qa_llms.sglang": [[5, 1, 1, "", "SGLangClient"], [5, 1, 1, "", "SGLangQAModel"]], "local_rqa.qa_llms.sglang.SGLangClient": [[5, 2, 1, "", "generate"], [5, 2, 1, "", "generate_stream"]], "local_rqa.qa_llms.sglang.SGLangQAModel": [[5, 2, 1, "", "generate"], [5, 3, 1, "", "is_api_model"], [5, 2, 1, "", "prepare_gen_kwargs"], [5, 2, 1, "", "r_generate"]], "local_rqa.qa_llms.tgi": [[5, 1, 1, "", "TGIQAModel"]], "local_rqa.qa_llms.tgi.TGIQAModel": [[5, 2, 1, "", "generate"], [5, 3, 1, "", "is_api_model"], [5, 2, 1, "", "prepare_gen_kwargs"], [5, 2, 1, "", "r_generate"]], "local_rqa.qa_llms.vllm": [[5, 1, 1, "", "VLLMClient"], [5, 1, 1, "", "vLLMQAModel"]], "local_rqa.qa_llms.vllm.VLLMClient": [[5, 2, 1, "", "generate"], [5, 2, 1, "", "generate_stream"]], "local_rqa.qa_llms.vllm.vLLMQAModel": [[5, 2, 1, "", "generate"], [5, 3, 1, "", "is_api_model"], [5, 2, 1, "", "prepare_gen_kwargs"], [5, 2, 1, "", "r_generate"]], "local_rqa.retrievers": [[6, 0, 0, "-", "base"], [6, 0, 0, "-", "faiss_retriever"]], "local_rqa.retrievers.base": [[6, 1, 1, "", "BaseRetriever"], [6, 1, 1, "", "DummyRetriever"], [6, 1, 1, "", "RetrievalOutput"]], "local_rqa.retrievers.base.BaseRetriever": [[6, 2, 1, "", "retrieve"], [6, 2, 1, "", "run"], [6, 3, 1, "", "run_input_keys"]], "local_rqa.retrievers.base.DummyRetriever": [[6, 2, 1, "", "retrieve"]], "local_rqa.retrievers.base.RetrievalOutput": [[6, 3, 1, "", "batch_source_documents"]], "local_rqa.retrievers.faiss_retriever": [[6, 1, 1, "", "FaissRetriever"]], "local_rqa.retrievers.faiss_retriever.FaissRetriever": [[6, 2, 1, "", "from_disk"], [6, 2, 1, "", "prepare_docs_for_retrieval"], [6, 2, 1, "", "retrieve"], [6, 2, 1, "", "retrieve_w_score"]], "local_rqa.schema": [[7, 0, 0, "-", "dialogue"], [7, 0, 0, "-", "document"]], "local_rqa.schema.dialogue": [[7, 1, 1, "", "DialogueSession"], [7, 1, 1, "", "DialogueTurn"], [7, 1, 1, "", "RQAOutput"], [7, 1, 1, "", "SeparatorStyle"]], "local_rqa.schema.dialogue.DialogueSession": [[7, 2, 1, "", "add_system_message"], [7, 2, 1, "", "add_user_message"], [7, 3, 1, "", "assistant_prefix"], [7, 2, 1, "", "clone"], [7, 2, 1, "", "from_list"], [7, 3, 1, "", "history"], [7, 3, 1, "", "sep_style"], [7, 3, 1, "", "sep_sys"], [7, 3, 1, "", "sep_user"], [7, 2, 1, "", "to_list"], [7, 2, 1, "", "to_string"], [7, 3, 1, "", "user_prefix"]], "local_rqa.schema.dialogue.DialogueTurn": [[7, 2, 1, "", "clone"], [7, 2, 1, "", "from_dict"], [7, 3, 1, "", "message"], [7, 3, 1, "", "source_documents"], [7, 3, 1, "", "speaker"], [7, 2, 1, "", "to_dict"], [7, 2, 1, "", "to_string"]], "local_rqa.schema.dialogue.RQAOutput": [[7, 3, 1, "", "batch_answers"], [7, 3, 1, "", "batch_dialogue_session"], [7, 3, 1, "", "batch_source_documents"]], "local_rqa.schema.dialogue.SeparatorStyle": [[7, 3, 1, "", "SINGLE"], [7, 3, 1, "", "TWO"]], "local_rqa.schema.document": [[7, 1, 1, "", "Document"], [7, 4, 1, "", "default_document_formatter"]], "local_rqa.schema.document.Document": [[7, 2, 1, "", "clone"], [7, 3, 1, "", "fmt_content"], [7, 2, 1, "", "from_dict"], [7, 2, 1, "", "from_langchain_doc"], [7, 3, 1, "", "metadata"], [7, 3, 1, "", "page_content"], [7, 2, 1, "", "to_dict"], [7, 2, 1, "", "to_langchain_doc"]], "local_rqa.serve": [[8, 0, 0, "-", "base_model_worker"], [8, 0, 0, "-", "controller"], [8, 0, 0, "-", "gradio_dialogue"], [8, 0, 0, "-", "gradio_rqa"], [8, 0, 0, "-", "gradio_static_server"], [8, 0, 0, "-", "gradio_web_server"], [8, 0, 0, "-", "model_worker"], [8, 0, 0, "-", "test_message"]], "local_rqa.serve.base_model_worker": [[8, 1, 1, "", "BaseModelWorker"], [8, 4, 1, "", "acquire_worker_semaphore"], [8, 4, 1, "", "api_count_token"], [8, 4, 1, "", "api_generate"], [8, 4, 1, "", "api_generate_stream"], [8, 4, 1, "", "api_get_conv"], [8, 4, 1, "", "api_get_status"], [8, 4, 1, "", "api_model_details"], [8, 4, 1, "", "api_retrieval"], [8, 4, 1, "", "create_background_tasks"], [8, 4, 1, "", "heart_beat_worker"], [8, 4, 1, "", "release_worker_semaphore"]], "local_rqa.serve.base_model_worker.BaseModelWorker": [[8, 2, 1, "", "count_token"], [8, 2, 1, "", "generate_gate"], [8, 2, 1, "", "generate_stream_gate"], [8, 2, 1, "", "get_queue_length"], [8, 2, 1, "", "get_status"], [8, 2, 1, "", "init_heart_beat"], [8, 2, 1, "", "register_to_controller"], [8, 2, 1, "", "retrieve"], [8, 2, 1, "", "send_heart_beat"]], "local_rqa.serve.controller": [[8, 1, 1, "", "Controller"], [8, 1, 1, "", "DispatchMethod"], [8, 1, 1, "", "WorkerInfo"], [8, 4, 1, "", "create_controller"], [8, 4, 1, "", "get_worker_address"], [8, 4, 1, "", "heart_beat_controller"], [8, 4, 1, "", "list_models"], [8, 4, 1, "", "receive_heart_beat"], [8, 4, 1, "", "refresh_all_workers"], [8, 4, 1, "", "register_worker"], [8, 4, 1, "", "worker_api_generate_stream"], [8, 4, 1, "", "worker_api_get_status"], [8, 4, 1, "", "worker_api_retrieval"]], "local_rqa.serve.controller.Controller": [[8, 2, 1, "", "get_worker_address"], [8, 2, 1, "", "get_worker_status"], [8, 2, 1, "", "handle_no_worker"], [8, 2, 1, "", "handle_worker_timeout"], [8, 2, 1, "", "list_models"], [8, 2, 1, "", "receive_heart_beat"], [8, 2, 1, "", "refresh_all_workers"], [8, 2, 1, "", "register_worker"], [8, 2, 1, "", "remove_stale_workers_by_expiration"], [8, 2, 1, "", "remove_worker"], [8, 2, 1, "", "worker_api_generate_stream"], [8, 2, 1, "", "worker_api_get_status"], [8, 2, 1, "", "worker_api_retrieval"]], "local_rqa.serve.controller.DispatchMethod": [[8, 3, 1, "", "LOTTERY"], [8, 3, 1, "", "SHORTEST_QUEUE"], [8, 2, 1, "", "from_str"]], "local_rqa.serve.controller.WorkerInfo": [[8, 3, 1, "", "check_heart_beat"], [8, 3, 1, "", "last_heart_beat"], [8, 3, 1, "", "model_names"], [8, 3, 1, "", "queue_length"], [8, 3, 1, "", "speed"]], "local_rqa.serve.gradio_dialogue": [[8, 1, 1, "", "AnnotationHistory"], [8, 1, 1, "", "GradioDialogueSession"]], "local_rqa.serve.gradio_dialogue.AnnotationHistory": [[8, 2, 1, "", "get_current_idx"], [8, 2, 1, "", "get_current_label"], [8, 2, 1, "", "get_next_idx"], [8, 2, 1, "", "get_num_labeled"], [8, 2, 1, "", "get_num_to_label"], [8, 2, 1, "", "get_prev_idx"], [8, 2, 1, "", "is_all_labeled"], [8, 2, 1, "", "load"], [8, 2, 1, "", "parse_int_range"], [8, 2, 1, "", "to_jsonl"], [8, 2, 1, "", "update_label"]], "local_rqa.serve.gradio_dialogue.GradioDialogueSession": [[8, 2, 1, "", "add_system_message"], [8, 2, 1, "", "add_user_message"], [8, 2, 1, "", "clone"], [8, 2, 1, "", "get_prompt"], [8, 3, 1, "", "skip_next"], [8, 2, 1, "", "to_dict"], [8, 2, 1, "", "to_gradio_chatbot"]], "local_rqa.serve.gradio_rqa": [[8, 1, 1, "", "GradioRQA"], [8, 1, 1, "", "GradioSimpleRQA"]], "local_rqa.serve.gradio_rqa.GradioRQA": [[8, 2, 1, "", "generate_stream_from_api"], [8, 2, 1, "", "get_model"], [8, 2, 1, "", "get_tokenizer"], [8, 2, 1, "", "prepare_prompt_for_generation"], [8, 2, 1, "", "rephrase_question_for_retrieval"], [8, 2, 1, "", "retrieve"]], "local_rqa.serve.gradio_rqa.GradioSimpleRQA": [[8, 2, 1, "", "from_scratch"], [8, 2, 1, "", "generate_stream_from_api"], [8, 2, 1, "", "get_model"], [8, 2, 1, "", "get_tokenizer"], [8, 2, 1, "", "prepare_prompt_for_generation"], [8, 2, 1, "", "rephrase_question_for_retrieval"], [8, 2, 1, "", "retrieve"]], "local_rqa.serve.gradio_static_server": [[8, 5, 1, "", "args"], [8, 4, 1, "", "build_demo"], [8, 4, 1, "", "document_view"], [8, 4, 1, "", "get_conv_log_filename"], [8, 4, 1, "", "load_demo"], [8, 4, 1, "", "render_next_session"], [8, 4, 1, "", "render_prev_session"], [8, 4, 1, "", "render_single_session"], [8, 4, 1, "", "save_annotations"], [8, 4, 1, "", "vote_correctness"], [8, 4, 1, "", "vote_harmlessness"], [8, 4, 1, "", "vote_helpfulness"], [8, 4, 1, "", "vote_response"]], "local_rqa.serve.gradio_web_server": [[8, 4, 1, "", "add_text"], [8, 5, 1, "", "args"], [8, 4, 1, "", "build_demo"], [8, 4, 1, "", "clear_history"], [8, 4, 1, "", "document_view"], [8, 4, 1, "", "downvote_last_response"], [8, 4, 1, "", "flag_last_response"], [8, 4, 1, "", "get_conv_log_filename"], [8, 4, 1, "", "get_model_list"], [8, 4, 1, "", "http_generate"], [8, 4, 1, "", "http_retrieve"], [8, 4, 1, "", "load_demo"], [8, 4, 1, "", "load_demo_refresh_model_list"], [8, 4, 1, "", "regenerate"], [8, 4, 1, "", "upvote_last_response"], [8, 4, 1, "", "violates_moderation"], [8, 4, 1, "", "vote_last_response"]], "local_rqa.serve.model_worker": [[8, 1, 1, "", "ModelWorker"], [8, 4, 1, "", "add_model_args"], [8, 4, 1, "", "create_model_worker"], [8, 4, 1, "", "load_model"]], "local_rqa.serve.model_worker.ModelWorker": [[8, 2, 1, "", "generate_gate"], [8, 2, 1, "", "generate_stream"], [8, 2, 1, "", "generate_stream_gate"], [8, 2, 1, "", "retrieve"]], "local_rqa.serve.test_message": [[8, 4, 1, "", "main"]], "local_rqa.text_loaders": [[9, 0, 0, "-", "base"], [9, 0, 0, "-", "langchain_text_loader"], [9, 0, 0, "-", "llamaindex_text_loader"]], "local_rqa.text_loaders.base": [[9, 1, 1, "", "BaseTextLoader"]], "local_rqa.text_loaders.base.BaseTextLoader": [[9, 2, 1, "", "load_data"], [9, 2, 1, "", "save_texts"]], "local_rqa.text_loaders.langchain_text_loader": [[9, 1, 1, "", "LangChainTextLoader"]], "local_rqa.text_loaders.langchain_text_loader.LangChainTextLoader": [[9, 2, 1, "", "load_data"], [9, 2, 1, "", "save_texts"]], "local_rqa.text_loaders.llamaindex_text_loader": [[9, 1, 1, "", "LlamaIndexTextLoader"]], "local_rqa.text_loaders.llamaindex_text_loader.LlamaIndexTextLoader": [[9, 2, 1, "", "load_data"], [9, 2, 1, "", "save_texts"]], "local_rqa.trainers": [[10, 0, 0, "-", "dist_utils"], [11, 0, 0, "-", "qa_llm"], [12, 0, 0, "-", "retriever"], [10, 0, 0, "-", "utils"]], "local_rqa.trainers.dist_utils": [[10, 4, 1, "", "barrier"], [10, 4, 1, "", "get_rank"], [10, 4, 1, "", "is_main"]], "local_rqa.trainers.qa_llm": [[11, 0, 0, "-", "arguments"], [11, 0, 0, "-", "datasets"], [11, 0, 0, "-", "supervised_fid_trainer"], [11, 0, 0, "-", "supervised_trainer"], [11, 0, 0, "-", "with_retriever_fid_trainer"], [11, 0, 0, "-", "with_retriever_trainer"]], "local_rqa.trainers.qa_llm.arguments": [[11, 1, 1, "", "E2EQATrainingArguments"], [11, 1, 1, "", "RetrievalQATrainingArguments"]], "local_rqa.trainers.qa_llm.arguments.E2EQATrainingArguments": [[11, 3, 1, "", "do_eval"], [11, 3, 1, "", "do_train"], [11, 3, 1, "", "eval_steps"], [11, 3, 1, "", "evaluation_strategy"], [11, 3, 1, "", "learning_rate"], [11, 3, 1, "", "load_best_model_at_end"], [11, 3, 1, "", "logging_steps"], [11, 3, 1, "", "lr_scheduler_kwargs"], [11, 3, 1, "", "lr_scheduler_type"], [11, 3, 1, "", "metric_for_best_model"], [11, 3, 1, "", "num_train_epochs"], [11, 3, 1, "", "output_dir"], [11, 3, 1, "", "per_device_eval_batch_size"], [11, 3, 1, "", "remove_unused_columns"], [11, 3, 1, "", "report_to"], [11, 3, 1, "", "save_steps"], [11, 3, 1, "", "save_strategy"], [11, 3, 1, "", "save_total_limit"], [11, 3, 1, "", "seed"], [11, 3, 1, "", "warmup_ratio"], [11, 3, 1, "", "weight_decay"]], "local_rqa.trainers.qa_llm.arguments.RetrievalQATrainingArguments": [[11, 3, 1, "", "documents_path"], [11, 3, 1, "", "eval_data_path"], [11, 3, 1, "", "lr_scheduler_kwargs"], [11, 3, 1, "", "output_dir"], [11, 3, 1, "", "write_predictions"]], "local_rqa.trainers.qa_llm.datasets": [[11, 1, 1, "", "NoopDataCollator"], [11, 1, 1, "", "SupervisedFiDRQAwRetrieverDataset"], [11, 1, 1, "", "SupervisedRQADataset"], [11, 1, 1, "", "SupervisedRQAwRetrieverDataset"], [11, 4, 1, "", "batch_iterator"], [11, 4, 1, "", "retriever_init"]], "local_rqa.trainers.qa_llm.datasets.SupervisedFiDRQAwRetrieverDataset": [[11, 2, 1, "", "encode_data"], [11, 2, 1, "", "encode_fid_inputs"], [11, 2, 1, "", "pre_retrieve_all_docs"], [11, 2, 1, "", "prepare_data"]], "local_rqa.trainers.qa_llm.datasets.SupervisedRQADataset": [[11, 2, 1, "", "encode_data"], [11, 2, 1, "", "prepare_data"]], "local_rqa.trainers.qa_llm.datasets.SupervisedRQAwRetrieverDataset": [[11, 2, 1, "", "encode_data"], [11, 2, 1, "", "pre_retrieve_all_docs"], [11, 2, 1, "", "prepare_data"]], "local_rqa.trainers.qa_llm.supervised_fid_trainer": [[11, 1, 1, "", "SupervisedFiDTrainer"]], "local_rqa.trainers.qa_llm.supervised_fid_trainer.SupervisedFiDTrainer": [[11, 2, 1, "", "compute_loss"], [11, 2, 1, "", "evaluation_loop"], [11, 2, 1, "", "prediction_step"], [11, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.qa_llm.supervised_trainer": [[11, 1, 1, "", "SupervisedTrainer"]], "local_rqa.trainers.qa_llm.supervised_trainer.SupervisedTrainer": [[11, 2, 1, "", "compute_loss"], [11, 2, 1, "", "evaluation_loop"], [11, 2, 1, "", "prediction_step"], [11, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.qa_llm.with_retriever_trainer": [[11, 1, 1, "", "FixedRetrieverTrainer"], [11, 4, 1, "", "batch_iterator"]], "local_rqa.trainers.qa_llm.with_retriever_trainer.FixedRetrieverTrainer": [[11, 2, 1, "", "compute_loss"], [11, 2, 1, "", "evaluation_loop"], [11, 2, 1, "", "prediction_step"], [11, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.retriever": [[12, 0, 0, "-", "arguments"], [12, 0, 0, "-", "datasets"], [12, 0, 0, "-", "embeddings"], [12, 0, 0, "-", "retriever_fid_trainer"], [12, 0, 0, "-", "retriever_replug_trainer"], [12, 0, 0, "-", "retriever_trainer"]], "local_rqa.trainers.retriever.arguments": [[12, 1, 1, "", "ContrasitiveTrainingArgs"], [12, 1, 1, "", "DataArguments"], [12, 1, 1, "", "FidTrainingArgs"], [12, 1, 1, "", "LoggerArguments"], [12, 1, 1, "", "ModelArguments"], [12, 1, 1, "", "ReplugTrainingArgs"], [12, 1, 1, "", "RetrievalQATrainingArguments"]], "local_rqa.trainers.retriever.arguments.ContrasitiveTrainingArgs": [[12, 3, 1, "", "contrastive_loss"], [12, 3, 1, "", "hard_neg_ratio"], [12, 3, 1, "", "temperature"]], "local_rqa.trainers.retriever.arguments.DataArguments": [[12, 3, 1, "", "eval_file"], [12, 3, 1, "", "full_dataset_file_path"], [12, 3, 1, "", "test_file"], [12, 3, 1, "", "train_file"]], "local_rqa.trainers.retriever.arguments.FidTrainingArgs": [[12, 3, 1, "", "apply_passage_mask"], [12, 3, 1, "", "apply_question_mask"], [12, 3, 1, "", "extract_cls"], [12, 3, 1, "", "indexing_dimension"], [12, 3, 1, "", "n_context"], [12, 3, 1, "", "projection"], [12, 3, 1, "", "reader_batch_size"], [12, 3, 1, "", "reader_model_path"], [12, 3, 1, "", "reader_temperature"], [12, 3, 1, "", "text_maxlength"], [12, 3, 1, "", "with_score"]], "local_rqa.trainers.retriever.arguments.LoggerArguments": [[12, 3, 1, "", "run_entity"], [12, 3, 1, "", "run_group"], [12, 3, 1, "", "run_project"]], "local_rqa.trainers.retriever.arguments.ModelArguments": [[12, 3, 1, "", "model_name_or_path"]], "local_rqa.trainers.retriever.arguments.ReplugTrainingArgs": [[12, 3, 1, "", "lm_model_path"], [12, 3, 1, "", "lm_temperature"], [12, 3, 1, "", "num_docs"], [12, 3, 1, "", "refresh_step"], [12, 3, 1, "", "retrieve_temperature"], [12, 3, 1, "", "text_maxlength"]], "local_rqa.trainers.retriever.arguments.RetrievalQATrainingArguments": [[12, 3, 1, "", "do_eval"], [12, 3, 1, "", "do_train"], [12, 3, 1, "", "eval_steps"], [12, 3, 1, "", "evaluation_strategy"], [12, 3, 1, "", "gradient_checkpointing"], [12, 3, 1, "", "learning_rate"], [12, 3, 1, "", "logging_steps"], [12, 3, 1, "", "lr_scheduler_kwargs"], [12, 3, 1, "", "lr_scheduler_type"], [12, 3, 1, "", "max_steps"], [12, 3, 1, "", "metric_for_best_model"], [12, 3, 1, "", "output_dir"], [12, 3, 1, "", "per_device_eval_batch_size"], [12, 3, 1, "", "per_device_train_batch_size"], [12, 3, 1, "", "pooling_type"], [12, 3, 1, "", "remove_unused_columns"], [12, 3, 1, "", "report_to"], [12, 3, 1, "", "save_steps"], [12, 3, 1, "", "save_strategy"], [12, 3, 1, "", "save_total_limit"], [12, 3, 1, "", "seed"], [12, 3, 1, "", "warmup_ratio"], [12, 3, 1, "", "weight_decay"], [12, 3, 1, "", "write_predictions"]], "local_rqa.trainers.retriever.datasets": [[12, 1, 1, "", "ContrastiveRetrievalDataset"], [12, 1, 1, "", "FidCollator"], [12, 1, 1, "", "FidDataset"], [12, 1, 1, "", "NoopDataCollator"], [12, 1, 1, "", "ReplugDataset"], [12, 1, 1, "", "RetrieverCollator"], [12, 4, 1, "", "encode_passages"], [12, 4, 1, "", "load_fid_data"]], "local_rqa.trainers.retriever.datasets.ContrastiveRetrievalDataset": [[12, 2, 1, "", "prepare_data"]], "local_rqa.trainers.retriever.datasets.FidDataset": [[12, 2, 1, "", "get_example"], [12, 2, 1, "", "get_target"], [12, 2, 1, "", "sort_data"]], "local_rqa.trainers.retriever.datasets.ReplugDataset": [[12, 2, 1, "", "get_target"]], "local_rqa.trainers.retriever.embeddings": [[12, 1, 1, "", "LocalEmbeddings"], [12, 4, 1, "", "batch_iterator"], [12, 4, 1, "", "compute_embedding"], [12, 4, 1, "", "embed_document_batch"], [12, 4, 1, "", "mean_pooling"]], "local_rqa.trainers.retriever.embeddings.LocalEmbeddings": [[12, 2, 1, "", "embed_documents"], [12, 2, 1, "", "embed_query"]], "local_rqa.trainers.retriever.retriever_fid_trainer": [[12, 1, 1, "", "FidRetrieverTrainer"]], "local_rqa.trainers.retriever.retriever_fid_trainer.FidRetrieverTrainer": [[12, 2, 1, "", "compute_loss"], [12, 2, 1, "", "embed_text"], [12, 2, 1, "", "evaluation_loop"], [12, 2, 1, "", "kldivloss"], [12, 2, 1, "", "prediction_step"], [12, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.retriever.retriever_replug_trainer": [[12, 1, 1, "", "ReplugRetrieverTrainer"]], "local_rqa.trainers.retriever.retriever_replug_trainer.ReplugRetrieverTrainer": [[12, 2, 1, "", "compute_loss"], [12, 2, 1, "", "evaluation_loop"], [12, 2, 1, "", "get_seq_prob"], [12, 2, 1, "", "instruct"], [12, 2, 1, "", "kldivloss"], [12, 2, 1, "", "prediction_step"], [12, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.retriever.retriever_trainer": [[12, 1, 1, "", "RetrieverTrainer"]], "local_rqa.trainers.retriever.retriever_trainer.RetrieverTrainer": [[12, 2, 1, "", "compute_loss"], [12, 2, 1, "", "evaluation_loop"], [12, 2, 1, "", "prediction_step"], [12, 2, 1, "", "wrap_model_for_eval"]], "local_rqa.trainers.utils": [[10, 4, 1, "", "create_dir_if_not_exists"], [10, 4, 1, "", "init_logger"], [10, 4, 1, "", "remove_optimizer_weights"]], "local_rqa.utils": [[1, 4, 1, "", "init_logger"], [1, 4, 1, "", "pretty_print_semaphore"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function", "5": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"], "5": ["py", "data", "Python data"]}, "titleterms": {"local_rqa": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "subpackag": [1, 10], "submodul": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "base": [1, 3, 4, 5, 6, 9], "modul": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "constant": 1, "util": [1, 2, 10], "evalu": [2, 18, 19, 20, 23], "packag": [2, 3, 4, 5, 6, 7, 8, 9], "metric": 2, "score": [2, 27], "content": [2, 3, 4, 5, 6, 7, 8, 9], "guardrail": 3, "pipelin": 4, "prompt": [4, 5], "retrieval_qa": 4, "qa_llm": [5, 11], "fid": [5, 26], "huggingfac": 5, "openai": 5, "sglang": 5, "tgi": 5, "vllm": 5, "retriev": [6, 12, 20, 26, 27, 28, 29], "bm25_retriev": 6, "faiss_retriev": 6, "schema": 7, "dialogu": 7, "document": [7, 14, 16], "serv": [8, 21, 22], "base_model_work": 8, "control": 8, "gradio_dialogu": 8, "gradio_rqa": 8, "gradio_static_serv": 8, "gradio_web_serv": 8, "model_work": 8, "test_messag": 8, "text_load": 9, "langchain_text_load": 9, "llamaindex_text_load": 9, "trainer": [10, 11, 12], "namespac": [10, 11, 12], "dist_util": 10, "argument": [11, 12], "dataset": [11, 12], "supervised_fid_train": 11, "supervised_train": 11, "with_retriever_fid_train": 11, "with_retriever_train": 11, "embed": 12, "retriever_fid_train": 12, "retriever_replug_train": 12, "retriever_train": 12, "instal": 13, "from": [13, 27], "sourc": 13, "quickstart": 14, "prepar": 14, "some": 15, "featur": 15, "subsect": 15, "welcom": 16, "localrqa": 16, "": [16, 27], "why": 16, "how": 16, "can": 16, "help": 16, "indic": 16, "tabl": 16, "data": [17, 28, 29], "end": 19, "default": [], "acceler": [21, 22], "framework": [21, 22], "static": 23, "result": [], "train": [25, 28, 29], "gener": [26, 28, 29], "supervis": 26, "finetun": 26, "ground": 26, "truth": 26, "sft": 26, "frozen": 26, "swr": 26, "fusion": 26, "decod": [26, 27], "distil": 27, "cross": 27, "attent": 27, "an": [14, 27], "encod": 27, "model": [22, 27], "dca": 27, "lm": 27, "probabl": 27, "distribut": 27, "rpg": 27, "contrast": 27, "learn": 27, "ctl": 27, "databrick": 28, "fair": 29, "build": 14, "rqa": 14, "system": 14, "next": 14, "step": 14, "human": 23, "interact": 24, "chat": 24, "infer": 22, "launcher": 21, "simplerqa": 22}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"local_rqa": [[0, "local-rqa"], [1, "module-local_rqa"]], "Subpackages": [[1, "subpackages"], [10, "subpackages"]], "Submodules": [[1, "submodules"], [3, "submodules"], [4, "submodules"], [5, "submodules"], [7, "submodules"], [9, "submodules"], [10, "submodules"], [2, "submodules"], [8, "submodules"], [11, "submodules"], [12, "submodules"], [6, "submodules"]], "local_rqa.base module": [[1, "module-local_rqa.base"]], "local_rqa.constants module": [[1, "module-local_rqa.constants"]], "local_rqa.utils module": [[1, "module-local_rqa.utils"]], "Module contents": [[3, "module-local_rqa.guardrails"], [4, "module-local_rqa.pipelines"], [5, "module-local_rqa.qa_llms"], [7, "module-local_rqa.schema"], [9, "module-local_rqa.text_loaders"], [2, "module-local_rqa.evaluation"], [8, "module-local_rqa.serve"], [6, "module-local_rqa.retrievers"]], "local_rqa.guardrails package": [[3, "local-rqa-guardrails-package"]], "local_rqa.guardrails.base module": [[3, "module-local_rqa.guardrails.base"]], "local_rqa.pipelines package": [[4, "local-rqa-pipelines-package"]], "local_rqa.pipelines.base module": [[4, "module-local_rqa.pipelines.base"]], "local_rqa.pipelines.prompts module": [[4, "module-local_rqa.pipelines.prompts"]], "local_rqa.pipelines.retrieval_qa module": [[4, "module-local_rqa.pipelines.retrieval_qa"]], "local_rqa.qa_llms package": [[5, "local-rqa-qa-llms-package"]], "local_rqa.qa_llms.base module": [[5, "module-local_rqa.qa_llms.base"]], "local_rqa.qa_llms.fid module": [[5, "module-local_rqa.qa_llms.fid"]], "local_rqa.qa_llms.huggingface module": [[5, "module-local_rqa.qa_llms.huggingface"]], "local_rqa.qa_llms.openai module": [[5, "module-local_rqa.qa_llms.openai"]], "local_rqa.qa_llms.prompts module": [[5, "module-local_rqa.qa_llms.prompts"]], "local_rqa.qa_llms.sglang module": [[5, "module-local_rqa.qa_llms.sglang"]], "local_rqa.qa_llms.tgi module": [[5, "module-local_rqa.qa_llms.tgi"]], "local_rqa.qa_llms.vllm module": [[5, "module-local_rqa.qa_llms.vllm"]], "local_rqa.schema package": [[7, "local-rqa-schema-package"]], "local_rqa.schema.dialogue module": [[7, "module-local_rqa.schema.dialogue"]], "local_rqa.schema.document module": [[7, "module-local_rqa.schema.document"]], "local_rqa.text_loaders package": [[9, "local-rqa-text-loaders-package"]], "local_rqa.text_loaders.base module": [[9, "module-local_rqa.text_loaders.base"]], "local_rqa.text_loaders.langchain_text_loader module": [[9, "module-local_rqa.text_loaders.langchain_text_loader"]], "local_rqa.text_loaders.llamaindex_text_loader module": [[9, "module-local_rqa.text_loaders.llamaindex_text_loader"]], "local_rqa.trainers namespace": [[10, "module-local_rqa.trainers"]], "local_rqa.trainers.dist_utils module": [[10, "module-local_rqa.trainers.dist_utils"]], "local_rqa.trainers.utils module": [[10, "module-local_rqa.trainers.utils"]], "Installation": [[13, "installation"]], "From source": [[13, "from-source"]], "Some feature": [[15, "some-feature"]], "Subsection": [[15, "subsection"]], "Welcome to LocalRQA\u2019s documentation!": [[16, "welcome-to-localrqa-s-documentation"]], "\ud83d\ude80 Why LocalRQA?": [[16, "why-localrqa"]], "How can LocalRQA help?": [[16, "how-can-localrqa-help"]], "Indices and tables": [[16, "indices-and-tables"]], "Evaluation": [[18, "evaluation"]], "Retriever Evaluation": [[20, "retriever-evaluation"]], "Serving": [[21, "serving"]], "Launchers": [[21, "launchers"]], "Acceleration Frameworks": [[21, "acceleration-frameworks"]], "Training": [[25, "training"]], "Generator": [[26, "generator"]], "Supervised finetune with ground-truth (SFT)": [[26, "supervised-finetune-with-ground-truth-sft"]], "Supervised finetune with a frozen retriever (SwR)": [[26, "supervised-finetune-with-a-frozen-retriever-swr"]], "Fusion-in-decoder (FiD)": [[26, "fusion-in-decoder-fid"]], "Retriever": [[27, "retriever"]], "Distill from Cross-Attention scores of an encoder-decoder model (DCA)": [[27, "distill-from-cross-attention-scores-of-an-encoder-decoder-model-dca"]], "Distill from an LM\u2019s probability distribution (RPG)": [[27, "distill-from-an-lm-s-probability-distribution-rpg"]], "Contrastive Learning (CTL)": [[27, "contrastive-learning-ctl"]], "Databricks": [[28, "databricks"]], "Data Generation": [[28, "data-generation"], [29, "data-generation"]], "Retriever Training": [[28, "retriever-training"], [29, "retriever-training"]], "Generator Training": [[28, "generator-training"], [29, "generator-training"]], "Faire": [[29, "faire"]], "Static Human Evaluation": [[23, "static-human-evaluation"]], "Quickstart": [[14, "quickstart"]], "Prepare Document": [[14, "prepare-document"]], "Build an RQA System": [[14, "build-an-rqa-system"]], "Next Steps": [[14, "next-steps"]], "Interactive Chat": [[24, "interactive-chat"]], "local_rqa.evaluation package": [[2, "local-rqa-evaluation-package"]], "local_rqa.evaluation.evaluator module": [[2, "module-local_rqa.evaluation.evaluator"]], "local_rqa.evaluation.metrics module": [[2, "module-local_rqa.evaluation.metrics"]], "local_rqa.evaluation.scores module": [[2, "module-local_rqa.evaluation.scores"]], "local_rqa.evaluation.utils module": [[2, "module-local_rqa.evaluation.utils"]], "local_rqa.serve package": [[8, "local-rqa-serve-package"]], "local_rqa.serve.base_model_worker module": [[8, "module-local_rqa.serve.base_model_worker"]], "local_rqa.serve.controller module": [[8, "module-local_rqa.serve.controller"]], "local_rqa.serve.gradio_dialogue module": [[8, "module-local_rqa.serve.gradio_dialogue"]], "local_rqa.serve.gradio_rqa module": [[8, "module-local_rqa.serve.gradio_rqa"]], "local_rqa.serve.gradio_static_server module": [[8, "module-local_rqa.serve.gradio_static_server"]], "local_rqa.serve.gradio_web_server module": [[8, "module-local_rqa.serve.gradio_web_server"]], "local_rqa.serve.model_worker module": [[8, "module-local_rqa.serve.model_worker"]], "local_rqa.serve.test_message module": [[8, "module-local_rqa.serve.test_message"]], "local_rqa.trainers.qa_llm namespace": [[11, "module-local_rqa.trainers.qa_llm"]], "local_rqa.trainers.qa_llm.arguments module": [[11, "module-local_rqa.trainers.qa_llm.arguments"]], "local_rqa.trainers.qa_llm.datasets module": [[11, "module-local_rqa.trainers.qa_llm.datasets"]], "local_rqa.trainers.qa_llm.supervised_fid_trainer module": [[11, "module-local_rqa.trainers.qa_llm.supervised_fid_trainer"]], "local_rqa.trainers.qa_llm.supervised_trainer module": [[11, "module-local_rqa.trainers.qa_llm.supervised_trainer"]], "local_rqa.trainers.qa_llm.with_retriever_fid_trainer module": [[11, "module-local_rqa.trainers.qa_llm.with_retriever_fid_trainer"]], "local_rqa.trainers.qa_llm.with_retriever_trainer module": [[11, "module-local_rqa.trainers.qa_llm.with_retriever_trainer"]], "local_rqa.trainers.retriever namespace": [[12, "module-local_rqa.trainers.retriever"]], "local_rqa.trainers.retriever.arguments module": [[12, "module-local_rqa.trainers.retriever.arguments"]], "local_rqa.trainers.retriever.datasets module": [[12, "module-local_rqa.trainers.retriever.datasets"]], "local_rqa.trainers.retriever.embeddings module": [[12, "module-local_rqa.trainers.retriever.embeddings"]], "local_rqa.trainers.retriever.retriever_fid_trainer module": [[12, "module-local_rqa.trainers.retriever.retriever_fid_trainer"]], "local_rqa.trainers.retriever.retriever_replug_trainer module": [[12, "module-local_rqa.trainers.retriever.retriever_replug_trainer"]], "local_rqa.trainers.retriever.retriever_trainer module": [[12, "module-local_rqa.trainers.retriever.retriever_trainer"]], "Inference Acceleration Frameworks": [[22, "inference-acceleration-frameworks"]], "Accelerating SimpleRQA": [[22, "accelerating-simplerqa"]], "Accelerating Model Serving": [[22, "accelerating-model-serving"]], "local_rqa.retrievers package": [[6, "local-rqa-retrievers-package"]], "local_rqa.retrievers.base module": [[6, "module-local_rqa.retrievers.base"]], "local_rqa.retrievers.bm25_retriever module": [[6, "local-rqa-retrievers-bm25-retriever-module"]], "local_rqa.retrievers.faiss_retriever module": [[6, "module-local_rqa.retrievers.faiss_retriever"]], "Data": [[17, "data"]], "End-to-End Evaluation": [[19, "end-to-end-evaluation"]]}, "indexentries": {"accelerationframework (class in local_rqa.constants)": [[1, "local_rqa.constants.AccelerationFramework"]], "context_overflow (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.CONTEXT_OVERFLOW"]], "controller_no_worker (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.CONTROLLER_NO_WORKER"]], "controller_worker_timeout (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.CONTROLLER_WORKER_TIMEOUT"]], "cuda_out_of_memory (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.CUDA_OUT_OF_MEMORY"]], "component (class in local_rqa.base)": [[1, "local_rqa.base.Component"]], "engine_overloaded (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.ENGINE_OVERLOADED"]], "errorcode (class in local_rqa.constants)": [[1, "local_rqa.constants.ErrorCode"]], "gradio_request_error (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.GRADIO_REQUEST_ERROR"]], "gradio_stream_unknown_error (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.GRADIO_STREAM_UNKNOWN_ERROR"]], "incorrect_auth_key (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.INCORRECT_AUTH_KEY"]], "internal_error (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.INTERNAL_ERROR"]], "invalid_auth_key (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.INVALID_AUTH_KEY"]], "invalid_model (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.INVALID_MODEL"]], "no_permission (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.NO_PERMISSION"]], "param_out_of_range (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.PARAM_OUT_OF_RANGE"]], "quota_exceeded (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.QUOTA_EXCEEDED"]], "rate_limit (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.RATE_LIMIT"]], "sglang (local_rqa.constants.accelerationframework attribute)": [[1, "local_rqa.constants.AccelerationFramework.SGLANG"]], "tgi (local_rqa.constants.accelerationframework attribute)": [[1, "local_rqa.constants.AccelerationFramework.TGI"]], "validation_type_error (local_rqa.constants.errorcode attribute)": [[1, "local_rqa.constants.ErrorCode.VALIDATION_TYPE_ERROR"]], "vllm (local_rqa.constants.accelerationframework attribute)": [[1, "local_rqa.constants.AccelerationFramework.VLLM"]], "init_logger() (in module local_rqa.utils)": [[1, "local_rqa.utils.init_logger"]], "local_rqa": [[1, "module-local_rqa"]], "local_rqa.base": [[1, "module-local_rqa.base"]], "local_rqa.constants": [[1, "module-local_rqa.constants"]], "local_rqa.utils": [[1, "module-local_rqa.utils"]], "module": [[1, "module-local_rqa"], [1, "module-local_rqa.base"], [1, "module-local_rqa.constants"], [1, "module-local_rqa.utils"], [6, "module-local_rqa.retrievers"], [6, "module-local_rqa.retrievers.base"], [6, "module-local_rqa.retrievers.faiss_retriever"]], "pretty_print_semaphore() (in module local_rqa.utils)": [[1, "local_rqa.utils.pretty_print_semaphore"]], "run() (local_rqa.base.component method)": [[1, "local_rqa.base.Component.run"]], "run_input_keys (local_rqa.base.component attribute)": [[1, "local_rqa.base.Component.run_input_keys"]], "baseretriever (class in local_rqa.retrievers.base)": [[6, "local_rqa.retrievers.base.BaseRetriever"]], "dummyretriever (class in local_rqa.retrievers.base)": [[6, "local_rqa.retrievers.base.DummyRetriever"]], "faissretriever (class in local_rqa.retrievers.faiss_retriever)": [[6, "local_rqa.retrievers.faiss_retriever.FaissRetriever"]], "retrievaloutput (class in local_rqa.retrievers.base)": [[6, "local_rqa.retrievers.base.RetrievalOutput"]], "batch_source_documents (local_rqa.retrievers.base.retrievaloutput attribute)": [[6, "local_rqa.retrievers.base.RetrievalOutput.batch_source_documents"]], "from_disk() (local_rqa.retrievers.faiss_retriever.faissretriever static method)": [[6, "local_rqa.retrievers.faiss_retriever.FaissRetriever.from_disk"]], "local_rqa.retrievers": [[6, "module-local_rqa.retrievers"]], "local_rqa.retrievers.base": [[6, "module-local_rqa.retrievers.base"]], "local_rqa.retrievers.faiss_retriever": [[6, "module-local_rqa.retrievers.faiss_retriever"]], "prepare_docs_for_retrieval() (local_rqa.retrievers.faiss_retriever.faissretriever method)": [[6, "local_rqa.retrievers.faiss_retriever.FaissRetriever.prepare_docs_for_retrieval"]], "retrieve() (local_rqa.retrievers.base.baseretriever method)": [[6, "local_rqa.retrievers.base.BaseRetriever.retrieve"]], "retrieve() (local_rqa.retrievers.base.dummyretriever method)": [[6, "local_rqa.retrievers.base.DummyRetriever.retrieve"]], "retrieve() (local_rqa.retrievers.faiss_retriever.faissretriever method)": [[6, "local_rqa.retrievers.faiss_retriever.FaissRetriever.retrieve"]], "retrieve_w_score() (local_rqa.retrievers.faiss_retriever.faissretriever method)": [[6, "local_rqa.retrievers.faiss_retriever.FaissRetriever.retrieve_w_score"]], "run() (local_rqa.retrievers.base.baseretriever method)": [[6, "local_rqa.retrievers.base.BaseRetriever.run"]], "run_input_keys (local_rqa.retrievers.base.baseretriever attribute)": [[6, "local_rqa.retrievers.base.BaseRetriever.run_input_keys"]]}})