.. _use-case-databricks:

Databricks
==========

Data Generation
---------------

We use data provided by Databricks' technical support team. After applying our document preparation steps, we obtain a documents of 11,136 passages with a maximum length of 400 tokens: ``databricks_400.pkl``. Then, run the data generation scripts to generate questions and answers for each document.

**Generate Questions**
::

    python scripts/data/doc_to_q_databricks.py \
    -mode all \
    -document_path data/database/databricks/databricks_400.pkl \
    --prompt_model gpt-3.5-turbo \
    --num_hard_negs_per_doc 2 \
    --num_train_data 1200 \  # use a small number to test if it works first
    --num_eval_test_data 150 \  # use a small number to test if it works first
    --save_dir data/training/databricks_new

**Generate Answers**
::

    python scripts/data/doc_q_to_a_databricks.py \
    --prompt_model gpt-4-1106-preview \
    --dataset_w_q data/training/databricks_new/train_w_q.jsonl \  # generated by the previous step
    --save_name train_w_qa.jsonl \
    --save_dir data/training/databricks_new \
    --end_data_idx 4  # a small number to test if it works


It will save ``train_w_qa.jsonl, train_w_a.jsonl, eval_w_qa.jsonl, eval_w_a.jsonl, test_w_qa.jsonl, test_w_a.jsonl`` under ``data/training/databricks_new`` folder.


Retriever Training
------------------

Take CTL retriever trainer with E5 model as an example, the finetuned retriever model will be saved under ``result/model_checkpoints/e5/e5_databricks_1e4_inbatch256_temp1_hard0.05`` folder with highest recall@4 score.
::

    python scripts/train/retriever/train_ctl_retriever.py \
    --full_dataset_file_path data/training/databricks_400.pkl \
    --train_file data/training/databricks_new/train_w_q.jsonl \
    --eval_file data/training/databricks_new/eval_w_q.jsonl \
    --model_path intfloat/e5-base-v2 \
    --pooling_type mean \
    --do_train True \
    --do_eval True \
    --learning_rate 1e-4 \
    --per_device_train_batch_size 256 \
    --per_device_eval_batch_size 128 \
    --hard_neg_ratio 0.05 \
    --contrastive_loss inbatch_contrastive \
    --metric_for_best_model eval_retr/document_recall/recall4 \
    --max_steps 150 \
    --eval_steps 5 \
    --save_steps 5 \
    --logging_steps 1 \
    --temperature 1 \
    --output_dir result/model_checkpoints/e5/e5_databricks_1e4_inbatch256_chunk400_fulldoc_temp1_hard0.05


Generator Training
------------------

TODO: an example for each training script, as promised in the training section.


By using the finetuned retriever from the previous step, train the generation model ``berkeley-nest/Starling-LM-7B-alpha`` further with fixed retriever.
::

    torchrun --nproc_per_node=1 --master_port=20001 scripts/train/qa_llm/train_w_fixed_retriever.py \
    --use_flash_attention true \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --deepspeed scripts/train/ds_config.json \
    --learning_rate 1e-5 \
    --num_train_epochs 2 \
    --gradient_accumulation_steps 4 \
    --bf16 true \
    --model_name_or_path berkeley-nest/Starling-LM-7B-alpha \
    --assistant_prefix "GPT4 Correct Assistant" \
    --user_prefix "GPT4 Correct User" \
    --sep_user "<|end_of_turn|>" \
    --sep_sys "<|end_of_turn|>" \
    --embedding_model model_checkpoints/retriever_model/e5_databricks_1e4_inbatch256_chunk400_fulldoc_temp1_hard0.05_retriever_train/checkpoint-120 \
    --embedding_max_num_to_retrieve 3 \
    --logging_steps 10 \
    --eval_steps 50 \
    --save_steps 50 \
    --output_dir model_checkpoints/databricks_Starling7b-5e6-train7_e5-ft \
    --run_group databricks_vicuna \
    --train_file data/training/databricks_new/train_w_qa.jsonl \
    --eval_file data/training/databricks_new/eval_w_qa.jsonl \
    --test_file data/training/databricks_new/test_w_qa.jsonl \
    --full_dataset_file_path data/database/databricks/databricks_400.pkl \
    --full_dataset_index_path data/database/databricks/databricks_400_e51e4_inbatch256_chunk400hard0.05_checkpoint120


- Test

Finally, the test script could evaluate the automatical metrics: recall@k, ROUGE-L, GPT4-Acc.
::

    python scripts/test/test_e2e.py \
    --qa_model_name_or_path model_checkpoints/databricks_Starling7b-1e5-train2_e5-ft/checkpoint-50 \
    --assistant_prefix "GPT4 Correct Assistant" \
    --user_prefix "GPT4 Correct User" \
    --sep_user "<|end_of_turn|>" \
    --sep_sys "<|end_of_turn|>" \
    --embedding_model_name_or_path model_checkpoints/retriever_model/e5_databricks_1e4_inbatch256_chunk400_fulldoc_temp1_hard0.05_retriever_train/checkpoint-120 \
    --document_path data/database/databricks/databricks_400.pkl \
    --index_path data/database/databricks/databricks_400_e51e4_inbatch256_chunk400hard0.05_checkpoint120 \
    --eval_data_path data/training/databricks_new/test_w_qa.jsonl \
    --output_dir model_checkpoints/databricks_e2e_tests/databricks_Starling7b-1e5-train2_e5-ft